
<ul class="toc"><li class="toclevel"><a href='User Guide.html'>User Guide</a></li><ul class="toc"><li class="toclevel"><a href='Graphics.html'>Graphics</a></li><ul class="toc"><li class="toclevel"><a href='Meshes.html'>Meshes</a></li><li class="toclevel"><a href='Particle Systems.html'>Particle systems</a></li><li class="toclevel"><a href='Materials and Shaders.html'>Materials and Shaders</a></li><li class="toclevel"><a href='Lighting and Rendering.html'>Lighting and Rendering</a></li><li class="toclevel"><a href='Making a GUI.html'> Making a GUI</a></li></ul><li class="toclevel"><a href='Assets.html'>Assets</a></li><ul class="toc"><li class="toclevel"><a href='Textures.html'>Texture 2D</a></li><li class="toclevel"><a href='Imported Scenes.html'> Importing 3D models</a></li><li class="toclevel"><a href='Sound files.html'>Sound Files</a></li><li class="toclevel"><a href='Prefabs.html'>Prefabs</a></li></ul><li class="toclevel"><a href='Game Logic.html'>Game Logic</a></li><ul class="toc"><li class="toclevel"><a href='Physics.html'>Physics</a></li><li class="toclevel"><a href='Animation.html'>Animation</a></li><li class="toclevel"><a href='Character-Animation.html'>Character Animation</a></li><li class="toclevel"><a href='Sound.html'>Sound</a></li><li class="toclevel"><a href='Input.html'>Input</a></li><li class="toclevel"><a href='Scripting.html'>Scripting</a></li></ul><li class="toclevel"><a href='Building a game.html'>Building a game</a></li></ul><li class="toclevel"><a href='Advanced (for technical guys).html'>Advanced (for technical guys)</a></li><ul class="toc"><li class="toclevel"><a href='Shaders.html'>Shaders</a></li><ul class="toc"><li class="toclevel"><a href='ShaderTut1.html'>Shaders: Getting started</a></li><li class="toclevel"><a href='ShaderTut2.html'> Shaders: Vertex and Fragment Programs</a></li><li class="toclevel"><a href='SL-Shader.html'>Shader</a></li><ul class="toc"><li class="toclevel"><a href='SL-Properties.html'>Properties</a></li><li class="toclevel"><a href='SL-SubShader.html'>SubShaders</a></li><ul class="toc"><li class="toclevel"><a href='SL-Pass.html'> Pass</a></li><ul class="toc"><li class="toclevel"><a href='SL-Material.html'> Color, Material &amp; Lighting</a></li><li class="toclevel"><a href='SL-CullAndDepth.html'>Culling &amp; Depth Testing</a></li><li class="toclevel"><a href='SL-SetTexture.html'>Texturing</a></li><li class="toclevel"><a href='SL-Fog.html'>Fog</a></li><li class="toclevel"><a href='SL-AlphaTest.html'> Alpha testing</a></li><li class="toclevel"><a href='SL-Blend.html'> Blend</a></li><li class="toclevel"><a href='SL-NameAndTags.html'> Tags</a></li><li class="toclevel"><a href='SL-BindChannels.html'> Bind Channels</a></li></ul><li class="toclevel"><a href='SL-GrabPass.html'> GrabPass</a></li></ul><li class="toclevel"><a href='SL-Fallback.html'>Fallback statement</a></li></ul><li class="toclevel"><a href='Reference - Structure.html'>Reference - Structure</a></li><li class="toclevel"><a href='Reference - Values.html'>Reference - Values</a></li><li class="toclevel"><a href='ShaderLab Cheat Sheet.html'>ShaderLab Cheat Sheet</a></li></ul><li class="toclevel"><a href='Plugins.html'>Plugins - Pro only feature</a></li><li class="toclevel"><a href='Reducing File size.html'>Reducing File Size</a></li><li class="toclevel"><a href='Optimizing Graphics Performance.html'>Optimizing Graphics Performance</a></li></ul><li class="toclevel"><a href='HOW-TOs.html'>HOW-TOs</a></li><ul class="toc"><li class="toclevel"><a href='Graphics how-tos.html'>Graphics how-tos</a></li><ul class="toc"><li class="toclevel"><a href='HOWTO-bumpmap.html'> How Do I Use Bump Maps?</a></li><li class="toclevel"><a href='HOWTO-UseDetailTexture.html'> How do I use Detail Textures?</a></li><li class="toclevel"><a href='HOWTO-MakeCubemap.html'>How Do I Make a Cubemap Texture?</a></li><li class="toclevel"><a href='HOWTO-UseSkybox.html'>How do I Make a Skybox?</a></li><li class="toclevel"><a href='HOWTO-MeshParticleEmitter.html'>How Do I make a Mesh Particle Emitter?</a></li><li class="toclevel"><a href='HOWTO-SplashScreen.html'> How do I make a Splash Screen</a></li><li class="toclevel"><a href='HOWTO-LightCookie.html'> How do I make a Spot Light Cookie?</a></li><li class="toclevel"><a href='HOWTO-FixZAxisIsUp.html'>Fixing the rotation of an imported model</a></li><li class="toclevel"><a href='HOWTO-Water.html'>How do I use Water?</a></li></ul><li class="toclevel"><a href='HOWTO-importObject.html'> How do I import objects from my 3D app?</a></li><ul class="toc"><li class="toclevel"><a href='HOWTO-ImportObjectMax.html'> Importing Objects From 3dsMax</a></li><li class="toclevel"><a href='HOWTO-ImportObjectBlender.html'> Importing Objects From Blender</a></li><li class="toclevel"><a href='HOWTO-ImportObjectCinema4D.html'> Importing Objects From Cinema 4D</a></li><li class="toclevel"><a href='HOWTO-importObjectLightwave.html'> Importing Objects From Lightwave</a></li><li class="toclevel"><a href='HOWTO-ImportObjectMaya.html'> Importing Objects From Maya</a></li><li class="toclevel"><a href='HOWTO-ImportObjectModo.html'> Importing Objects From Modo</a></li><li class="toclevel"><a href='HOWTO-ImportObjectCheetah3D.html'> Importing Objects From Cheetah3D</a></li></ul><li class="toclevel"><a href='Workflow.html'>Workflow</a></li><ul class="toc"><li class="toclevel"><a href='HOWTO-exportpackage.html'>How do I reuse assets between projects?</a></li><li class="toclevel"><a href='HOWTO-InstallStandardAssets.html'>How do I install or upgrade Standard Assets</a></li></ul></ul></ul>
<p>In this document we go over the Unity feature set grouped categorically.
</p>

<p><!--BEGIN-->
<ul class="toc"><li class="toclevel"><a href="../Manual/Graphics.html">Graphics</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Meshes.html">Meshes</a></li><li class="toclevel"><a href="../Manual/Particle Systems.html">Particle Systems</a></li><li class="toclevel"><a href="../Manual/Materials and Shaders.html">Materials and Shaders</a></li><li class="toclevel"><a href="../Manual/Lighting and Rendering.html">Lighting and Rendering</a></li><li class="toclevel"><a href="../Manual/Making a GUI.html">Making a GUI</a></li></ul><li class="toclevel"><a href="../Manual/Assets.html">Assets</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Textures.html">Textures</a></li><li class="toclevel"><a href="../Manual/Imported Scenes.html">Imported Scenes</a></li><li class="toclevel"><a href="../Manual/Sound files.html">Sound files</a></li><li class="toclevel"><a href="../Manual/Prefabs.html">Prefabs</a></li></ul><li class="toclevel"><a href="../Manual/Game Logic.html">Game Logic</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Physics.html">Physics</a></li><li class="toclevel"><a href="../Manual/Animation.html">Animation</a></li><li class="toclevel"><a href="../Manual/Character-Animation.html">Character-Animation</a></li><li class="toclevel"><a href="../Manual/Sound.html">Sound</a></li><li class="toclevel"><a href="../Manual/Input.html">Input</a></li><li class="toclevel"><a href="../Manual/Scripting.html">Scripting</a></li></ul><li class="toclevel"><a href="../Manual/Building a game.html">Building a game</a></li></ul>
<!--END-->
</p>




<p>One of the core components of Unity is its next-generation graphics engine. Read on for more...
</p>


<p><ul class="toc"><li class="toclevel"><a href="../Manual/Meshes.html">Meshes</a></li><li class="toclevel"><a href="../Manual/Particle Systems.html">Particle Systems</a></li><li class="toclevel"><a href="../Manual/Materials and Shaders.html">Materials and Shaders</a></li><li class="toclevel"><a href="../Manual/Lighting and Rendering.html">Lighting and Rendering</a></li><li class="toclevel"><a href="../Manual/Making a GUI.html">Making a GUI</a></li></ul>
</p>



<p>At the core of any 3D game are <i>Meshes</i> - objects consisting of triangles, with textures applied.
</p>

<p>Meshes in Unity are passed through <i>render pipeline</i>. Although there may be many variations, most often a pipeline consists of a <a href="../Components/class-MeshFilter.html"> Mesh Filter</a> and a <a href="../Components/class-MeshRenderer.html"> Mesh Renderer</a>:
</p>
<ul><li> The filter loads mesh from mesh asset. Regular meshes use a Mesh Filter, while skinned meshes use a <a href="../Components/class-SkinnedMeshFilter.html"> Skinned Mesh Filter</a>.
</li><li> The renderer displays it at the Game Object's position.
</li><li> The appearance of the mesh is controlled through renderer's <a > Materials</a>.
</li></ul>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Meshes-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Meshes-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A <a href="../Components/class-MeshFilter.html"> Mesh Filter</a> together with <a href="../Components/class-MeshRenderer.html"> Mesh Renderer</a> makes the model appear on screen. Car model courtesy of ATI Technologies Inc.</i>
</p>



<p>Particle systems in Unity are used to make clouds of smoke, steam, fire and other atmospheric effects. Particle systems work by using one or two textures &amp; drawing them many times, creating a chaotic effect.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>One of the default explosions included in unity and the two textures it is made of. The orange texture is used for the flames in the bottom of the explosion, and the grayscale one is used to make the smoke near the top.
</p>

<p>A typical particle system in Unity is an object that contains a Particle Emitter, a Particle Animator and a Particle Renderer component. The <a href="../Components/class-EllipsoidParticleEmitter.html">emitter</a> generates the particles, the <a href="../Components/class-ParticleAnimator.html">animator</a> moves them over time, and the <a href="../Components/class-ParticleRenderer.html">renderer</a> gets them on the screen.
</p>

<p>If you want your particles to interact with the world, add a <a href="../Components/class-WorldParticleCollider.html">particle collider</a> component to the object.
</p>

<h2>See also</h2>



<h1>Ellipsoid Particle Emitter</h1>
<p>The Ellipsoid Particle Emitter spawns particles inside a sphere. Use the <b>Ellipsoid</b> property below to scale &amp; stretch the sphere.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Ellipsoid Particle Emitter</i>
</p>


<h2>Properties</h2>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
 Emit</nobr></b></td><td> If enabled, the emitter will emit particles.
</td></tr><tr><td><b><nobr>Min Size</nobr></b></td><td> The minimum size each particle can be at the time when it is spawned.
</td></tr><tr><td><b><nobr>Max Size</nobr></b></td><td> The maximum size each particle can be at the time when it is spawned.
</td></tr><tr><td><b><nobr>Min Energy</nobr></b></td><td> The minimum lifetime of each particle, measured in seconds.
</td></tr><tr><td><b><nobr>Max Energy</nobr></b></td><td> The maximum lifetime of each particle, measured in seconds.
</td></tr><tr><td><b><nobr>Min Emission</nobr></b></td><td> The minimum number of particles that will be spawned every second.
</td></tr><tr><td><b><nobr>Max Emission</nobr></b></td><td> The maximum number of particles that will be spawned every second.
</td></tr><tr><td><b><nobr>World Velocity</nobr></b></td><td> The starting speed of particles in world space, along X, Y, and Z.
</td></tr><tr><td><b><nobr>Local Velocity</nobr></b></td><td> The starting speed of particles along X, Y, and Z, measured in the object's orientation.
</td></tr><tr><td><b><nobr>Rnd Velocity</nobr></b></td><td> A random speed along X, Y, and Z that is added to the velocity.
</td></tr><tr><td><b><nobr>Emitter Velocity Scale</nobr></b></td><td> The amount of the emitter's speed that the particles inherit.
</td></tr><tr><td><b><nobr>Simulate In World Space</nobr></b></td><td> If enabled, the particles don't move when the emitter moves. If false, when you move the emitter, the particles follow it around.
</td></tr><tr><td><b><nobr>One Shot</nobr></b></td><td> If enabled, the particle numbers specified by min &amp; max emission is spawned all at once. If disabled, the particles are generated in a long stream.
</td></tr><tr><td><b><nobr>Ellipsoid</nobr></b></td><td> Scale of the sphere along X, Y, and Z that the particles are spawned inside.
</td></tr><tr><td><b><nobr>MinEmitterRange</nobr></b></td><td> Determines an empty area in the center of the sphere - use this to make particles appear on the edge of the sphere.
<p></td></tr></tr></table>
</p>


<h2>Details</h2>
<p>Ellipsoid Particle Emitters (EPEs) are the basic emitter, and are included when you choose to add a Particle System to your scene from Components -&gt; Particles -&gt; Particle System.  You can define the boundaries for the particles to be spawned, and give the particles an initial velocity.  From here, use the <a href="../Components/class-ParticleAnimator.html">Particle Animator</a> to manipulate how your particles will change over time to achieve interesting effects.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>An EPE applied to a sphere</i>
</p>

<p>Particle Emitters work in conjunction with <a href="../Components/class-ParticleAnimator.html">Particle Animators</a> and <a href="../Components/class-ParticleRenderer.html">Particle Renderers</a> to create, manipulate, and display Particle Systems.  All three components must be present on an object before the particles will behave correctly.  When particles are being emitted, all different velocities are added together to create the final velocity.
</p>


<h3>Spawning Properties</h3>

<p>Spawning properties like <b>Size</b>, <b>Energy</b>, <b>Emission</b>, and <b>Velocity</b> will give your particle system distinct personality when trying to achieve different effects.  Having a small <b>Size</b> could simulate fireflies or stars in the sky.  A large <b>Size</b> could simulate dust clouds in a musky old building.
</p>

<p><b>Energy</b> and <b>Emission</b> will control how long your particles remain onscreen and how many particles can appear at any one time.  For example, a rocket might have high <b>Emission</b> to simulate density of smoke, and high <b>Energy</b> to simulate the slow dispersion of smoke into the air.
</p>

<p><b>Velocity</b> will control how your particles move.  You might want to change your <b>Velocity</b> in scripting to achieve interesting effects, or if you want to simulate a constant effect like wind, set your X and Z <b>Velocity</b> to make your particles blow away.
</p>

<h3>Simulate in World Space</h3>

<p>If this is disabled, the position of each individual particle will always translate relative to the <b>Position</b> of the emitter.  When the emitter moves, the particles will move along with it.  If you have <b>Simulate in World Space</b> enabled, particles will not be affected by the translation of the emitter.  For example, if you have a fireball that is spurting flames that rise, the flames will be spawned and float up in space as the fireball gets further away.  If <b>Simulate in World Space</b> is disabled, those same flames will move across the screen along with the fireball.
</p>

<h3>Emitter Velocity Scale</h3>

<p>This property will only apply if <b>Simulate in World Space</b> is enabled.
</p>

<p>If this property is set to 1, the particles will inherit the exact translation of the emitter at the time they are spawned.  If it is set to 2, the particles will inherit double the emitter's translation when they are spawned.  3 is triple the translation, etc.
</p>

<h3>One Shot</h3>

<p><b>One Shot</b> emitters will create all particles within the <b>Emission</b> property all at once, and cease to emit particles over time.  Here are some examples of different particle system uses with <b>One Shot</b> enabled or disabled:
</p>

<p>Enabled
</p>
<ul><li>Explosion
</li><li>Water splash
</li><li>Magic spell
</li></ul>

<p>Disabled
</p>
<ul><li>Gun barrel smoke
</li><li>Wind effect
</li><li>Waterfall
</li></ul>



<h3>Min Emitter Range</h3>

<p>The <b>Min Emitter Range</b> determines the depth within the ellipsoid that particles can be spawned.  Setting the range to 0 will allow particles to spawn anywhere from the center core of the ellipsoid to the outer-most range.  Setting the range to 1 will restrict spawn locations to the outer-most range of the ellipsoid.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i><b>Min Emitter Range</b> of 0</i>
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-4.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-4.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i><b>Min Emitter Range</b> of 1</i>
</p>

<h2>Hints</h2>
<p><ul><li>
Be careful of using many large particles. This can seriously hinder performance on low-level machines. Always try to use the minimum number of particles to attain an effect.
</li><li>The <b>Emit</b> property works in conjunction with the <b>AutoDestruct</b> property of the ParticleAnimator.  Through scripting, you can cease the emitter from emitting, and then <b>AutoDestruct</b> will automatically destroy the Particle System and the GameObject it is attached to.
</li></ul>
</p>
<h1> Mesh Particle Emitter</h1>
<p>The Mesh Particle Emitter emits particles around a mesh. Particles are spawned from the surface of the mesh, which can be necessary when you want to make your particles interact in a complex way with objects.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-5.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-5.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Mesh Particle Emitter</i>
</p>

<p>Here is how to create a <a href="../Manual/HOWTO-MeshParticleEmitter.html">Mesh Particle Emitter</a>.
</p>

<h2> Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
 Emit</nobr></b></td><td> If enabled, the emitter will emit particles.
</td></tr><tr><td><b><nobr>Min Size</nobr></b></td><td> The minimum size each particle can be at the time when it is spawned.
</td></tr><tr><td><b><nobr>Max Size</nobr></b></td><td> The maximum size each particle can be at the time when it is spawned.
</td></tr><tr><td><b><nobr>Min Energy</nobr></b></td><td> The minimum lifetime of each particle, measured in seconds.
</td></tr><tr><td><b><nobr>Max Energy</nobr></b></td><td> The maximum lifetime of each particle, measured in seconds.
</td></tr><tr><td><b><nobr>Min Emission</nobr></b></td><td> The minimum number of particles that will be spawned every second.
</td></tr><tr><td><b><nobr>Max Emission</nobr></b></td><td> The maximum number of particles that will be spawned every second.
</td></tr><tr><td><b><nobr>World Velocity</nobr></b></td><td> The starting speed of particles in world space, along X, Y, and Z.
</td></tr><tr><td><b><nobr>Local Velocity</nobr></b></td><td> The starting speed of particles along X, Y, and Z, measured in the object's orientation.
</td></tr><tr><td><b><nobr>Rnd Velocity</nobr></b></td><td> A random speed along X, Y, and Z that is added to the velocity.
</td></tr><tr><td><b><nobr>Emitter Velocity Scale</nobr></b></td><td> The amount of the emitter's speed that the particles inherit.
</td></tr><tr><td><b><nobr>Simulate In World Space</nobr></b></td><td> If enabled, the particles don't move when the emitter moves. If false, when you move the emitter, the particles follow it around.
</td></tr><tr><td><b><nobr>One Shot</nobr></b></td><td> If enabled, the particle numbers specified by min &amp; max emission is spawned all at once. If disabled, the particles are generated in a long stream.
</td></tr><tr><td><b><nobr>Interpolate Triangles</nobr></b></td><td> If enabled, particles are spawned all over the mesh's surface. If disabled, particles are only spawned from the mesh's vertrices.
</td></tr><tr><td><b><nobr>Systematic</nobr></b></td><td> If enabled, particles are spawned in the order of the vertices defined in the mesh. Although you seldom have direct control over vertex order in meshes, most 3D modelling applications have a very systematic setup when using primitives. It is important that the mesh contains no faces in order for this to work.
</td></tr><tr><td><b><nobr>Min Normal Velocity</nobr></b></td><td> Minimum amount that particles are thrown away from the mesh.
</td></tr><tr><td><b><nobr>Max Normal Velocity</nobr></b></td><td> Maximum amount that particles are thrown away from the mesh.
<p></td></tr></tr></table>
</p>

<h2> Details</h2>
<p>Mesh Particle Emitters (MPEs) are used when you want more precise control over the spawn position &amp; directions than the simpler Ellipsoid Particle Emitter gives you.  They can be used for making advanced effects like flaming swords.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-6.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-6.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A flaming sword created with a Mesh Particle Emitter</i>
</p>

<p>MPEs work emitting particles at the vertices of the attached mesh. Therefore, the areas of your mesh that are more dense with polygons will be more dense with particle emission.
</p>

<p>Particle Emitters work in conjunction with <a href="../Components/class-ParticleAnimator.html">Particle Animators</a> and <a href="../Components/class-ParticleRenderer.html">Particle Renderers</a> to create, manipulate, and display Particle Systems.  All three components must be present on an object before the particles will behave correctly.  When particles are being emitted, all different velocities are added together to create the final velocity.
</p>


<h3>Spawning Properties</h3>

<p>Spawning properties like <b>Size</b>, <b>Energy</b>, <b>Emission</b>, and <b>Velocity</b> will give your particle system distinct personality when trying to achieve different effects.  Having a small <b>Size</b> could simulate fireflies or stars in the sky.  A large <b>Size</b> could simulate dust clouds in a musky old building.
</p>

<p><b>Energy</b> and <b>Emission</b> will control how long your particles remain onscreen and how many particles can appear at any one time.  For example, a rocket might have high <b>Emission</b> to simulate density of smoke, and high <b>Energy</b> to simulate the slow dispersion of smoke into the air.
</p>

<p><b>Velocity</b> will control how your particles move.  You might want to change your <b>Velocity</b> in scripting to achieve interesting effects, or if you want to simulate a constant effect like wind, set your X and Z <b>Velocity</b> to make your particles blow away.
</p>

<h3>Simulate in World Space</h3>

<p>If this is disabled, the position of each individual particle will always translate relative to the <b>Position</b> of the emitter.  When the emitter moves, the particles will move along with it.  If you have <b>Simulate in World Space</b> enabled, particles will not be affected by the translation of the emitter.  For example, if you have a fireball that is spurting flames that rise, the flames will be spawned and float up in space as the fireball gets further away.  If <b>Simulate in World Space</b> is disabled, those same flames will move across the screen along with the fireball.
</p>

<h3>Emitter Velocity Scale</h3>

<p>This property will only apply if <b>Simulate in World Space</b> is enabled.
</p>

<p>If this property is set to 1, the particles will inherit the exact translation of the emitter at the time they are spawned.  If it is set to 2, the particles will inherit double the emitter's translation when they are spawned.  3 is triple the translation, etc.
</p>

<h3>One Shot</h3>

<p><b>One Shot</b> emitters will create all particles within the <b>Emission</b> property all at once, and cease to emit particles over time.  Here are some examples of different particle system uses with <b>One Shot</b> enabled or disabled:
</p>

<p>Enabled
</p>
<ul><li>Explosion
</li><li>Water splash
</li><li>Magic spell
</li></ul>

<p>Disabled
</p>
<ul><li>Gun barrel smoke
</li><li>Wind effect
</li><li>Waterfall
</li></ul>


<h2>Interpolate Triangles</h2>

<p>Enabling your emitter to interpolate triangles will allow particles to be spawned outside of the mesh's vertices.  This option is off by default, so particles will only be spawned at vertex locations.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-7.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-7.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A flaming sword with <b>Interpolate Triangles</b> off (by default)</i>
</p>

<p>Enabling this option will spawn particles on and in-between vertices, essentially all over the mesh's surface (seen below).
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-8.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-8.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A flaming sword with <b>Interpolate Triangles</b> on</i>
</p>

<p>It bears repeating that even with <b>Interpolate Triangles</b> enabled, particles will still be denser in areas of your mesh that are more dense with polygons.
</p>

<h2>Systematic</h2>

<p>Enabling <b>Systematic</b> will cause your particles to be spawned in your mesh's vertex order.  The vertex order is set by your 3D modeling application.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-9.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-9.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>An MPE attached to a sphere with Systematic enabled</i>
</p>

<h2>Normal Velocity</h2>

<p><b>Normal Velocity</b> controls the speed at which particles are emitted along the normal from where they are spawned.
</p>

<p>For example, create a Mesh Particle system, use a cube mesh as the emitter, enable <b>Interpolate Triangles</b>, and set <b>Normal Velocity Min</b> and <b>Max</b> to 1. You will now see the particles emit from the faces of the cube in a straight line.
</p>

<h2>See Also</h2>
<ul><li> <a href="../Manual/HOWTO-MeshParticleEmitter.html">How to make a Mesh Particle Emitter</a>
</li></ul>

<h2> Hints</h2>
<p><ul><li>
</p>

<p>MPEs can also be used to make glow from a lot of lamps placed in a scene. Simply make a mesh with one vertex in the center of each lamp, and build an MPE from that with a halo material. Great for evil sci-fi worlds.
</li></ul>
</p>
<h1> Particle Animator</h1>
<p>Particle Animators move your particles over time, you use them to apply wind, drag &amp; color cycling to your particle systems.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-10.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-10.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Particle Animator</i>
</p>

<h2> Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Does Animate Color</nobr></b></td><td> If enabled, particles cycle their color over their lifetime.
</td></tr><tr><td><b><nobr>Color Animation</nobr></b></td><td> The 5 colors particles go through. All particles cycle over this - if some have a shorter life span than others, they will animate faster.
</td></tr><tr><td><b><nobr>World Rotation Axis</nobr></b></td><td> An optional world-space axis the particles rotate around. Use this to make advanced spell effects or give caustic bubbles some life.
</td></tr><tr><td><b><nobr>Local Rotation Axis</nobr></b></td><td> An optional local-space axis the particles rotate around. Use this to make advanced spell effects or give caustic bubbles some life.
</td></tr><tr><td><b><nobr>Size Grow</nobr></b></td><td> Use this to make particles grow in size over their lifetime. As randomized forces will spread your particles out, it is often nice to make them grow in size so they don't fall apart.
Use this to make smoke rise upwards, to simulate wind, etc.
</td></tr><tr><td><b><nobr>Rnd Force</nobr></b></td><td> A random force added to particles every frame. Use this to make smoke become more alive.
</td></tr><tr><td><b><nobr>Force</nobr></b></td><td> The force being applied every frame to the particles, measure relative to the world.
</td></tr><tr><td><b><nobr>Damping</nobr></b></td><td> How much particles are slowed every frame. A value of 1 gives no damping, while less makes them slow down.
</td></tr><tr><td><b><nobr>Autodestruct</nobr></b></td><td> If enabled, the GameObject attached to the Particle Animator will be destroyed when all particles disappear.
<p></td></tr></tr></table>
</p>

<h2> Details</h2>

<p>Particle Animators allow your particle systems to be dynamic.  They allow you to change the color of your particles, apply forces and rotation, and choose to destroy them when they are finished emitting.  For more information about Particle Systems, reference <a href="../Components/class-MeshParticleEmitter.html">Mesh Particle Emitters</a>, <a href="../Components/class-EllipsoidParticleEmitter.html">Ellipsoid Particle Emitters</a>, and <a href="../Components/class-ParticleRenderer.html">Particle Renderers</a>.
</p>

<h3>Animating Color</h3>

<p>If you would like your particles to change colors or fade in/out, enable them to <b>Animate Color</b> and specify the colors for the cycle.  Any particle system that animates color will cycle through the 5 colors you choose.  The speed at which they cycle will be determined by the Emitter's <b>Energy</b> value.
</p>

<p>If you want your particles to fade in rather than instantly appear, set your first or last color to have a low Alpha value.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-11.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-11.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>An <b>Animating Color</b> Particle System</i>
</p>

<h3>Rotation Axes</h3>

<p>Setting values in either the Local or World <b>Rotation Axes</b> will cause all spawned particles to rotate around the indicated axis (with the <b>Transform's</b> position as the center).  The greater the value is entered on one of these axes, the faster the rotation will be.
</p>

<p>Setting values in the Local Axes will cause the rotating particles to adjust their rotation as the <b>Transform's</b> rotation changes, to match its local axes.
</p>

<p>Setting values in the World Axes will cause the particles' rotation to be consistent, regardless of the <b>Transform's</b> rotation.
</p>

<h3>Forces &amp; Damping</h3>

<p>You use force to make particles accelerate in the direction specified by the force.
</p>

<p>Damping (Drag) can be used to decelerate or accelerate without changing their direction.<br />
A value of 1 means no damping is applied, the particles will not slow down or accelerate.<br />
A value of 0 means particles will stop immediately.<br />
A value of 2 means particles will double their speed every second.
</p>

<h3>Destroying Objects attached to Particles</h3>

<p>You can destroy the Particle System and any attached Game Object by enabling the <b>AutoDestruct</b> property.  For example, if you have an oil drum, you can attach a Particle System that has <b>Emit</b> disabled and <b>AutoDestruct</b> enabled.  On collision, you enable the Particle Emitter.  The explosion will occur and after it is over, the Particle System and the oil drum will be destroyed and removed from the scene.
</p>

<h2> Hints</h2>
<p><ul><li>
Use the color animation to make your particles fade in &amp; out over their lifetime - otherwise, you will get nasty-looking pops.
</li><li>Use the rotation axes to make whirlpool-like swirly motions.
</li></ul>
</p>
<h1>Particle Collider</h1>

<p>The Particle Collider is used to collide particles against other objects in the scene.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-12.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-12.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A shot of a very simple particle system with particle collider colliding with a cube</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Bounce Factor</nobr></b></td><td> Particles can be accelerated or slowed down when they collide against other objects. This factor is similar to the Particle Animator's damping.
</td></tr><tr><td><b><nobr>Collision Energy Loss</nobr></b></td><td>Amount of energy (in seconds) a particle should lose when colliding. If the energy goes below 0, the particle is killed
</td></tr><tr><td><b><nobr>Min Kill Velocity</nobr></b></td><td> If a particle's velocity drops below Min Kill Velocity because of a Collision, it will be eliminated.
</td></tr><tr><td><b><nobr>Collides with</nobr></b></td><td> Which layers the particles collides against.
</td></tr><tr><td><b><nobr>Send Collision Message</nobr></b></td><td> When colliding every particle sends out a message that you can catch through scripting.
<p></td></tr></tr></table>
</p>
<h2>Details</h2>

<p>To create a particle system with particle collider:
</p>
<ol><li> Create a particle system using <b>GameObject -&gt; Create Other -&gt; Particle System</b>
</li><li> Add the particle collider using <b>Component -&gt; Particles -&gt; World Particle Collider</b>
</li></ol>


<h3>Messaging</h3>
<p>If Send Collision Message is enabled, any particles that are in a collision will send the message OnParticleCollision to  both the particle's GameObject and the GameObject the particle collided with.
</p>

<h2>Hints</h2>
<p><ul><li>
Send Collision message can be used to simulate bullets and apply damage on impact.
</li><li>Particle Collision Detection is slow when used with a lot of particles. Use Particle Collision Detection wisely.
</li><li>Message sending introduces a large overhead and shouldn't be used for normal particle systems.
</li></ul>
</p>
<h1>Particle Renderer</h1>
<p>The Particle Renderer renders the particle system on screen.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-13.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-13.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
<i>The Particle Renderer</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Materials</nobr></b></td><td> Reference to a list of Materials that will be displayed in the position of each individual particle.
</td></tr><tr><td><b><nobr>Camera Velocity Scale</nobr></b></td><td> The amount of stretching that is applied to the particles based on Camera movement.
</td></tr><tr><td><b><nobr>Stretch Particles</nobr></b></td><td> Determines how the particles are rendered.
<dl><dt>Billboard</dt><dd> The particles are rendered as if facing the camera.</dd><dt>Stretched</dt><dd> The particles are facing the direction they are moving. </dd><dt>SortedBillboard</dt><dd> The particles are sorted by depth. Use this when using a blending material.</dd></dl>
</td></tr><tr><td><b><nobr>Length Scale</nobr></b></td><td> If <b>Stretch Particles</b> is set to Stretched, this value determines how long the particles are in their direction of motion.
</td></tr><tr><td><b><nobr>Velocity Scale</nobr></b></td><td> If <b>Stretch Particles</b> is set to Stretched, this value determines the rate at which particles will be stretched, based on their movement speed.
</td></tr><tr><td><b><nobr>UV Animation</nobr></b></td><td> If either of these are set, the UV coordinates of the particles will be generated for use with a tile animated texture. See the section on Animated Textures below.
</td></tr><tr><td><b><nobr>    X Tile</nobr></b></td><td> Number of frames located across the X axis
</td></tr><tr><td><b><nobr>    Y Tile</nobr></b></td><td> Number of frames located across the Y axis
</td></tr><tr><td><b><nobr>    Cycles</nobr></b></td><td> How many times to loop the animation sequence.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>Particle Renderers are required for any Particle Systems to be displayed on the screen.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Particle Systems-14.jpg%22" --><p><table><tr><td><img class="figure" src="images/Particle Systems-14.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A Particle Renderer is what makes explosion appear on the screen</i>
</p>

<h3> Choosing a material</h3>
<p>When setting up a particle renderer it is very important to use an appropriate material and shader. Most of the time you want to use a material with one of the <b>builtin Particle shaders</b>. There are some premade materials in the Standard Assets/Particles/Sources folder.
</p>

<p>Creating a new material is easy:
</p>
<ol><li> <b>Assets -&gt; Create Other -&gt; Material</b>
</li><li> The {class-Material|material} has a shader popup, choose one of the shaders in the Particles group. Eg. Particles/Multiply
</li><li> Now assign a texture. The different shaders use the alpha channel of the textures slightly differently, but most of the time a value of black will make it invisible and white in the alpha channel will display it on screen.
</li></ol>

<h3>Distorting particles</h3>

<p>By default particles are rendered billboarded. That is simple square sprites. This is good for smoke and explosions and most other particle effects.
</p>

<p>Particles can be made to either stretch with the velocity. This is useful for sparks, lightning or laser beam.
Length Scale and Velocity Scale affects how long the stretched particle will be.
</p>

<p>Sorted Billboard can be used to make all particles sort by depth. Sometimes this is necessary, mostly when using Alpha Blended particle shaders. This can be expensive and should only be used if it really makes a quality difference when rendering.
</p>

<h3>Animated textures</h3>
<p>Particle systems can be rendered with an animated tile texture. To use this feature, make the texture out of a grid of images. As the particles go thorough their life cycle, they will cycle through the images. This is good for adding more life to your particles, or making small rotating debris pieces.
</p>

<h2>Hints</h2>
<p><ul><li>
Use particle materials with the Particle Renderer.
</li></ul>
</p>



<p>Unity has an extensive Shader system, allowing you to tweak the look of all in-game graphics. It works like this:
</p>

<p>A Shader basically defines a formula for how the in-game shading should look. Within any given Shader is a number of properties (typically textures). Shaders are implemented through <b>Materials</b>, which are attached directly to individual Game Objects.  Within a Material, you will choose a Shader, then define the properties (usually textures and colors but properties can vary) that are used by the Shader.
</p>

<p>As this is rather complex, a graph is in order:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Materials and Shaders-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Materials and Shaders-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>On the left side of the graph is the <i>Carbody Shader</i>. 2 different Materials are created from this: <i>Blue car Material</i> and <i>Red car Material</i>. Each of these Materials have 2 textures assigned; the <i>Car Texture</i> defines the main texture of the car, and a <i>Color FX texture</i>. These properties are used by the shader to make the car finish look like 2-tone paint. This can be seen on the front of the red car: it is yellow where it faces the camera and then fades towards purple as the angle increases. The car materials are attached to the 2 cars. The car wheels, lights and windows don't have the color change effect, and must hence use a different Material. At the bottom of the graph there is a <i>Simple Metal Shader</i>. The <i>Wheel Material</i> is using this Shader. Note that even though the same <i>Car Texture</i> is reused here, the end result is quite different from the car body, as Shader used in the Material is different .
</p>

<p><i>Note: Quite a few textures, Shaders &amp; Materials were left out from this diagram in order to avoid clutter.</i>
</p>

<p>To be more specific, a Shader defines:
</p>
<ul><li> The method to render an object. This includes using different methods depending on the graphics card of the end user.
</li><li> Any vertex and fragment programs used to render.
</li><li> Some texture properties that are assignable within Materials.
</li><li> Color and number settings that are assignable within Materials.
</li></ul>

<p>A Material defines:
</p>
<ul><li> Which textures to use for rendering.
</li><li> Which colors to use for rendering.
</li><li> Any other assets, such as a Cubemap that is required by the shader for rendering.
</li></ul>

<p>Shaders are meant to be written by graphics programmers. They are written using the ShaderLab language, which is quite simple. However, getting a shader to work well on a variety graphics cards is an involved job and requires a fairly comprehensive knowledge of how graphics cards work.
</p>

<p>A number of shaders are built into Unity directly, and some more come in the <a href="../Manual/HOWTO-InstallStandardAssets.html">Standard Assets</a> Library.
</p>


<h2>Making new Materials</h2>

<p>To make a new Material, either:
</p>
<ul><li> Right-click on a Shader in the library window and select 'Add Material'
</li><li> Select an existing material and choose duplicate from the edit menu.
</li><li> Drag a texture onto a mesh. This automatically creates the material in the 'Materials' folder next to the texture.
</li></ul>

<h2>Setting Material Properties</h2>

<p>When you select an object in the scene, you can pick the Material from the object's <i>Renderer</i> component in the Inspector, or dragging a Material to the object from the library. After doing this, the Material inspector shows up. First it shows the shader used by this material, then all material properties are listed. Currently the properties can be colors, sliders, textures, numbers and vectors. As you change these, you can see the changes to the scene updated in real-time.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Materials and Shaders-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Materials and Shaders-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>To assign a texture, drag one from the project view over one of the texture buttons, or click &quot;Select&quot; and choose from a list. To edit the mapping options for the texture, click the &quot;Placement&quot; button. Mapping optons will fold out:
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Offset</nobr></b></td><td> Slides the texture around
</td></tr><tr><td><b><nobr> Scale</nobr></b></td><td> Scales the texture along the different axes
<p></td></tr></tr></table>
</p>

<h2>Changing The Shader of a Material</h2>
<p>Sometimes, you wish to change the shader being used by a material. In order to do so, simply expand the <b>Shader</b> drop-down in the Material inspector, and choose your new shader.  Unity will carry across any properties that the shaders share. All shaders that ship with Unity have been constructed with this in mind, so most of the time you can just replace a shader and see the effect.
</p>

<h2>Builtin Shaders</h2>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Materials and Shaders-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Materials and Shaders-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The builtin Unity shaders matrix</i>
</p>

<p>Unity comes with 30+ ready to use shaders. They can be grouped by purpose:
<dl><dt>Normal</dt><dd> Use for opaque textured objects.</dd><dt>Transparent</dt><dd> Use for partly transparent objects. Texture's alpha channel defines the level of tranparency.</dd><dt>Self-Illuminated</dt><dd> Use for objects that have light emitting parts.</dd><dt>Reflective</dt><dd> Use for opaque textured objects that reflect an environment cubemap.</dd><dt>Lightmapped</dt><dd> Use for objects that have an additional <i>lightmap</i> texture and corresponding texture coordinate channel.</dd></dl>
In each group, builtin shaders range by complexity, from the simple <i>VertexLit</i> to the complex <i>Parallax Bumped with Specular</i>.
</p>

<p>This chapter deals with how to get graphics on the screen in the final game.
</p>

<p>The components discussed here are added through the 'Add Componentâ€”&gt;Rendering' menu in the game object inspector
</p>


<h1>Light</h1>

<p>Lights will bring personality and flavor to your game. You use lights to illuminate the scenes and objects to create the perfect visual mood. Lights can be used to simulate the sun, match light, flashlights, gun-fire, or explosions, just to name a few.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Light Component</i>
</p>

<p>There are three types of lights in Unity:
</p>
<ul><li> <i>Point lights</i> shine from a location equally in all directions, like a light bulb.
</li><li> <i>Directional lights</i> are placed infinitely far away and affect everything in the scene, like the sun.
</li><li> <i>Spot lights</i> shine from a point in a direction and only illuminate objects within a cone - like the headlights of a car.
</li></ul>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The three different light types in Unity</i>
</p>

<h2>Properties</h2>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>Type</nobr></b></td><td> The current type of light object
<dl><dt>Directional</dt><dd> A light placed infinitely far away. It affects everything in the scene and can not attenuate.</dd><dt>Point</dt><dd> A light that shines equally in all directions from its location, affecting all objects within its <b>Range</b>.</dd><dt>Spot</dt><dd> A light that shines everywhere within a cone (<b>Spot Angle</b>), and a <b>Range</b>. Only objects within this region are affected by the light.</dd></dl>
</td></tr><tr><td><b><nobr>Color</nobr></b></td><td> The color of the light emitted
</td></tr><tr><td><b><nobr>Attenuate</nobr></b></td><td> Does the light diminish with increasing distance? If disabled, objects' brightness will &quot;pop&quot; as they enter and exit the light's region of influence. It can be useful to turn off when you want to do some special effects. If the light is directional, this property is ignored.
</td></tr><tr><td><b><nobr>Range</nobr></b></td><td> How far light is emitted from the center of the object.
</td></tr><tr><td><b><nobr>Spot Angle</nobr></b></td><td> If the light is a Spot light, this determines the angle of the cone in degrees.
</td></tr><tr><td><b><nobr>Cookie</nobr></b></td><td> You can assign a texture to a light. The alpha channel of this texture is used as a mask that determines how bright the light is at different places. If the light is a <b>Spot</b> or a <b>Directional</b> light, this must be a 2D texture. If the light is a <b>Point</b> light, it must be a cubemap.
</td></tr><tr><td><b><nobr>Draw Halo</nobr></b></td><td> If checked, a spherical halo of light will be drawn with a radius equal to <b>Range</b>.
</td></tr><tr><td><b><nobr>Flare</nobr></b></td><td> Optional reference to the <a href="../Components/class-Flare.html">Flare</a> that will be rendered at the light's position.
</td></tr><tr><td><b><nobr>Render Mode</nobr></b></td><td> Choose whether this light is rendered as a vertex light, pixel light, or determined automatically. For a detailed description of this tradoff, see <i>Performance Considerations</i> below. Options include
<dl><dt>Auto</dt><dd> The rendering method is determined at runtime depending on the brightness of nearby lights and current <a href="../Components/class-QualitySettings.html">QualitySettings</a>.</dd><dt>Force Pixel</dt><dd> This light is always rendered at per-pixel quality. Use this for very important effects only (e.g. headlights of a player's car).</dd><dt>Force Vertex</dt><dd> This light is always rendered as a vertex-lit light.</dd></dl>
</td></tr><tr><td><b><nobr> Culling Mask</nobr></b></td><td> Use to selectively exclude groups of objects from being affected by the light; see <a href="../ScriptingConcepts/Layers.html">Layers</a>.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>There are three basic light types in Unity. Each type can be customized to fit your needs.
</p>

<p>You can use a texture that contains an alpha channel and assign it to be projected from any of the light types. This texture then becomes the cookie. The cookie's alpha mask modulates the light amount, creating light and dark spots on surfaces. They are a great way af adding lots of complexity to a scene, and hence providing a lot of atmosphere.
</p>

<p>All builtin shaders in Unity seamlessly work with any type of light (<i>VertexLit</i> type shaders ignore light cookies though).
</p>

<h3>Point Lights</h3>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Point lights shine out from a point in all directions. They are the most common lights in computer games - typically used for explosions, light bulbs, etc.  They have an average cost on the graphics processor.
</p>

<p>Point light cookies must be cubemaps with an alpha channel. This cubemap gets projected out in all directions.
</p>


<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>


<h3>Spot Lights</h3>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-4.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-4.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Spot lights only shine in one direction, in a cone.  They are Perfect for flashlights or car headlights.  They cost the most expensive on the graphics processor.
</p>

<p>The cookie is projected down the cone of the spot light. This is good for creating an effect of light shining through a window. It is very important that the texture is black at the edges and its wrapping mode is set to <i>clamp</i>. For more info on this, see Texture
</p>


<h3>Directional Lights</h3>
<p>Directional lights are used mainly in outdoor scenes for sun &amp; moonlight.  The light affect all surfaces of objects in your scene.  They are the least expensive on the graphics processor.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-5.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-5.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>With a directional light, the cookie is projected down the center of the light's Z axis. If you want to stretch it out over a large area, set the wrapping mode to 'repeat'
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-6.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-6.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>The above is a great way to add some quick detail to large outdoor scenes. You can even slide the light slowly over the scene to give the impression of moving clouds.
</p>


<h2>Performance considerations</h2>
<p>Lights can be rendered in one of two methods: vertex lighting and per-pixel lighting. Vertex lighting only calculates the lighting at the vertices of the game models, and interpolates the lighting over the surfaces of the models. Per-pixel lights are calculated at every screen pixel, and hence are much more expensive.  Some older graphics cards only support vertex lighting.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-7.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-7.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Lights have a big impact on rendering speed - therefore a tradeoff has to be made betwen lighting quality and game speed. Since per-pixel lights are much more expensive than per-vertex lights, Unity will only render the brightest lights at per-pixel quality. The actual number of pixel lights can be set as in the <a href="../Components/class-QualitySettings.html">Quality Settings</a>. The actual lights that are rendered as pixel lights are determined on an object-by-object case. This means:
</p>
<ul><li> Huge objects with bright lights could use all the pixel lights (depending on the quality settings). If the player is far from these, nearby lights will be rendered as vertex lights.  Therefore, it is better to split huge objects up in a couple of small ones.
</li></ul>

<h2>Creating Cookies</h2>

<p>For more information on creating cookies, please see the tutorial on how to create a Spot Light cookie <a href="../Manual/HOWTO-LightCookie.html">here</a>.
</p>

<h2>Hints</h2>
<p><ul><li>
Spotlights with textures can be extremely effective for making light coming in from windows. In this case, disable attenuation, and set the range to just reach the floor.
</li><li>Low-intensity point lights are good for providing depth to a scene.
</li><li>Put a light near a particle system and assign a 'lighted' shader from the Particles group to its material. This works really well with projection textures.
</li><li>For high performance, use the <i>Vertex Lit</i> shader. This shader only does per-vertex lighting, giving a much higher throughput on low-end cards.
</li></ul>
</p>
<h1>Camera</h1>

<p>Cameras are the devices that capture and display the world to the player.  By customizing and manipulating cameras, you can make the presentation of your game truly unique.  You can have an unlimited number of cameras in a scene. They can be set to render in any order, at any place on the screen, or only certain parts of the screen.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-8.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-8.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Unity's flexible Camera object</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Clear Flags</nobr></b></td><td> Determines which parts of the screen will be cleared.  This is handy when using multiple Cameras to draw different game elements.
</td></tr><tr><td><b><nobr>Background color</nobr></b></td><td> Color applied to the remaining screen after all elements in view have been drawn and there is no skybox.
</td></tr><tr><td><b><nobr>Normalized View Port Rect</nobr></b></td><td> Four values that indicate where on the screen this camera view will be drawn, in Screen Coordinates.
</td></tr><tr><td><b><nobr>    Xmin</nobr></b></td><td>The beginning horizontal position that the camera view will be drawn.
</td></tr><tr><td><b><nobr>    Ymin</nobr></b></td><td>The beginning vertical position that the camera view will be drawn.
</td></tr><tr><td><b><nobr>    Xmax</nobr></b></td><td>The ending horizontal position that the camera view will be drawn.
</td></tr><tr><td><b><nobr>    Ymax</nobr></b></td><td>The ending vertical position that the camera view will be drawn.
</td></tr><tr><td><b><nobr>Near Clip Plane</nobr></b></td><td> The closest point relative to the camera that drawing will occur.
</td></tr><tr><td><b><nobr>Far Clip Plane</nobr></b></td><td> The furthest point relative to the camera that drawing will occur.
</td></tr><tr><td><b><nobr>Field of view</nobr></b></td><td> Width of the Camera's view angle, measured in degrees along the local Y axis.
</td></tr><tr><td><b><nobr>Is ortho graphic</nobr></b></td><td> Toggles the camera's capability to simulate perspective.
</td></tr><tr><td><b><nobr>Orthographic size</nobr></b></td><td> The viewport size of the Camera when it is Orthographic.
</td></tr><tr><td><b><nobr>Depth</nobr></b></td><td> The camera's position in the draw order. Cameras with a higher depth will be drawn on top of cameras with a lower depth value.
</td></tr><tr><td><b><nobr>Culling Mask</nobr></b></td><td> Include or omit layers of objects to be rendered by the Camera.  Assign layers to your objects in the Inspector.
</td></tr><tr><td><b><nobr>Render Target (Pro)</nobr></b></td><td> Reference to a Render Texture that will contain the output of the Camera view
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>Cameras are essential for displaying your game to the player.  They can be customized, scripted, or parented to achieve just about any kind of effect imaginable.  For a puzzle game, you might keep the Camera static for a full view of the puzzle.  For a first-person shooter, you would parent the Camera to the player character, and place it at the character's eye level.  For a racing game, you'd likely want to have the Camera follow your player's vehicle.
</p>

<p>You can create multiple Cameras and assign each one to a different depth.  Cameras are drawn from low depth to high depth.  In other words, a Camera with a depth of 2 will be drawn on top of a Camera with a depth of 1.  You can adjust the values of the <b>Normalized View Port Rectangle</b> property to resize and position the Camera's view onscreen.  This can create multiple mini-views like missile cams, map views, rear-view mirrors, etc.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-9.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-9.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Multiple Cameras making use of <b>Normalized View Port Rectangle</b></i>
</p>

<h3>Clear Flags</h3>

<p>Each Camera stores a color and depth information when it renders its view.  The portions of the screen that are not filled with a game object are empty, and will display the skybox by default.  When you are using multiple Cameras, each one stores its own color and depth information in buffers, accumulating more data as each Camera renders.  As any particular Camera in your scene renders its view, you can set the <b>Clear Flags</b> to clear different collections of the buffer information. This is done by choosing one of the four options:
</p>

<h4><span style="text-decoration:underline;">Skybox</span></h4>
<p>This is the default setting.  Any empty portions of the screen will display the current Camera's skybox.  If the current Camera has no skybox set, it will default to the skybox chosen in the <a href="../Components/class-RenderSettings.html">Render Settings</a> (found in <b>Edit -&gt; Render Settings</b>).  It will then fall back to the <b>Background Color</b>.
</p>

<h4><span style="text-decoration:underline;">Solid Color</span></h4>
<p>Any empty portions of the screen will display the current Camera's <b>Background Color</b>.
</p>

<h4><span style="text-decoration:underline;">Depth Only</span></h4>
<p>For example, if you wanted to draw a player's gun without letting it get clipped inside the environment, you would set one Camera at Depth 0 to draw the environment, and another Camera at Depth 1 to draw the weapon alone.  The weapon Camera's <b>Clear Flags</b> should be set to to &quot;depth only&quot;.  This will keep the graphical display of the environment on the screen, but discard all information about where each object exists in 3-D space.  When the gun is drawn, the opaque parts will completely cover anything drawn, regardless of how close the gun is to the wall.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-10.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-10.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The gun is drawn last, after clearing the depth buffer of the cameras before it</i>
</p>

<h4><span style="text-decoration:underline;">Don't Clear</span></h4>
<p>This mode does not clear either the color or the depth buffer.  The result is that each frame is drawn over the next, resulting in a smear-looking effect.  This isn't typically used in games, and would likely be best used with a custom shader.
</p>

<h3>Clip Planes</h3>

<p>The <b>Near</b> and <b>Far Clip Plane</b> properties determine where the Camera's view begins and ends.  The planes are laid out perpendicular to the Camera's direction and are measured from the its position.  The <b>Near plane</b> is the closest location that will be rendered, and the <b>Far plane</b> is the furthest.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-11.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-11.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Far Clip Plane set to small versus large distance</i>
</p>

<h3>Culling Mask</h3>

<p>The Culling Mask is used for selectively rendering groups of objects using Layers.  More information on using layers can be found <a href="../ScriptingConcepts/Layers.html">here</a>.
</p>

<p>Commonly, it is good practice to put your User Interface on a different layer, then render it by itself with a separate camera set to render the UI layer by itself.
</p>

<p>In order for the UI to display on top of the other Camera views, you'll also need to set the <b>Clear Flags</b> to &quot;Depth only&quot; and make sure that the UI Camera's <b>Depth</b> is higher than the other Cameras.
</p>

<h3>Normalized Viewport Rectangle</h3>

<p><b>Normalized Viewport Rectangles</b> are specifically for defining a certain portion of the screen that the current camera view will be drawn upon.  You can put a map view in the lower-right hand corner of the screen, or a missile-tip view in the upper-left corner.  With a bit of design work, you can use Viewport Rectangle to create some unique behaviors.
</p>

<p>It's easy to create a two-player split screen effect using Normalized Viewport Rectangle.  After you have created your two cameras, change player one's Ymin value to 0.5, and player two's Ymax: value to 0.5.  This will make player one's camera display from halfway up the screen to the top, and player two's camera will start at the bottom and stop halfway up the screen.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-12.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-12.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Two-player display created with Normalized Viewport Rectangle</i>
</p>

<h3>Orthographic</h3>

<p>Marking a Camera as orthographic removes all perspective from the Camera's view.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-13.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-13.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A non-orthographic and orthographic camera viewports</i>
</p>


<h3>Render Texture</h3>

<p>This feature is only available for Unity Pro licenses.  It will place the camera's view onto a <a href="../Components/class-RenderTexture.html"> Texture</a> that can then be applied to another object.  This makes it easy to create sports arena video monitors, surveillance cameras, reflections etc.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-14.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-14.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Render Texture used to create a live Arena-Cam</i>
</p>

<h2>Hints</h2>
<p><ul><li>
Cameras can be instantiated, parented, and scripted just like any other Game Object.
</li><li>To increase the sense of speed in a racing game, use a high field of view.
</li><li>Cameras can be used in physics simulation if you add a Rigidbody component.
</li><li>There is no limit to the number of Cameras you can have in your scenes.
</li><li>Orthographic cameras are great for making 3-D user interfaces
</li><li>Pro license holders have the option of rendering a Camera's view to a texture, called Render-to-Texture, for even more unique effects.
</li><li>Unity comes with pre-installed Camera scripts, found in <b>Components -&gt; Camera Control</b>.  Experiment with them to get a taste of what's possible.
</li></ul>
</p>
<h1>Skybox</h1>

<p>Skyboxes are a wrapper around your entire scene that display the vast beyond of your world.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Lighting and Rendering-15.jpg%22" --><p><table><tr><td><img class="figure" src="images/Lighting and Rendering-15.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Skybox</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Material</nobr></b></td><td> The Material used to render the skybox, which contains the 6 Skybox textures. This Material should use the Skybox shader, and each of the textures should be assigned to the proper global direction.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>Skyboxes are rendered before anything else in the scene in order to give the impression of complex scenery at the horizon. They are a box of 6 textures, one for each primary direction (+/-X, +/-Y, +/-Z).
</p>

<p>You have 2 options for implementing Skyboxes.  You can add them to an individual <a href="../Components/class-Camera.html">Camera</a> (usually the main Camera) or you can set up a default Skybox in <a href="../Components/class-RenderSettings.html">Render Settings's</a> <b>Skybox Material</b> property.  The Render Settings is most useful if you want all cameras in your scene to share the same Skybox.
</p>

<p>Adding the Skybox component to a Camera is useful if you want to override the default skybox set up in the Render Settings.  E.g. You might have two split screens and want the second camera to use a different skybox.  To add a Skybox component to a Camera, click to highlight the camera and go to <b>Component -&gt; Rendering -&gt; Skybox</b>.
</p>

<p>Unity's Standard Assets contain 6 pre setup Skybox materials. (Standard Assets/Skyboxes)
</p>

<p>If you want to create a new Skybox see <a href="../Manual/HOWTO-UseSkybox.html">here</a>.
</p>

<h2>Hints</h2>
<p><ul><li>
If you have a skybox assigned to a camera, make sure to set the camera's clear mode to Skybox
</li></ul>
</p>



<p>Unity has functionality for making in-game Head-Up-Displays and 2D menus, using the GUI Texture and GUI Text components. A complete GUI is made up from several GUI components.
</p>

<p>To create a GUI, you must first attach a GUI Layer component to the main camera. Then add GUI Texture and GUI Text objects to the scene. The x and y components of the GUI objects' position determine the position on the screen with (0,0) being the bottom left and (1,1) the top right corner of the screen.
</p>

<h1>GUI Texture</h1>

<p>GUI Textures are displayed as flat images in 2D. They are made especially for User Interface elements, buttons, or decorations.  Their positioning and scaling is performed along the x and y axes only, and they are measured in Screen Coordinates, rather than World Coordinates.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Making a GUI-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Making a GUI-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The GUI Texture</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Texture</nobr></b></td><td> Reference to the <a href="../Components/class-Texture2D.html">Texture2D</a> that will be used as the texture's display.
</td></tr><tr><td><b><nobr>Color</nobr></b></td><td> Value that will tint the <b>Texture</b> drawn on screen.
</td></tr><tr><td><b><nobr>Pixel Inset</nobr></b></td><td> Used for pixel-level control of the scaling and positioning of the GUI Texture. All values are measured relative to the position of the GUI Texture's <b>Transform</b>.
</td></tr><tr><td><b><nobr>    Xmin</nobr></b></td><td> Left-most pixel position of the texture.
</td></tr><tr><td><b><nobr>    Ymin</nobr></b></td><td> Bottom-most pixel position of the texture.
</td></tr><tr><td><b><nobr>    Xmax</nobr></b></td><td> Right-most pixel position of the texture.
</td></tr><tr><td><b><nobr>    Ymax</nobr></b></td><td> Top-most pixel position of the texture.
</td></tr><tr><td><b><nobr>Left Border</nobr></b></td><td> Number of pixels from the left that are not affected by scale.
</td></tr><tr><td><b><nobr>Right Border</nobr></b></td><td> Number of pixels from the right that are not affected by scale.
</td></tr><tr><td><b><nobr>Top Border</nobr></b></td><td> Number of pixels from the top that are not affected by scale.
</td></tr><tr><td><b><nobr>Bottom Border</nobr></b></td><td> Number of pixels from the bottom that are not affected by scale.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>To create a gui texture
</p>
<ol><li> Select a texture in the project view
</li><li> Choose <b>Game Object -&gt; Create Other -&gt; GUI Texture</b>
</li></ol>


<p>GUI Textures are perfect for presenting game interface backgrounds, buttons, or other elements to the player.  Through scripting, you can easily provide visual feedback for different &quot;states&quot; of the texture &mdash; when the mouse is hovering over the texture, or is actively clicking it for example.  Here is the basic breakdown of how the GUI Texture is calculated:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Making a GUI-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Making a GUI-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Here's a real-world example of GUI Texture at work from Unity forum member Bampf's game <span style="text-decoration:underline;">Pawns</span>.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Making a GUI-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Making a GUI-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h3>Borders</h3>

<p>The number of pixels that will not scale with the texture at each edge of the image.  As you rarely know the resolution your game runs in, chances are your GUI will get scaled. Some GUI textures have a border at the edge that is meant to be an exact number of pixels. In order for this to work, set the border sizes to match those from the texture.
</p>

<h3>Pixel Inset</h3>

<p>The purpose of the <b>Pixel Inset</b> is to prevent textures from scaling with screen resolution, and keeping thim in a fixed pixel size. This allows you to render a texture without any scaling.  This means that players who run your game in higher resolutions will see your textures in smaller areas of the screen, allowing them to have more screen real-estate for your gameplay graphics.
</p>

<p>To use it effectively, you need to set the scale of the GUI Texture's <b>Transform</b> to 0, 0, 0. Now, the <b>Pixel Inset</b> is in full control of the texture's size and you can set the <b>Pixel Inset</b> values to be the exact pixel size of your texture.
</p>

<h2>Hints</h2>
<p><ul><li>
<b>GUI Textures</b> are great for making menu screens, or pause/escape menu screens.
</li><li>You should use <b>Pixel Inset</b> on any GUI Textures that you want to be a specific number of pixels for the width and height.
</li></ul>
</p>


<h1>GUI Text</h1>

<p>GUI Text displays text of any font you import in screen coordinates.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Making a GUI-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/Making a GUI-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The GUI Text</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Text</nobr></b></td><td> The string of text to display.
</td></tr><tr><td><b><nobr>Anchor</nobr></b></td><td> Which point of the text shares the position of the Transform.
</td></tr><tr><td><b><nobr>Alignment</nobr></b></td><td> How multiple lines are aligned within the GUIText.
</td></tr><tr><td><b><nobr>Line Spacing</nobr></b></td><td> How much space will be in-between lines of text.
</td></tr><tr><td><b><nobr>Tab Size</nobr></b></td><td> How much space will be inserted for a tab '\t' character. As a multiplum of the space character offset.
</td></tr><tr><td><b><nobr>Font</nobr></b></td><td> The <a href="../Components/class-Font.html">font</a> to use when rendering the text.
</td></tr><tr><td><b><nobr>Material</nobr></b></td><td> Reference to the Material containing the characters to be drawn. If set, this property overrides the one in the <a href="../Components/class-Font.html">Font</a> asset.
</td></tr><tr><td><b><nobr>Pixel Correct</nobr></b></td><td> If enabled, all text characters will be drawn in the size of the imported font texture. If disabled, the characters will be resized based on the transform's scale.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>GUI Texts are used to print text onto the screen in 2D. The camera has to have a <a href="../Components/class-GUILayer.html">GUI Layer</a> attached in order to render the text.  Cameras include a GUI Layer by default, so don't remove it if you want to display a GUI Text.  GUI Texts are positioned using only the X and Y axes.  Rather than being positioned in World Coordinates, GUI Texts are positioned in Screen Coordinates, where (0,0) is the bottom-left and (1,1) is the top-right corner of the screen
</p>

<p>To import a font see the <a href="../Components/class-Font.html">Font class</a>.
</p>

<h3>Pixel Correct</h3>

<p>By default Fonts are rendered pixel correct. This makes them look crisp and they will stay the same size in pixels independent of the screen resolution.
</p>

<h2>Hints</h2>
<p><ul><li>
When entering text into the <b>Text</b> property, you can create a line break by holding <i>Alt</i> and pressing <i>Return</i>.
</li><li>You can download free true type fonts from <a class="wiki"  href="http://www.1001freefonts.com/fonts/afonts.htm">http://www.1001freefonts.com/fonts/afonts.htm</a> (download the windows fonts since they contain true type fonts).
</li><li>If you are scripting the <b>Text</b> property, you can add line breaks by inserting the escape character &quot;\n&quot; in your strings.
</li></ul>
</p>




<p>A large part of making a game is assigning all your source files to world objects. This goes for textures, models, sound effects and behaviour scripts. Inside Unity, you have quick access to all the files that makes up your game using the Project view:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Assets-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Assets-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>This view shows the organization of the files in your project folder. Whenever you change one of your asset files, changes are immediately reflected into your game!
</p>

<p>In order to import an asset file in your game, you simple move the file into the Assets folder in the Finder, and it will get imported into Unity. To assign it to objects in your game scenes, simply drag the files from the project window over your objects in the hierarchy or scene views.
</p>

<p>What exactly happens depends on the type of file:
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Textures.html">Textures</a></li><li class="toclevel"><a href="../Manual/Imported Scenes.html">Imported Scenes</a></li><li class="toclevel"><a href="../Manual/Sound files.html">Sound files</a></li><li class="toclevel"><a href="../Manual/Prefabs.html">Prefabs</a></li></ul>
</p>

<h2>Hints</h2>

<ul><li> Rename and move files to your heart's content inside Unity; nothing will break.
</li><li> <b>Never</b> rename or move anything from the Finder or another program; everything will break. In short, Unity stores lots of metadata for each asset (things like import settings, cached versions of compressed textures, etc.) and if you move a file externally, Unity can no longer associate metadata with the moved file.
</li></ul>



<p>Textures are what brings your worlds to life! They are image or movie files that you put on your objects. As they are so important, they have a lot of properties. If reading this for the first time, jump down to <i>Details</i>, and return to the actual settings when you need a reference.
</p>

<p>Which shaders you use for your objects put specific requirements on your textures, but the basic principle is that you can put any image file inside your project. If it meets the size requirements (specified below), it will get imported and optimized for game use.
</p>

<p>This extends to multi-layer Photoshop or TIFF files - they are flattened on import, so there is no size penalty for your game.
</p>

<h2>Properties</h2>
<p>The texture inspector looks a bit different from most others:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Textures-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Textures-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>The top section contains a few settings, and the bottom part contains a texture preview. The changes you make to the bottom part only affect the display, and not the texture itself.
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Filtering Mode</nobr></b></td><td> Selects how the texture is filtered when it gets stretched by 3D transformations.

<dl><dt>No Filtering</dt><dd> The texture becomes blocky up close</dd><dt>Bilinear</dt><dd> The texture becomes blurry up close</dd><dt>Trilinear</dt><dd> Like Bilinear, but the texture also blurs between the different mip levels...</dd></dl>

</td></tr><tr><td><b><nobr>Anisotropy</nobr></b></td><td>   Increases texture quality when viewing the texture at a steep angle. Good for floor textures
</td></tr><tr><td><b><nobr>Edge mode</nobr></b></td><td> Selects how the texture behaves when tiled
<dl><dt>Repeat</dt><dd> The texture repeats (tiles) itself.</dd><dt>Clamp</dt><dd>  The texture's edges get stretched. </dd></dl>

<p></td></tr></tr></table>
</p>

<h2>Import Settings</h2>

<p>Textures all come from image files in your project folder. How they are imported is specified by the texture's import settings. You change these by selecting the file texture in the project window and clicking the import settings button on the toolbar above:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Textures-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Textures-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>This brings up the import settings dialog:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Textures-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Textures-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Max. Texture Size</nobr></b></td><td> The maximum imported texture size. A lot of artists prefer to work with huge textures - scale the texture down to a suitable size with this.
</td></tr><tr><td><b><nobr>Texture Format</nobr></b></td><td> What internal representation is used for the texture. This is a tradeoff between size and quality. In the examples below we show the final size of a in-game texture of 256 by 256 pixels.

<dl><dt>RGB Compressed DXT1</dt><dd> Compressed RGB texture. This is the most common format for diffuse textures. 4 bits per pixel (32 KB for a 256x256 texture).</dd><dt>RGBA Compressed DXT3</dt><dd> Compressed RGBA texture. Provides a different compression method for alpha. Usually DXT5 looks better. 1 byte/pixel (64 KB for a 256x256 texture).</dd><dt>RGBA Compressed DXT5</dt><dd> Compressed RGBA texture. This is the main format used for diffuse &amp; specular control textures. 1 byte/pixel (64 KB for a 256x256 texture).</dd><dt>RGB 16 bit</dt><dd> 65 thousand colors with no alpha. Compressed DXT formats use less memory and usually look better. 128 KB for a 256x256 texture.</dd><dt>RGB 24 bit</dt><dd> Truecolor but without alpha. 192 KB for a 256x256 texture.</dd><dt>Alpha 8 bit</dt><dd> High quality alpha channel but without any color. 64 KB for a 256x256 texture.</dd><dt>RGBA 16 bit</dt><dd> Low-quality truecolor. Has 16 levels of red, green, blue and alpha. Compressed DXT3/5 formats use less memory and usually look better. 128 KB for a 256x256 texture.</dd><dt>RGBA 32 bit</dt><dd> Truecolor with alpha - this is the highest quality. At 256 KB for a 256x256 texture, this one is expensive. Most of the time, _DXTC5_ offers sufficient quality at a much smaller size. The main place this is used is for bump maps, as DXTC compression often carries a huge quality loss.</dd></dl>
</td></tr><tr><td><b><nobr>Build Alpha From Grayscale</nobr></b></td><td> If enabled, an alpha transparency channel will be generated by the image's existing values of light &amp; dark.
</td></tr><tr><td><b><nobr>Generate Cube Map</nobr></b></td><td> Generates a cubemap from the texture using different generation methods.
</td></tr><tr><td><b><nobr>Generate Mip Maps</nobr></b></td><td> Select this to enable mip-map generation. Mip maps are smaller versions of the texture that gets used when the texture is very small on screen. For more info, see Mip Maps, below.
</td></tr><tr><td><b><nobr>Correct Gamma</nobr></b></td><td> Select this to enable per-mip-level gamma correction.
</td></tr><tr><td><b><nobr>Border Mip Maps</nobr></b></td><td> Select this to avoid colors seeping out to the edge of the lower Mip levels. Used for light cookies (see below).
</td></tr><tr><td><b><nobr>Mip Map Filtering</nobr></b></td><td> 3 ways of mip map filtering is available to optimize image quality
<dl><dt>Box</dt><dd> The simplest way to fade out the mipmaps - the mip levels become smoother and smoother as they go down in size.</dd><dt>Kaiser</dt><dd> A sharpening Kaiser algorithm is run on the mip maps as they go down in size.</dd></dl>
By default, Box mode is selected. If your textures are to blurry in the distance, try some of the other options and see if they work. This is not an exact science, so play around and see what works for different textures.

</td></tr><tr><td><b><nobr>Fade Out Mips</nobr></b></td><td> Enable this to make the mipmaps fade to gray the mip levels progress. This is used for detail maps.
</td></tr><tr><td><b><nobr>Fade Out start</nobr></b></td><td> The first mip level to begin fading out at.
</td></tr><tr><td><b><nobr>Fade Out End</nobr></b></td><td> The mip level where the texture is completely grayed out
Generate  Bump Map</td></tr><tr><td><b><nobr>Bumpyness</nobr></b></td><td> Increase the amount of bumpyness.
</td></tr><tr><td><b><nobr>Filtering</nobr></b></td><td> Determine how the bumpyness is calculated
<dl><dt>Standard</dt><dd> This generates normal maps that are smoother than with a sobel filter</dd><dt>Sobel</dt><dd> The solber filter generates normal maps that are sharper than Standard. </dd></dl>

<p></td></tr></tr></table>
</p>

<h2> Details</h2>

<h3> Supported Formats</h3>
<p>Unity can read the following formats: PSD, TIFF, JPG, TGA, GIF, PNG,  BMP, IFF, PICT. Of these, the 2 really interesting ones are PSD &amp; TIFF - Unity can read multi-layer PSD &amp; TIFF files just fine. They are flattened automatically on import, so there is no penalty from using them. This is important as it allows you to just have one copy of your textures that you can use from Photoshop, through your 3D modelling app and into Unity.
</p>

<h3> Texture Sizes</h3>
<p>In order for textures to work in real-time engines, their size must be a power of two on the sides. The allowed sizes are as follows: 2, 4, 8, 16, 32, 64, 128, 256, 512 or 1024 pixels. The textures do not need to have the same size horizontally and vertically, but each side have one of lengths mentioned above.
</p>

<h3> UV Mapping</h3>
<p>When mapping a 2D texture on to a 3D model, some sort of wrapping is done. This is called UV mapping and is done in your 3D modelling app. Inside Unity, you can scale and move the texture using <a href="../Components/class-Material.html">Materials</a>. Scaling bump &amp; detail maps are especially useful
</p>

<h3> Mip Maps</h3>
<p>Mip Maps are a list of progressively smaller versions of an image, used optimise performance on real-time 3D engines. Object that are far away from the camera use the smaller textures. Using mip maps uses 33% more memory, but not using mipmaps can be a huge performance loss. You should always you mipmaps for in-game textures; the only exceptions are textures that will never be minified (e.g. GUI textures).
</p>

<h3> Bump Maps</h3>
<p>Bump maps are used by bump map shaders to make low-polygon models look as if they contain more detail. Unity uses normal maps encoded as RGB images. You also have the option to generate a normal map from a grayscale height map image.
</p>

<h3> Detail Maps</h3>
<p>If you want to do a terrain, you normally use your main texture to show where there are grass, rocks sand, etc... If your terrain has a decent size, you will end up with a very blurry terrain. <a href="../Manual/HOWTO-UseDetailTexture.html">Detail textures</a> hide this fact by fading in small details as your main texture get up close.
</p>

<p>When drawing detail textures, a neutral gray is invisible, white makes the main texture twice as bright and black makes the main texture completely black.
</p>

<h3> Cube Maps</h3>
<p>If you want to use texture for reflection maps (e.g. use <i>Reflective</i> builtin shaders), you need to use <a href="../Components/class-CubemapTexture.html">Cubemap Textures</a>.
</p>

<h3> Light Cookies</h3>
<p>An interesting way to add a lot of visual detail to your scenes is to use cookies - greyscale textures you use to control the precise look of in-game lighting. This is fantastic for making moving clouds and giving an impression of dense foilage. The <a href="../Components/class-Light.html">Light</a> page has more info on all this, but the main thing is that for textures to be usable for cookies, the following properties need to be set:
</p>

<p>For <i>spotlight</i> cookies, use the following settings:
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Texture Format</nobr></b></td><td> Any setting that has an alpha channel</td></tr><tr><td><b><nobr>Build Alpha from RGB Grayscale</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Generate Mip Maps</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Border Mip Maps</nobr></b></td><td> Enabled
</td></tr></tr></table>
You should keep the edges of you cookie texture solid black in order to get the proper effect. In the texture inspector, set the Edge Mode to <b>Clamp</b>.
</p>

<p>For <i>directional</i> lights, use the following settings:
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Texture Format</nobr></b></td><td> Any setting that has an alpha channel</td></tr><tr><td><b><nobr>Build Alpha from RGB Grayscale</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Generate Mip Maps</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Border Mip Maps</nobr></b></td><td> Disabled
</td></tr></tr></table>
This texture will tile, so in the texture inspector, you must set the Edge Mode to <b>Repeat</b>.
</p>

<p>For <i>point</i> lights, you need to use <b>Cube Maps</b>. To generate one, either make six textures and assign them as detailed in <a href="../Components/class-CubemapTexture.html">Cubemap Textures</a> or generate on with the following settings:
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Texture Format</nobr></b></td><td> Any setting that has an alpha channel</td></tr><tr><td><b><nobr>Generate Cube Map</nobr></b></td><td> Any other setting than <b>None</b>.
</td></tr><tr><td><b><nobr>Build Alpha from RGB Grayscale</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Generate Mip Maps</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Border Mip Maps</nobr></b></td><td> Disabled
</td></tr></tr></table>
</p>



<p>Meshes make up a large part of your 3D worlds. You don't build your meshes in Unity, but in another application.
</p>

<p>In Unity, we have done everything in our power to make this process as simple as possible. There are a lot of details, but the following should hold:
</p>

<h1> How do I import objects from my 3D app?</h1>

<p>Unity supports importing from a lot of 3D applications. Choose the one you're working with below:
</p>
<ul><li> <a href="../Manual/HOWTO-ImportObjectMaya.html">Maya</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectCinema4D.html">Cinema 4D</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectMax.html">3D Studio MAX</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectCheetah3D.html">Cheetah3D</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectModo.html">Modo</a>
</li><li> <a href="../Manual/HOWTO-importObjectLightwave.html">Lightwave</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectBlender.html">Blender</a>
</li></ul>

<h2> Other applications</h2>
<p>Unity can read <b>.FBX</b>, <b>.3DS</b>, <b>.dxf</b> and <b>.obj</b> files, so if your program can export to this format you're home free. FBX exporters for popular 3D packages can be found <a class="wiki"  href="http://autodesk.com/fbx">here</a>.
</p>

<h2>Hints</h2>
<ul><li> Store textures in a folder called <b>Textures</b> next to the exported mesh. This will guarantee that Unity can always find the Texture and automatically connect the Texture to the Material. For more information, see the <a href="../Components/class-Texture2D.html">Textures</a> reference.
</li></ul>

<h2>See Also</h2>
<ul><li> <a href="../Manual/HOWTO-bumpmap.html">How do I use bump maps?</a>
</li><li> <a href="../Components/class-Mesh.html">Mesh Import Settings</a>
</li><li> <a href="../Manual/HOWTO-FixZAxisIsUp.html">Fixing a mesh that has the z-axis facing upwards</a>
</li></ul>

<h2> Textures</h2>
<p>Unity will attempt to hook up materials to your imported scenes - Basically, just place textures in a folder called 'Textures' next to the sccene file, or in any folder above it.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Imported Scenes-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Imported Scenes-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h2> Import settings.</h2>
<p>To access the importing settings for a 3D scene file, click the <b>Settings</b> button in the project window, or control-click a scene file and select <b>Import Settings...</b>.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Imported Scenes-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Imported Scenes-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Share Materials</nobr></b></td><td> Enable this to generate material files near the found texture files. When enabled,  different scenes will share the same material settings when they use the same textures. For the precise rules, see Material Generation below.
</td></tr><tr><td><b><nobr>One Material for...</nobr></b></td><td> This will generate materials per scene, so only this scene uses them.
</td></tr><tr><td><b><nobr>Don't generate materials</nobr></b></td><td> This will not generate materials at all.
</td></tr><tr><td><b><nobr>Mesh Scale Factor</nobr></b></td><td> Unity's physics system expects 1 meter in the game world to be 1 unit in the imported file. If you like to model at a different scale, this is the place to fix it.
</td></tr><tr><td><b><nobr>Meshes have colliders</nobr></b></td><td> If this is enabled, your meshes will be imported with Mesh Colliders automatically attached. This is recommended for background geometry, but never for geometry you move about. For more info see Colliders below.
</td></tr><tr><td><b><nobr>Automatically calculate normals</nobr></b></td><td> Enable this to automatically generate normals for the imported geometry. If enabled, the <b>Smoothing Angle</b> sets how sharp an edge has to be to be treated as a hard edge.
</td></tr><tr><td><b><nobr>Swap primary and secondary uv channel</nobr></b></td><td> Use this if Lightmapped shaders pick up wrong UV channels.
</td></tr><tr><td><b><nobr>Animation options</nobr></b></td><td> Controls how animations are imported.
<dl><dt>No Animation</dt><dd> No animation or skinning is imported.</dd><dt>Animation in root</dt><dd> Animations are stored in the scene's transform root objects. Use this when animating anything that has a hierarchy.</dd><dt>Animation in original roots</dt><dd> Animations are stored in root objects of your animation package (these might be different from root objects in Unity).</dd><dt>Animation stored in nodes</dt><dd> Animations are stored together with the objects they animate. Use this when you have a complex animation setup and want full scripting control.</dd></dl>
</td></tr><tr><td><b><nobr>Bake IK &amp; simulation</nobr></b></td><td> When using IK or simulation in your animation package, enable this. Unity will convert to FK on import.
</td></tr><tr><td><b><nobr>Keyframe reduction</nobr></b></td><td> Perform keyframe reduction on imported animations. You should always use this, as it takes less memory and is faster.
</td></tr><tr><td><b><nobr>Split animation into multiple clips</nobr></b></td><td> If you have multiple animations in a single file, here you can split it into multiple clips.
<p></td></tr></tr></table>
</p>

<h3> Material Generation</h3>

<p>Materials are found based on the following rules:
</p>

<ul><li> Unity gets the name of the main diffuse material bound to the objects in the scene.
</li><li> Unity looks for a material with this name in a Folder called 'Materials' next to the scene.
</li><li> Unity goes up the project folders, looking for the Material in each 'Materials' folder along the way.
</li></ul>

<p>If Unity can't find the Material, it tries to create one from the texture:
</p>

<ul><li> Unity checks for a texture with the correct name in the same folder as the scene.
</li><li> Unity checks for a texture with the correct name in a folder called 'Textures' next to the scene.
</li><li> Unity goes up the project folders, looking for the correct texture in each 'Textures' folder along the way.
</li><li> If Unity finds the texture, it creates a 'Materials' folder next to it and creates a material in there.
</li></ul>

<h3> Colliders</h3>

<p>Unity features two primary types of colliders: Mesh colliders and Primitive colliders. Mesh colliders are imported together with your geometry and are used for background objects. When you enable <b>Meshes Have Colliders</b> in the import settings, the mesh becomes solid as far as the physics system is concerned.
</p>

<p>If you are moving the object around (a car for example), you can not use mesh colliders. Instead, you will have to use primitive colliders. In this case you should disable the <b>Meshes Have Colliders</b> setting.
</p>

<h3> Animations</h3>

<p>Animations are automatically imported from the scene. For more details about animation import options see <a href="../Manual/Character-Animation.html">Character-Animation</a> chapter.
</p>

<h2>Hints</h2>

<p><ul><li>
Merge your meshes together. Make them share materials and textures. This has a huge performance benefit.
</li><li>If you need to set up your objects further in Unity (adding physics, scripts or other coolness), save yourself a world of pain and name your objects properly in your 3D application. Working with lots of <i>pCube17</i> or <i>Box42</i>-like objects is not fun.
</li><li>Make your meshes be centered on the world origin in your 3D app. This will make them easier to place in Unity.
</li></ul>
</p>



<p>Adding sound to a game is one of the final touches that make a game feel like a complete product. Be it nerve-wrecking sound effects or thumping background music, they are seen by Unity as Audio Clips.
</p>

<p>See the <a href="../Manual/Sound.html">Sound chapter</a> in the Game Logic section of this manual for more information on how to use sound in Unity.
</p>

<h1>Audio Clip</h1>

<p>Audio Clips are used by <a href="../Components/class-AudioSource.html">Audio Sources</a> to represent the audio asset imported into Unity.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Sound files-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Sound files-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Audio Clip</i>
</p>

<p>Audio Clips just work.  The only thing you should have to do with them is reference them from within <a href="../Components/class-AudioSource.html">Audio Sources</a>.
</p>

<h2>Properties</h2>
<p>Sound assets only have 3 read-only properties.
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Format </nobr></b></td><td> The format the sound is stored in. Unity supports 4 raw formats and one compressed.
<dl><dt>Mono 8 bit</dt><dd> 8 bit uncompressed mono PCM audio</dd><dt>Mono 16 bit</dt><dd> 16 bit uncompressed mono PCM audio</dd><dt>Stereo 8 bit</dt><dd> 8 bit uncompressed stereo PCM audio</dd><dt>Stereo 16 bit</dt><dd> 16 bit uncompressed stereo PCM audio</dd><dt>Ogg Vorbis</dt><dd> Ogg Vorbis encoded stereo or mono audio</dd></dl>
</td></tr><tr><td><b><nobr>Length</nobr></b></td><td> The duration of the sound file in seconds.
</td></tr><tr><td><b><nobr>Frequency</nobr></b></td><td> The sampling frequency of the file.
</td></tr></tr></table>
</p>

<h2>Supported sound formats</h2>
<p>Unity currently supports the following file formats:
</p>

<p><dl><dt><b>AIFF</b></dt><dd> Both mono and stereo. The sound will be stored as-is inside the player-data. No compression will be attempted.</dd><dt><b>WAV</b></dt><dd> Both mono and stereo. The sound will be stored as-is inside the player-data. No compression will be attempted.</dd><dt><b>MP3</b></dt><dd> Mono and stereo. Note that the audio will be uncompressed in the editor and stored uncompressed in the player. If you want to conserve space, use Ogg Vorbis files instead.</dd><dt><b>Ogg Vorbis</b></dt><dd> Both mono and stereo. The file will be stored compressed in the player-data and decompressed on the fly. </dd></dl>
</p>

<h2>Hints</h2>
<p><ul><li>
Stereo sounds are always played as-is. If you want to use attenuation and other 3D audio effects, use mono sounds.
</li><li>You can get an Ogg Vorbis encoder here <a class="wiki"  href="http://www.nouturn.com/oggdrop/">http://www.nouturn.com/oggdrop/</a>
</li></ul>
</p>





<p>Prefabs are reusable game objects that are stored in the library. They can be inserted into many scenes, and any changes to the source prefab is immediately reflected in all scenes through the project.
</p>

<p>Prefabs are groups/hierarchies of game objects which can be instantiated.
</p>

<h2>Creating Prefabs</h2>
<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Select the folder you want to create the prefab in.
</li><li> Choose <b>Assets-&gt;Create-&gt;Prefab</b> from the main menu, or <b>Create-&gt;Prefab</b> from the project view context menu.
</li><li> Drag&amp;Drop a game object from the hierarchy view on the created prefab in the project view.
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>This will copy the dragged game objects - including it's transform hierarchy - into the prefab and make the game object in the hierarchy view inherit from the prefab.
</p>

<h2>Instantiating Prefabs</h2>
<p>To copy a prefab into a scene, simply drag the prefab back into the scene view or the hierarchy pane. This copies all game objects in the prefab into the scene. These game objects now inherit from the prefab.
</p>

<p>Inheritance means that whenever the Prefab changes, changes are copied to the inheriting objects in the scene.
</p>

<p>All properties of inherited game objects have an override flag, shown as a checkbox in the inspector. If the override flag is set, changes in the Prefab will not affect this property, allowing you to make local modifications to game objects. The override flags are automatically set when you change the properties of the game object.
</p>

<p>There are some limitations to the changes you can make to inherited game objects. These are:
</p>

<ul><li> You cannot add a new component to an inheriting game object
</li><li> You cannot remove a component from an inheriting game object
</li><li> You cannot attach other game objects as children of an inheriting game object.
</li></ul>

<p>If you do any of these things, unity will ask you if you really want to disconnect the game object from its prefab. When a game object has been disconnected from its prefab, changes to the prefab will no longer affect the game object in the scene.
</p>

<p>You can later reconnect the game object to the Prefab.
</p>

<h2>Uploading Changes</h2>
<p>When creating or editing complex prefabs, it makes sense to instantiate them in the scene and edit them there. Once you are done, select the root game object and choose <b>Game Object-&gt;Upload changes to Prefab</b> from the main menu. All your changes are then copied back to the prefab, and copied to any other inheriting objects in the scene.
</p>

<p>You can also use drag &amp; drop to upload your changes: Simply drag the game objects back to the prefab it came from.
</p>

<p>Uploading changes into a prefab can cause unwanted data loss if you drag the wrong gameobject into it, since the changes are immediately copied into any inheriting GameObjects. Thus Upload changes to prefab only works when the operation seems to be safe. Drag&amp;Drop asks you if you really want to perform a drag if it seems like you are about to change a prefab that might cause data loss.
</p>

<p>It is important that you change and upload an inherited game object and not any game object that never had a connection to the Prefab. If you do, any other inherited game objects will have their overriden values lost. (This is especially annoying for Transform positions)
</p>

<h2>Connecting game objects to prefabs</h2>
<p>To make a game object in a scene connect to a prefab, hold alt and drag the prefab onto the game object. You can drag onto a game object only in the hierarchy view. After the drag the game object you dragged upon will inherit from the dragged prefab. The operation will not change the prefab at all, but add or remove components and child game objects from the game object you dragged upon.
</p>

<h2>Importing Prefabs</h2>
<p>When importing meshes, unity automatically generates prefabs out of those meshes.
Thus when you instantiate the prefab in unity and then change the imported scene in your 3d art package, all changes will be reflected in all instantiated prefabs.
</p>


<p>Sometimes you want to add scripts or components to the imported mesh and at the same time be able to place it several times in the scene quickly. For this you have to create another prefab:
<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Drag the prefab generated from eg. an fbx file from the project view into the scene view or hierarchy view.
</li><li> Modify the game object to your liking, add scripts, components etc.
</li><li> Create a new prefab. Choose <b>Assets-&gt;Create-&gt;Prefab</b> from the main menu, or <b>Create-&gt;Prefab</b> from the project view context menu.
</li><li> Drag the game object from the hierarchy view on the prefab.
</li></ol>

</div></div></td></tr></table>
</p>

<p>A game is not only fancy graphics. Interactivity requires some added functionality. This is where the Game Logic kicks in.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Physics.html">Physics</a></li><li class="toclevel"><a href="../Manual/Animation.html">Animation</a></li><li class="toclevel"><a href="../Manual/Character-Animation.html">Character-Animation</a></li><li class="toclevel"><a href="../Manual/Sound.html">Sound</a></li><li class="toclevel"><a href="../Manual/Input.html">Input</a></li><li class="toclevel"><a href="../Manual/Scripting.html">Scripting</a></li></ul>
</p>



<p>Unity has the next-generation Ageia PhysX physics engine built-in. This allows for unique emergent behaviour and is generally very cool.
</p>

<h2>Basics</h2>
<p>To put an object under physics control, simply add a Rigidbody to it. When you do this, the object will be affected by gravity, and can collide with other objects in the world.
</p>


<h1>Rigidbody</h1>
<p>Rigidbodies are the gateway for applying physics to your objects. The Rigidbody can receive forces and torque to make your objects move in a realistic way.  Any GameObject must contain a Rigidbody to be influenced by gravity, act under added forces via scripting, or interact with other objects through the Ageia physX physics engine.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A GameObject with a Rigidbody component attached</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Mass</nobr></b></td><td> The weight of the object. Keep this below 1 for the best stability.
</td></tr><tr><td><b><nobr>Drag</nobr></b></td><td> How much air resistance affects the object when moving from forces. 0 means no air resistance, and infinity makes the object stop moving immediately.
</td></tr><tr><td><b><nobr>Angular Drag</nobr></b></td><td> How much air resistance affects the object when rotating from torque. 0 means no air resistance, and infinity makes the object stop rotating immediately.
</td></tr><tr><td><b><nobr>Use Gravity</nobr></b></td><td> If checked, the object is affected by gravity.
</td></tr><tr><td><b><nobr>Is Kinematic</nobr></b></td><td> If checked, the object will not be driven by the physics engine, but can only be manipulated by its Transform. This is useful for moving platforms or if you want to animate a Rigidbody that has a Hinge Joint attached.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>Rigidbodies allow your GameObjects to act under control of the physics engine.  This opens the gateway to realistic collisions, varied types of joints, and other very cool behaviors.  Manipulating your objects by adding forces to a Rigidbody creates a very different feel and look than adjusting the Transform property directly.  Generally, you shouldn't manipulate the Rigidbody and the Transform of the same object &mdash; just one or the other.
</p>

<p>The biggest difference between manipulating the Transform or the Rigidbody is the use of forces.  Rigidbodies can receive forces and torque, but Transforms cannot.  Transforms can be translated and rotated, but this is not the same as using physics. You'll notice the distinct difference when adding you try it for yourself.  Adding forces/torque to the Rigidbody will actually change the object's position and rotation of the Transform component.  This is why you should only be using one or the other.  Changing the Transform while using phyics could cause problems with collisions and other calculations.
</p>

<p>Rigidbodies must be explicitly added to your game object before they will be affected by the physics engine.  You can add a Rigidbody to your selected object from <b>Components -&gt; Dynamics -&gt; Rigidbody</b>. Now your object is physics-ready; it will fall under gravity and can receive forces via scripting, but you may want to add a Collider or a Joint to get it to behave exactly how you want.
</p>

<h3> Parenting</h3>
<p>When an object is under physics control, it moves semi-independently of the way its transform parents move. If you move any parents, they will pull the Rigidbody child along with them. However, the Rigidbodies will still fall down due to gravity and react to collision detection.
</p>

<h3> Scripting</h3>
<p>To control your Rigidbodies, you will primarily use scripts to add forces or torque. You do this by calling <a class="wiki"  href="../ScriptReference/Rigidbody.AddForce.html">AddForce</a> and <a class="wiki"  href="../ScriptReference/Rigidbody.html#AddTorque">AddTorque</a> on the object's Rigidbody.  Remember that you shouldn't be directly altering the object's Transform when you are using physics.
</p>

<h3>Animation</h3>
<p>For some situations, mainly creating ragdoll effects, it is neccessary to switch control of the object between animations and physics. For this purpose Rigidbodies can be marked <a class="wiki"  href="http://www.unity3d.com/Documentation/ScriptReference/Rigidbody.html#isKinematic">Kinematic</a>. While the Rigidbody is marked Kinematic, it will not be affected by collisions, forces, or any other part of the physics engine. This means that you will have to control the object by manipulating the <a href="../Components/class-Transform.html">Transform</a> component directly.  Kinematic Rigidbodies will affect other objects, but they themselves will not be affected by physics. For example, Joints which are attached to Kinematic objects will constrain any other Rigidbodies attached to them and Kinematic Rigidbodies will affect other Rigidbodies through collisions.
</p>

<h3>Colliders</h3>
<p>Colliders are another kind of component that must be added alongside the Rigidbody in order to allow collisions to occur.  If two Rigidbodies bump into each other, the phyics engine will not calculate a collision unless both objects also have a Collider attached.  Collider-less Rigidbodies will simply pass through each other during physics simulation.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A Rigidbody with a Collider component attached</i>
</p>

<p>Add a collider with the Component -&gt; Dynamics menu.  View the Component page of any individual Collider for more specific information:
</p>
<ul><li><a href="../Components/class-BoxCollider.html">Box Collider</a> - primitive shape of a cube
</li><li><a href="../Components/class-SphereCollider.html">Sphere Collider</a> - primitive shape of a sphere
</li><li><a href="../Components/class-CapsuleCollider.html">Capsule Collider</a> - primitive shape of a capsule
</li><li><a href="../Components/class-MeshCollider.html">Mesh Collider</a> - creates a collider from the object's mesh, cannot collide with another Mesh Collider
</li><li><a href="../Components/class-WheelCollider.html">Wheel Collider</a> - specifically for creating cars or other moving vehicles
</li></ul>



<h3>Compound colliders</h3>

<p>Compound Colliders are combinations of primitive Colliders, all together acting as a single Collider.  They come in handy when you have a complex mesh to use in collisions, but cannot use a Mesh Collider.  To create a Compound Collider, create child objects of your colliding object, then add a primitive Collider to each child object.  This allows you to position, rotate, and scale each Collider easily and independently of each other.
</p>

<p><img alt="" src=""img/wiki_up/RigidBody" border="0"  />
</p>

<p><i>A GameObject with a Rigidbody and multiple colliders attached</i>
</p>

<p>In the above picture, the terrain has a Mesh Collider attached.  Mesh Colliders work the best for terrain or environments made from irregular shapes. The Rigidbody has 3 child Colliders attached: capsule, cube and sphere. When Play mode begins, the Rigidbody falls due to gravity, and the 3 child Colliders fall with it. The 3 Collision primitives collide with the Mesh Collider, and the Rigidbody eventually balances and comes to rest on the 3 Colliders.
</p>

<p>Keep in mind, Mesh Colliders can't collide with each other, so the typical solution is to use primitive Colliders for any objects that move, and Mesh Colliders for static background objects.
</p>




<h2>Use the right size</h2>
<p>The size value of the your object's mesh is much more important than the mass of the Rigidbody.  If you find that your Rigidbody is not behaving exactly how you expect; it moves slowly, 'floats', or doesn't collide correctly; consider adjusting the scale of your mesh and/or the Rigidbody's <a href="../Components/class-Transform.html">Transform</a>.  Unity's default unit scale is 1 unit = 1 meter, so the scale of your imported mesh is maintained, and applied to physics calculations.  For example, a crumbling skyscraper is going to fall apart very differently than a tower made of toy blocks, so objects of different sizes should be modeled to accurate scale.
</p>

<p>If you are modelling a human make sure he is around 2 meters big in Unity. To check if your object has the right size compare it to the default cube. You can create a cube using <b>GameObject -&gt; Create Other -&gt; Cube</b>. The cube will be exactly 1 meter large. So your human should be twice as tall.
</p>

<p>If you aren't able to adjust the mesh itself, you can change the global scale of each particular mesh by control-clicking on your imported mesh and selecting 'Import Settings' from the context menu.  Here, you can change the scale and re-import your mesh.
</p>

<p>If your game requires that your GameObject needs to be instantiated at different scales, it is perfectly okay to directly adjust the values of your Transform's scale.  The down-side is that the physics simulation must do more work at the time the object is instantiated, and could cause a performance drop in your game.  This isn't a terrible loss, but it is not as efficient as finalizing your scale with the other two options.
</p>


<h2>Hints</h2>
<p><ul><li>
The relative masses of two objects determines how they react when they collide.
</li><li>Making one object have higher mass than another does not make it fall faster in free fall. Use drag for that.
</li><li>A low drag value makes an object seem heavy. A high one makes it seem light. Typical values for drag are between .001 (solid block of metal) and 10 (feather)
</li><li>If you are directly manipulating the Transform component of your object, don't attach a Rigidbody
</li></ul>
</p>
<h1>Constant Force</h1>
<p>The Constant Force component is a quick utility for adding constant forces to a rigidbody.
This works great for one shot objects like rockets, if you don't want it to start with a large velocity but instead accelerate.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A rocket propelled forward by the constant force component</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Force</nobr></b></td><td> The vector of a force to be applied in world space.
</td></tr><tr><td><b><nobr>Relative Force</nobr></b></td><td> The vector of a force to be applied in the objects local space.
</td></tr><tr><td><b><nobr>Torque</nobr></b></td><td> The vector of a torque, applied in world space. The object will begin spinning <i>around</i> this vector. The longer the vector is, the faster the rotation.
</td></tr><tr><td><b><nobr>Relative Torque</nobr></b></td><td> The vector of a torque, applied in local space. The object will begin spinning <i>around</i> this vector. The longer the vector is, the faster the rotation.
<p></td></tr></tr></table>
</p>

<h3> Details</h3>

<p>To make a rocket that accelerates forward set the relative force to be along the positive z-axis. Then use the rigidbody's drag property to make it not exceed a some maximum velocity. (The higher the drag the lower the maximum velocity will be.)
In the rigidbody also make sure to turn off gravity so that the rocket will always stay on it's path.
</p>

<h2>Hints</h2>
<p><ul><li>
To make an object flow upwards, add a constant force with the Force property having a positive Y value.
</li><li>To make an object fly forwards,  add a constant force with the Relative Force property having a positive Z value.
</li></ul>
</p>

<h1>Sphere Collider</h1>
<p>The Sphere Collider is a basic sphere-shaped collision primitive.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>(Image of a Sphere Collider in Inspector)</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Material</nobr></b></td><td> Reference to the PhysicMaterial that determines how this Collider interacts with others.
</td></tr><tr><td><b><nobr>Is Trigger</nobr></b></td><td> If enabled, this Collider is used for triggering events, and is ignored by the physics engine.

</td></tr><tr><td><b><nobr>Radius</nobr></b></td><td> The size of the collider.
</td></tr><tr><td><b><nobr>Center</nobr></b></td><td> The position of the collider in the object's local space.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>The Sphere Collider can be resized to uniform scale, but not along individual axes. It works great for falling boulders, ping pong balls, marbles, etc.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-4.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-4.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A standard Sphere Collider</i>
</p>


<p>Colliders work with Rigidbodies to bring physics in Unity to life.  Whereas Rigidbodies allow objects to be controlled by physics, Colliders allow objects to collide with each other.  Colliders must be added to objects independently of Rigidbodies.  A Collider does not necessarily need a Rigidbody attached, but a Rigidbody <span style="text-decoration:underline;">must</span> be attached in order for the object to react to collisions.
</p>

<p>When a collision between two Colliders occurs and if at least one of them has a Rigidbody attached, <a class="wiki"  href="../ScriptReference/Collider.html#OnCollisionEnter">three</a> <a class="wiki"  href="../ScriptReference/Collider.html#OnCollisionExit">collision</a> <a class="wiki"  href="../ScriptReference/Collider.html#OnCollisionStay">messages</a> are sent out to the objects attached to them. These events can be handled in scripting, and allow you to create unique behaviors with or without making use of the built-in Ageia physX engine.
</p>

<h3>Triggers</h3>
<p>An alternative way of using Colliders is to mark them as a Trigger, just check the IsTrigger property checkbox in the Inspector.  Triggers are effectively ignored by the physics engine, and have a unique set of <a class="wiki"  href="../ScriptReference/Collider.html#OnTriggerEnter">three</a> <a class="wiki"  href="../ScriptReference/Collider.html#OnTriggerExit">trigger</a> <a class="wiki"  href="../ScriptReference/Collider.html#OnTriggerStay">messages</a> that are sent out when a collision with a Trigger occurs.  Triggers are useful for triggering other events in your game, like cutscenes, automatic door opening, displaying tutorial messages, etc.  Use your imagination!
</p>

<p>Be aware that in order for two Triggers to send out trigger events when they collide, one of them must be attached to a Rigidbody. For a Trigger to collide with a normal Collider, one of them must have a Rigidbody attached.  For a detailed chart of different types of collisions, see the collision action matrix in the Advanced section below.
</p>


<h2>Compound Colliders</h2>

<p>Compound Colliders are combinations of primitive Colliders, all together acting as a single Collider.  They come in handy when you have a complex mesh to use in collisions, but cannot use a Mesh Collider.  To create a Compound Collider, create child objects of your colliding object, then add a primitive Collider to each child object.  This allows you to position, rotate, and scale each Collider easily and independently of each other.
</p>

<p><img alt="" src=""img/wiki_up/RigidBody" border="0"  />
</p>

<p><i>A GameObject with a Rigidbody and multiple colliders attached</i>
</p>

<p>In the above picture, the terrain has a Mesh Collider attached.  Mesh Colliders work the best for terrain or environments made from irregular shapes. The Rigidbody has 3 child Colliders attached: capsule, cube and sphere. When Play mode begins, the Rigidbody falls due to gravity, and the 3 child Colliders fall with it. The 3 Collision primitives collide with the Mesh Collider, and the Rigidbody eventually balances and comes to rest on the 3 Colliders.
</p>

<p>Keep in mind, Mesh Colliders can't collide with each other, so the typical solution is to use primitive Colliders for any objects that move, and Mesh Colliders for static background objects.
</p>


<h2>Hints</h2>
<p><ul><li>
To add multiple Colliders for an object, create child objects and attach a Collider to each one.  This allows each Collider to be manipulated independently.
</li><li>You can look at the gizmos in the Scene view to see how the Collider is being calculated on your object.
</li><li>Colliders do their best to match the scale of an object. If you have a non-uniform scale (a scale which is different in each direction), only the Mesh Collider can match completely.
</li><li>If you make an explosion, it can be very effective to add a rigidbody with lots of drag and a sphere collider to it in order to push it out a bit from the wall it hits.
</li></ul>
</p>


<h1>Box Collider</h1>
<p>The Box Collider is a basic cube-shaped collision primitive.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-5.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-5.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Box collider here is used to approximate car's hull</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>Size</nobr></b></td><td> The size of the collider in the X, Y, Z directions.
</td></tr><tr><td><b><nobr>Center</nobr></b></td><td> The position of the collider in the object's local space.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>The Box Collider can be resized into different shapes of rectangular prisms.  It works great for doors, walls, platforms, etc. It is also effective as a human torso in a ragdoll or car hull in a vehicle. Of course, it works perfectly for just boxes and crates as well!
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-6.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-6.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A standard Box Collider</i>
</p>




<h2>Compound Colliders</h2>




<h2>Hints</h2>
<p><ul><li>
</p>

<p></li></ul>
</p>


<h1>Mesh Collider</h1>

<p>The Mesh Collider takes a <a href="../Components/class-Mesh.html">Mesh Asset</a> and builds its Collider based on that mesh.  It is far more accurate for collision detection than using primitives for complicated meshes, but it cannot collide with other Mesh Colliders.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-7.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-7.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A Mesh Collider used on the flag tower object</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>Mesh</nobr></b></td><td> Reference to the Mesh to use for collisions.
</td></tr><tr><td><b><nobr>Smooth Sphere Collisions</nobr></b></td><td> When this is enabled, collision mesh normals are smoothed. You should enable this on smooth surfaces eg. rolling terrain without hard edges to make sphere rolling smoother.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>The Mesh Collider builds its collision representation from the <a href="../Components/class-Mesh.html">Mesh</a> attached to the GameObject, and reads the properties of the attached <a href="../Components/class-Transform.html">Transform</a> to set its position and scale correctly.
</p>



<h2>Hints</h2>
<p><ul><li>
Mesh Colliders <span style="text-decoration:underline;">cannot</span> collide with each other.  Therefore, they are most useful for background objects like environment geometry.
</li><li>It is usually better to use primitive Colliders for objects under physics control.
</li><li>When you attach a Mesh Collider to a Game Object, its Mesh property will default to the mesh being rendered. You can change that by assigning a different Mesh.
</p>

<p></li></ul>
</p>


<h1>Physic Material</h1>
<p>The physics material contain all info needed to tune friction and bouncing effects of colliding objects.
</p>

<p>To create a physic material select the menu <b>Assets -&gt; Create -&gt; Physic Material</b>.  Then drag the physic material from the project pane on a collider in the scene.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-8.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-8.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Physic Material</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Static Friction</nobr></b></td><td> The friction used when an object is lying on a surface. Usually a value from 0 to 1.
</td></tr><tr><td><b><nobr>Dynamic Friction</nobr></b></td><td> The friction used when already moving. Usually a value from 0 to 1.
</td></tr><tr><td><b><nobr>Bouncyness</nobr></b></td><td> How bouncy is the surface? A value of 0 will not bounce. A value of 1 will bounce without any loss of energy.
</td></tr><tr><td><b><nobr>Friction Combine Mode</nobr></b></td><td> How the friction of two colliding objects is combined.
</td></tr><tr><td><b><nobr>Â Â Â Â Average</nobr></b></td><td> The two friction values are averaged.
</td></tr><tr><td><b><nobr>Â Â Â Â Min</nobr></b></td><td> The smallest of the two values is used.
</td></tr><tr><td><b><nobr>Â Â Â Â Max</nobr></b></td><td> The largest of the two values is used.
</td></tr><tr><td><b><nobr>Â Â Â Â Multiply</nobr></b></td><td> The friction values are multiplied with each other.
</td></tr><tr><td><b><nobr>Bounce Combine Mode</nobr></b></td><td> How the bouncyness of two colliding objects is combined.
</td></tr><tr><td><b><nobr>Â Â Â Â Average</nobr></b></td><td> The two values are averaged.
</td></tr><tr><td><b><nobr>Â Â Â Â Min</nobr></b></td><td> The smallest of the two values is used.
</td></tr><tr><td><b><nobr>Â Â Â Â Max</nobr></b></td><td> The largest of the two values is used.
</td></tr><tr><td><b><nobr>Â Â Â Â Multiply</nobr></b></td><td> The values are multiplied with each other.
</td></tr><tr><td><b><nobr>Friction Direction 2</nobr></b></td><td> The direction of anisotropy. Anisotropic friction is enabled if the vector3 is not zero. Dynamic Friction 2 and Static Friction 2 will be applied along Friction Direction 2.
</td></tr><tr><td><b><nobr>Dynamic Friction 2</nobr></b></td><td> If anisotropic friction is enabled, dynamicFriction2 will be applied along Friction Direction 2.
</td></tr><tr><td><b><nobr>Static Friction 2</nobr></b></td><td> If anisotropic friction is enabled, staticFriction2 will be applied along Friction Direction 2.
</td></tr><tr><td><b><nobr>Static Friction 2</nobr></b></td><td> If anisotropic friction is enabled, staticFriction2 will be applied along Friction Direction 2.
</td></tr><tr><td><b><nobr>Use Spring</nobr></b></td><td> If use Spring is checked, surface will be springy.
</td></tr><tr><td><b><nobr>Spring</nobr></b></td><td> The spring of the surface
</td></tr><tr><td><b><nobr>Â Â Â Â Spring</nobr></b></td><td> The spring coefficient. A high value will pull the surfaces towards the rest position faster.
</td></tr><tr><td><b><nobr>Â Â Â Â Damper</nobr></b></td><td> The damper coefficient. A high value will dampen the relative movement of the two surfaces.
</td></tr><tr><td><b><nobr>Â Â Â Â Target Position</nobr></b></td><td> The rest position of the spring.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>Friction is the quantity which prevents surfaces from sliding off each other. This value is critical when trying to stack objects.
Friction comes in two forms, dynamic and static. Static friction is used when the object is lying still. It will prevent the object from starting to move. If a large enough force is applied to the object it will start moving. At this point dynamic friction will come into play. Dynamic friction will now attempt to slow down the object while in contact with another.
</p>

<h2>Hints</h2>
<p><ul><li>
Don't try to use a standard physic material for the main character. Make a customized one and get it perfect.
</li></ul>
</p>
<h1>Hinge Joint</h1>

<p>The Hinge Joint groups together 2 <a href="../Components/class-Rigidbody.html">Rigidbodies</a>, constraining them to move like they are connected by a hinge. It is perfect for doors, but can also be used to model chains, pendulums, etc.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-9.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-9.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Hinge Joint</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Connected Body</nobr></b></td><td> Optional reference to the Rigidbody that the joint is dependent upon. If not set, the joint connects to the world.
</td></tr><tr><td><b><nobr>Anchor</nobr></b></td><td> The Position of the anchor around which the body swings. The Position is defined in local space.
</td></tr><tr><td><b><nobr>Axis</nobr></b></td><td> The Direction of the axis around which the body swings. The Axis is defined in local space.
</td></tr><tr><td><b><nobr>Use Spring</nobr></b></td><td> Spring makes the rigid body attempt to stay in a specific angle compared to its connected body.
</td></tr><tr><td><b><nobr>Â Â Â Â Spring</nobr></b></td><td> The force the object asserts to move into the position.
</td></tr><tr><td><b><nobr>Â Â Â Â Damper</nobr></b></td><td> the higher this value, the more the object will slow down.
</td></tr><tr><td><b><nobr>Â Â Â Â Target Position</nobr></b></td><td> Target angle of the spring. The spring pulls towards this angle measured in degrees.
</td></tr><tr><td><b><nobr>Use Motor</nobr></b></td><td> The motor makes the object spin around.
</td></tr><tr><td><b><nobr>Â Â Â Â Target Velocity</nobr></b></td><td> The speed the object tries to attain.
</td></tr><tr><td><b><nobr>Â Â Â Â Force</nobr></b></td><td> The force applied in order to attain the speed.
</td></tr><tr><td><b><nobr>Â Â Â Â Free Spin</nobr></b></td><td> If enabled, the motor is never used to brake the spinning, only accelerate it.
</td></tr><tr><td><b><nobr>Use Limits</nobr></b></td><td> If enabled, the angle of the hinge will be restricted within the <b>Min</b> &amp; <b>Max</b> values.
</td></tr><tr><td><b><nobr>Â Â Â Â Min</nobr></b></td><td> The lowest angle the rotation can go.
</td></tr><tr><td><b><nobr>Â Â Â Â Max</nobr></b></td><td> The highest angle the rotation can go.
</td></tr><tr><td><b><nobr>Â Â Â Â Min Bounce</nobr></b></td><td> How much the object bounces when it hits the minimum stop.
</td></tr><tr><td><b><nobr>Â Â Â Â Max Bounce</nobr></b></td><td> How much the object bounces when it hits the maximum stop.
</td></tr><tr><td><b><nobr>Break Force</nobr></b></td><td> The force that needs to be applied for this joint to break.
</td></tr><tr><td><b><nobr>Break Torque</nobr></b></td><td> The torque that needs to be applied for this joint to break.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>A single Hinge Joint should be applied to an object per desired hinge.  The hinge will rotate at the point specified by the <b>Anchor</b> property, moving around the specified <b>Axis</b> property.  You DO NOT need to assign a Game Object to the joint's <b>Connected Body</b> property.  You should only assign a Game Object to the <b>Connected Body</b> property if you want the joint's Transform to be dependent on the attached object's Transform.
</p>

<p>Think about how the hinge of a door works. The <b>Axis</b> in this case is up, positive along the Y axis. The <b>Anchor</b> is placed somewhere at the intersection between door and wall.  You would not need to assign the wall to the <b>Connected Body</b>, because the joint will be connected to the world by default.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-10.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-10.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A practical Hinge Joint with no <b>Connected Body</b></i>
</p>

<p>Now think about a doggy door hinge. The doggy door's <b>Axis</b> would be sideways, positive along the relative X axis.  The main door should be assigned as the <b>Connected Body</b>, so the doggy door's hinge is dependent on the main door's Transform.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-11.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-11.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A practical Hinge Joint with a proper <b>Connected Body</b></i>
</p>


<h3>Chains</h3>

<p>Multiple Hinge Joints can also be strung together to create a chain.  Add a joint to each link in the chain, and attach the next link as a <b>Connected Body</b>.  The result should be similar to the following picture.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-12.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-12.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>A Nunchaku made exclusively with primitives and Hinge Joints</i>
</p>

<h3>Vehicles</h3>

<p>Hinge Joints can be implemented as axles on vehicles, as seen here in Forest Johnson's racing game. However, it's often better just to use a <a href="../Components/class-WheelCollider.html">Wheel Collider</a> for vehicles.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Physics-13.jpg%22" --><p><table><tr><td><img class="figure" src="images/Physics-13.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h2>Hints</h2>
<p><ul><li>
You do not need to assign a <b>Connected Body</b> to your joint for it to work.
</li><li>Use <b>Break Force</b> in order to make dynamic damage systems. This is really cool as it allows the player to break a door off its hinge by blasting it with a rocket launcher or running into it with a car.
</li><li>The <b>Spring</b>, <b>Motor</b>, and <b>Limits</b> properties allow you to fine-tune your joint's behaviors.
</li></ul>
</p>






<p>Animations are best imported from art programs but can also be created inside Unity.
</p>

<p>To import an animation from your art package just <a href="../Manual/HOWTO-importObject.html">drop in your model files</a>.
</p>

<p>When you place your model file in unity's project folder it will automatically appear in the project view and you can drag it to the scene. The animation on all objects in the scene is imported automatically and you wil see the animation playing when you hit play.
</p>

<p>For more information about animating characters or importing animations see the <a href="../Manual/Character-Animation.html"> Character Animation section</a>.
</p>

<h2>Creating animations inside Unity</h2>

<p>1. Switch to the animation layout. This will give you a time line pane. In the time line you will create and modify animations.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Animation-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Animation-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>2. Select the object you want to animate in the scene view.
</p>

<p>3. Click on the record button in the animation time line
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Animation-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Animation-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>4. Select another time in the timeline by clicking on it. Then move the object some where else and hit record again.
</p>

<p>If you hit play now, your object will follow the animation you just created.
</p>

<h2>Hints</h2>
<p><ul><li>
By default only the transform's position, rotation and scale is included in the animation.
Right-click on the timeline and use the &quot;Add Key With Attribute&quot; menu to add other animatable properties of the selected object to the animation.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Animation-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Animation-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p></li><li>You can scrub on the timeline by dragging a keyframe with the center mouse button
</p>

<p></li><li>Post Infinity is used to define behaviour of the animation after the last keyframe. Right-click on the timeline and select Post Infinity -&gt; Repeat from the context menu.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Animation-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/Animation-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p></li><li>Sometimes it is useful to create animations which are shared among all objects.
To do this, create an animation clip in the assets menu.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Animation-4.jpg%22" --><p><table><tr><td><img class="figure" src="images/Animation-4.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Then drag the animation clip on an object. Then you animate the object. Then you can drag the animation clip on other objects.
</li></ul>
</p>



<p>Unity's Animation System allows you to create beautifully animated skinned characters. The Animation System supports animation blending, mixing, additive animations, walk cycle time synchronization, animation layers, control over all aspects of the animation playback (time, speed, blend-weights), mesh skinning with 1, 2 or 4 bones per vertex and finally physically based ragdolls.
</p>

<p>Making an animated character involves two things; <i>moving</i> them through the world and <i>animating</i> them accordingly.
</p>

<p>This page focuses on the animation. If you want to learn more about moving characters around (for a Super Mario Bros style game or a first-person shooter), go <a href="../Components/class-CharacterController.html">here</a>.
</p>

<ul><li><A HREF="#ImportAnim">Importing Character Animations</A>
<ul><li><A HREF="#ImportSplit">Animation Splitting</A>
</li><li><A HREF="#ImportFile">Multipe Files</A>
</li><li><A HREF="#ImportIK">Inverse Kinematics</A>
</li></ul></li><li><A HREF="#IntoScene">Inserting Into a Unity Scene</A>
</li><li><A HREF="#Animate">Animating the Character</A>
<ul><li><A HREF="#AnimBlend">Animation Blending</A>
</li><li><A HREF="#AnimLayers">Animation Layers</A>
</li><li><A HREF="#LayerExample">Additive Animation</A>
</li></ul></li></ul>

<p>You can download an <b><a class="wiki"  href="http://www.unity3d.com/examples/index.html">example project</a></b> showing pre-setup animated characters <a class="wiki"  href="http://www.unity3d.com/examples/index.html">here</a>.
</p>



<p><A NAME="ImportAnim"></A>
</p>
<h2> Importing The Animations</h2>
<p>First of all we have to import the character.  Unity natively imports Maya (.mb/.ma) files, Cinema 4D (.c4d) files, and fbx files which can be exported from most animation packages. Click here to learn how to <a href="../Manual/HOWTO-importObject.html">export from your modelling/animation package</a>.
</p>

<p><A NAME="ImportSplit"></A>
</p>
<h3>Importing Animations using Animation Splitting</h3>
<p>The most convenient way for animators to work is to have a single model containing all animations. When importing the animated model, you can define which frames make up each part of the animation. Unity will automatically split the animation into the individual parts, called <b>Animation Clips</b>.
</p>

<p>For example:
</p>
<ul><li>idle animation during frames 0 - 40
</li><li>run animation during frames 41 - 65
</li><li>walk animation during frames 66 - 83
</li></ul>

<p>To import the animations you simply place the model in your project folder. Unity will now automatically import it. Now highlight it in the project view and choose <b>Assets -&gt; Import Settings...</b> from the main menu.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Character-Animation-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Character-Animation-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Import Settings Dialog for a mesh</i>
</p>

<p>In the Import Settings' <b>Split Animations</b> table you tell Unity which frames in your 3D file make up which <b>Animation Clip</b>. The names you specify here are used to activate them in your game.
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
name</nobr></b></td><td> Defines the Animation Clip's name within Unity.
</td></tr><tr><td><b><nobr>first frame</nobr></b></td><td> the first frame of the animation. The frame number refers to the same frame as in the 3D program used to create the animation.
</td></tr><tr><td><b><nobr>last frame</nobr></b></td><td> The last frame of the animation.
</td></tr><tr><td><b><nobr>loop frame</nobr></b></td><td> If enabled, an extra <i>loop frame</i> is inserted at the end of the animation. This frame matches the first frame in the clip. Use this if you want to make a looping animation and your artwork has not been created in such a way that the first and last frame of the animation match up exactly.
<p></td></tr></tr></table>
</p>

<p><A NAME="ImportFile"></A>
</p>
<h3>Importing Animations using multiple model files</h3>
<p>The other way to import animations is to follow the @ animation naming scheme. You create seperate model files and name them like: 'model name'@'animation name'.fbx
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Character-Animation-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Character-Animation-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>An example of 4 animation files for an animated character</i>
</p>

<p>Unity automatically imports all 4 files and collects all animations to the file without the @ sign in. In the example above, the goober.mb file will be setup to reference idle, jump, and walk automatically.
</p>

<p><A NAME="ImportIK"></A>
</p>
<h3> Importing Inverse Kinematics</h3>
<p>When importing animated Characters from Maya that are created using IK, you have to check the Bake IK &amp; simulation box in the import settings. Otherwise, your Character will not animate correctly.
</p>

<p><A NAME="IntoScene"></A>
</p>
<h2> Bringing the Character into the Scene</h2>

<p>When you have imported your model you drag the object from the Project view into the Scene view or Hierarchy.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Character-Animation-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Character-Animation-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The animated character is added by dragging it into the scene</i>
</p>

<p>The character above has 3 animations in the animation list and no default animation. You can add more animations to the character by dragging animation clips from the <b>Project View</b> on to the character (in either the <b>Hierarchy View</b> or a <b>Scene View</b>). This will also set the default animation. When you hit play the default animation will be played.
</p>

<p>TIP: you can use this to quickly test if your animation plays back correctly. Also use the Wrap Mode to view different behaviors of the animation- especially looping.
</p>

<p><A NAME="Animate"></A>
</p>
<h2> Animating the Character</h2>

<p>The actual animation of characters is done through Unity's scripting interface.
</p>

<p><A NAME="AnimBlend"></A>
</p>
<h3> Animation Blending</h3>

<p>In today's games, animation blending is an essential feature to ensure that characters have smooth animations. Animators create separate animations, e.g. a walk cycle, run cycle, idle animation or shoot animation. At any point in time in your game you need to be able to transition from the idle animation into the walk cycle and vice versa. Of course you don't want any sudden jumps in the motion. You want the animation to smoothly transition.
</p>

<p>This is where animation blending comes in. In Unity you can have an arbitrary amount of animations playing on the same character. All animations are blended or added together to generate the final animation.
</p>


<p>Our first step will be to make a character smoothly blend between the idle and walk animations.  In order to make our job simpler when scripting, we will first set the <b>Wrap Mode</b> of the animation to <b>Loop</b>. Then we will turn off <b>Play Automatically</b> to make sure our script is the only one playing animations.
</p>

<p>Our first script for animating the character is quite simple; we only need some way to detect how fast our character is moving, and then fade between walk and idle animation. For this simple test we use the pre-setup input axes.
</p>

<p><pre class='codelisting'>
function Update ()
{
   if (Input.GetAxis(&quot;Vertical&quot;) &gt; 0.2)
       animation.CrossFade (&quot;walk&quot;);
   else
      animation.CrossFade (&quot;idle&quot;);
}
</pre>
</p>

<p>To get this script running:
</p>
<ol><li> Create a javascript using Assets -&gt; Create Other -&gt; Javascript.
</li><li> Copy &amp; Paste the code into it
</li><li> Drag the script onto the character (It needs to be the same game object as the animation)
</li></ol>

<p>When you hit the play button, The character will start walking in place when you hold the up arrow key and return to the idle pose when you release  it.
</p>

<p><A NAME="AnimLayers"></A>
</p>
<h3> Animation Layers</h3>

<p>Layers are an incredibly useful concept that allow you to group animations and prioritize weighting.
</p>

<p>in Unity's animation system, you can blend between as many animation clips as you want. You can assign blend weights manually or simply use animation.CrossFade, which will animate the weight automatically.
</p>

<h4>Blend weights are always normalized before being applied</h4>

<p>Let's say you have a walk cycle and a run cycle, both have a weight of 1 (100%). When Unity generates the final animation it will normalize the weights, which means walk will contribute 50% to the animation, the run cycle will also contribute 50%.
</p>

<p>This is all very nice, but often you want to prioritize which animation receives most weight when there are two animations playing. Surely you could just make sure that the weight sums up to 100% manually, but it is a lot easier to use layers for this purpose.
</p>


<p><A NAME="LayerExample"></A>
</p>
<h4> Layering Example</h4>
<p>For example you might have a shoot animation, an idle and a walk cycle. You will want to continously fade between the walk and idle animation based on the player's speed. But when the player shoots you want to only show the shoot animation. Thus the shoot animation essentially has a higher priority.
</p>

<p>The easiest way to do this is to simply keep playing the walk and idle animations while shooting. Then we need to make sure that the shoot animation is in a higher layer than idle and walk. This means the shoot animation will receive blend weights first. The walk and idle animation will receive weights only if the shoot animation doesn't use all of the 100% blend weights. So when CrossFading the shoot animation in, the weight will start out at zero and over a short period become 100%. In the beginning the walk and idle layer will still receive blend weights but when the shoot animation is completely faded in, they will receive no weights at all.  This is exactly what we need!
</p>

<p><pre class='codelisting'>
function Start ()
{
   // Set all animations to loop
   animation.wrapMode = WrapMode.Loop;
   // except shooting
   animation[&quot;shoot&quot;].wrapMode = WrapMode.Once;

   // Put idle and walk into lower layers (The default layer is always 0)
   // This will do two things
   // - Since shoot and idle/walk are in different layers they will not affect
   //   each other's playback when calling CrossFade.
   // - Since shoot is in a higher layer, the animation will replace idle/walk 
   //   animations when faded in.
   animation[&quot;shoot&quot;].layer = 1;
  
   // Stop animations that are already playing
   //(In case user forgot to disable play automatically)
   animation.Stop();
}

function Update () {
   // Based on the key that is pressed,
   // play the walk animation or the idle animation
   if (Mathf.Abs(Input.GetAxis(&quot;Vertical&quot;)) &gt; 0.1)
      animation.CrossFade(&quot;walk&quot;);
   else
      animation.CrossFade(&quot;idle&quot;);

   // Shoot
   if (Input.GetButtonDown (&quot;Fire1&quot;))
      animation.CrossFade(&quot;shoot&quot;);
}
</pre>
</p>

<p>By default the animation.Play or animation.CrossFade function will stop or fade out animations that are in the same layer. This is exactly what we want in mose cases. In our shoot, idle, run example. Playing idle and run will not affect the shoot animation and vice versa. (You can change this behaviour with an optional parameter to animation.CrossFade if you like)
</p>

<p><A NAME="Additive"></A>
</p>
<h3> Additive Animations and Animation Mixing</h3>

<p>Additive Animations and Animation mixing allow you to cut down on the number of animations you have to create for your game, and are important to creating facial animation.
</p>

<p>Let's say you want to create a character that leans to the sides when running and turning.
</p>

<p>You already made a walk and run cycle, now you could make a walk-lean-left, walk-lean-right, run-lean-left, run-lean-right animation.
</p>

<p>But that means you just doubled the amount of animation work! Creating a huge amount of animations is not feasiable. Additive animations and Mixing to the rescue!
</p>

<h4>Additive Animation Example</h4>
<p>Additive animations allow you to overlay the effects of animation on top of any others that may be playing. When making additive animations, Unity will calculate the difference between the first frame in the animation clip and the current frame. Then it will apply this difference on top of all other playing animations.
</p>

<p>Now you only have to make a lean-left and lean-right animation. Unity will then layer this animation on top of the walk, idle or run cycle.
</p>

<p>Here is the code to make that happen:
<pre class='codelisting'>
private var leanLeft : AnimationState;
private var leanRight : AnimationState;

function Start ()
{
   leanLeft = animation[&quot;leanLeft&quot;];
   leanRight = animation[&quot;leanRight&quot;];
	
   // Put the leaning animation in a seperate layer
   // So that other calls to CrossFade won't affect it.
   leanLeft.layer = 10;
   leanRight.layer = 10;

   // Set the lean animation to be additive
   leanLeft.blendMode = AnimationBlendMode.Additive;
   leanRight.blendMode = AnimationBlendMode.Additive;

   // Set the lean animation ClampForever
   // With ClampForever animation's will not automatically
   // stop when reaching the end of the clip
   leanLeft.wrapMode = WrapMode.ClampForever;
   leanRight.wrapMode = WrapMode.ClampForever;

   // Enable the animation and fade it in completely
   // We don't use animation.Play here because we manually adjust the time
   // in the Update function.
   // Instead we just enable the animation and set it to full weight
   leanRight.enabled = true;
   leanLeft.enabled = true;
   leanRight.weight = 1.0;
   leanLeft.weight = 1.0;

   // For testing just play run animation and loop it
   animation[&quot;walk&quot;].wrapMode = WrapMode.Loop;
   animation.Play(&quot;walk&quot;);
}

// Every frame just set the normalized time 
// based on how much lean we want to apply
function Update ()
{
   var lean = Input.GetAxis(&quot;Horizontal&quot;);
   // normalizedTime is 0 at the first frame and 1 at the last frame in the clip
   leanLeft.normalizedTime = -lean;
   leanRight.normalizedTime = lean;
}
</pre>
</p>

<p>Tip:
When using Additive animations it critical that you are also playing some other non-additive animation on every transform that is also used int eh additive animation, otherwise the animations will add on top of the last frame's result. This is most certainly not what you want.
</p>

<p>You have learned how to make a basic character animation please see the <a class="wiki"  href="http://www.unity3d.com/examples">projects</a> for in-depth examples of character animation and the <a class="wiki"  href="../ScriptReference/Animation.html">animation script interface</a>.
</p>



<p>Unity uses OpenAL to implement immersive 3D audio. Adding sound to a game is one of the final touches that make a game feel like a complete product. Using 3D positioned audio effects and well chosen music creatively can even add to the game play and greatly affect the mood of the final product.
</p>

<p>In short, adding sounds to a game consists of adding sound assets to the project, attaching an Audio Listener to the main camera object and attaching Audio Sources to game objects.
</p>

<h2>Scripting</h2>

<p>Audio is triggered from scripting. See the documentation on the <a href="../ScriptReference/AudioListener.html">AudioListener</a>, <a href="../ScriptReference/AudioSource.html">AudioSource</a> and the <a href="../ScriptReference/AudioClip.html">AudioClip</a> classes in the <a href="../ScriptReference/index.html">Script Reference</a> for more information on scripting audio.
</p>

<h1>Audio Listener</h1>
<p>The Audio Listener acts as a microphone-like device. It receives input from any given <a href="../Components/class-AudioSource.html">Audio Source</a> in the scene and plays sounds through the computer speakers.  It is traditionally attached to the main <a href="../Components/class-Camera.html">Camera</a>.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Sound-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Sound-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Audio Listener, attached to the Main Camera</i>
</p>

<h2>Properties</h2>
<p>The Audio Listener has no properties.  It simply must be added to work.
</p>

<h2>Details</h2>
<p>The Audio Listener works in conjunction with <a href="../Components/class-AudioSource.html">Audio Sources</a>, allowing you to create the aural experience of your games.  When the Audio Listener is attached to an object in your scene, any Sources that are close enough to the Listener will be picked up and played through the player's computer speakers.  Each scene can only have 1 Audio Listener to work properly.
</p>

<p>As long as the Sources are in mono format, the Listener will automatically position the sound in the correct speaker, at the correct volume.  Stereo Sources will automatically play in both speakers.  For example, if your character walks off a street into a night club, the night club's music should probably be stereo, while the individual voices of characters in the club should be mono.
</p>

<p>You should attach the Audio Listener to either the main camera or to the game object that represents the player. Try both to find what suits your game best.
</p>

<h2>Hints</h2>
<p><ul><li>
Each scene can only have one Audio Listener.
</li><li>You access the project-wide audio settings using the <a href="../Components/class-AudioManager.html">AudioManager</a>, found in the Edit-&gt;Project Settings-&gt;Audio menu.
</li></ul>
</p>


<h1>Audio Source</h1>
<p>The Audio Source takes an <a href="../Components/class-AudioClip.html">Audio Clip</a> and plays it from a position in the world.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Sound-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Sound-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Audio Source in the scene view and Inspector</i>
</p>

<h2> Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Audio Clip</nobr></b></td><td> Reference to the sound clip file that will be played
</td></tr><tr><td><b><nobr>Play On Awake</nobr></b></td><td> If enabled, the sound will start playing the moment the scene launches. If disabled, you need to start it using the Play() command from scripting.
</td></tr><tr><td><b><nobr>Volume</nobr></b></td><td> How loud the sound is at 1 world unit's (1 meter) distance from Audio Listener.
</td></tr><tr><td><b><nobr>Min Volume</nobr></b></td><td> The minimum value of the sound. No matter how far away you get, the sound will get softer.
</td></tr><tr><td><b><nobr>Max Volume</nobr></b></td><td> How loud the sound gets at the loudest. No matter how close you get, the sound will never get louder.
</td></tr><tr><td><b><nobr>Rolloff Factor</nobr></b></td><td> How fast the sound fades. the higher the value, the shorter the range the Listener can hear the sound.
</td></tr><tr><td><b><nobr>Loop</nobr></b></td><td> Enable this to make the <b>Audio Clip</b> loop when it finishes playing.
<p></td></tr></tr></table>
</p>

<h2> Hints</h2>
<p><ul><li>
The key to a nice sound environment is tweaking the <b>Rolloff Factor</b>.
</li><li>The 3D audio effects will only work for mono audio clips. Stereo audio clips will be mixed as-is into the sound output.
</li></ul>
</p>

<h1>Audio Clip</h1>

<p>Audio Clips are used by <a href="../Components/class-AudioSource.html">Audio Sources</a> to represent the audio asset imported into Unity.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Sound-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Sound-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The Audio Clip</i>
</p>

<p>Audio Clips just work.  The only thing you should have to do with them is reference them from within <a href="../Components/class-AudioSource.html">Audio Sources</a>.
</p>

<h2>Properties</h2>
<p>Sound assets only have 3 read-only properties.
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Format </nobr></b></td><td> The format the sound is stored in. Unity supports 4 raw formats and one compressed.
<dl><dt>Mono 8 bit</dt><dd> 8 bit uncompressed mono PCM audio</dd><dt>Mono 16 bit</dt><dd> 16 bit uncompressed mono PCM audio</dd><dt>Stereo 8 bit</dt><dd> 8 bit uncompressed stereo PCM audio</dd><dt>Stereo 16 bit</dt><dd> 16 bit uncompressed stereo PCM audio</dd><dt>Ogg Vorbis</dt><dd> Ogg Vorbis encoded stereo or mono audio</dd></dl>
</td></tr><tr><td><b><nobr>Length</nobr></b></td><td> The duration of the sound file in seconds.
</td></tr><tr><td><b><nobr>Frequency</nobr></b></td><td> The sampling frequency of the file.
</td></tr></tr></table>
</p>

<h2>Supported sound formats</h2>
<p>Unity currently supports the following file formats:
</p>

<p><dl><dt><b>AIFF</b></dt><dd> Both mono and stereo. The sound will be stored as-is inside the player-data. No compression will be attempted.</dd><dt><b>WAV</b></dt><dd> Both mono and stereo. The sound will be stored as-is inside the player-data. No compression will be attempted.</dd><dt><b>MP3</b></dt><dd> Mono and stereo. Note that the audio will be uncompressed in the editor and stored uncompressed in the player. If you want to conserve space, use Ogg Vorbis files instead.</dd><dt><b>Ogg Vorbis</b></dt><dd> Both mono and stereo. The file will be stored compressed in the player-data and decompressed on the fly. </dd></dl>
</p>

<h2>Hints</h2>
<p><ul><li>
Stereo sounds are always played as-is. If you want to use attenuation and other 3D audio effects, use mono sounds.
</li><li>You can get an Ogg Vorbis encoder here <a class="wiki"  href="http://www.nouturn.com/oggdrop/">http://www.nouturn.com/oggdrop/</a>
</li></ul>
</p>







<p>Unity supports keyboard, joystick and gamepad input.
</p>

<p>Virtual axes and buttons can be created in the Input inspector and end users can configure keyboard input in a nice screen configuration dialog.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Input-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Input-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>You can setup joysticks, joypads, keyboard and mouse buttons and access them all through one simple scripting interface.
</p>

<p>From scripts all virtual axes are accessed by their name.
</p>

<p>Every project has the following default input axes.
&quot;Horizontal&quot; and &quot;Vertical&quot; are mapped to w, a, s, d and the arrow keys.
&quot;Fire1&quot;, &quot;Fire2&quot;, &quot;Fire3&quot; are mapped to control, alt and cmd.
&quot;Mouse X&quot;, &quot;Mouse Y&quot;is mapped to the mouse delta.
&quot;Window Shake X&quot; and &quot;Window Shake Y&quot; is mapped to the movement of the window.
</p>

<h3>Adding new Input Axes</h3>
<p>If you want to add new virtual axes go to the Edit-&gt;Project Settings -&gt; Input menu.
Here you can also change the settings of each axis.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Input-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Input-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>You map each Axis either to a Joystick, Mouse or two keyboard buttons.
</p>

<p>There are various parameters like gravity and sensitivity which can be used to fine tune the look and feel of input. They are all documented with tooltips.
</p>

<h3>Using Input Axes from Scripts</h3>
<p>You can query the current state from a script like this:
<pre class='codelisting'>
value = Input.GetAxis (&quot;Horizontal&quot;);
</pre>
An axis has a value between -1 and 1. The neutral position is 0.
This is the case for joystick input and keyboard input.
</p>

<p>However mouse delta and window shake delta is how much the mouse or window moved during the last frame. This means it can be larger than 1 or smaller than -1 when the user moves the mouse quickly.
</p>

<p>It is possible to create multiple Axes with the same name. When getting the input axis, the axis with the largest absolute value will be returned. This makes it possible to assign more than one input device to one Axis name. Eg. Create one axis for keyboard input and one axis for joystick input with the same name. If the user is using the joystick, input will come from the joystick otherwise the keyboard. This way you don't have to think at all about from where the input comes when writing scripts.
</p>

<h3>Button names</h3>

<p>To map a key to an axis you have to enter the key's name in the &quot;Positive Button&quot; or &quot;Negative Button&quot; property in the inspector.
</p>

<p>The names of keys follow this convention:
</p>
<ul><li> Normal keys: &quot;a&quot;, &quot;b&quot;, &quot;c&quot; ...
</li><li> Number keys: &quot;1&quot;, &quot;2&quot;, &quot;3&quot;,  ...
</li><li> Arrow keys: &quot;up&quot;, &quot;down&quot;, &quot;left&quot;, &quot;right&quot;
</li><li> Keypad keys: &quot;[1]&quot;, &quot;[2]&quot;, &quot;[3]&quot;, &quot;[+]&quot;, &quot;[equals]&quot;
</li><li> Modifier keys: &quot;right shift&quot;, &quot;left shift&quot;, &quot;right ctrl&quot;, &quot;left ctrl&quot;, &quot;right alt&quot;, &quot;left alt&quot;, &quot;right cmd&quot;, &quot;left cmd&quot;
</li><li> Mouse Buttons: &quot;mouse 0&quot;, &quot;mouse 1&quot;, &quot;mouse 2&quot;, ...
</li><li> Joystick Buttons (from any joystick): &quot;joystick button 0&quot;, &quot;joystick button 1&quot;, &quot;joystick button 2&quot;,  ...
</li><li> Joystick Buttons (from a specific joystick): &quot;joystick 0 button 0&quot;, &quot;joystick 0 button 1&quot;, &quot;joystick 1 button 0&quot;, ...
</li><li> Special keys: &quot;backspace&quot;, &quot;tab&quot;, &quot;return&quot;, &quot;escape&quot;, &quot;space&quot;, &quot;delete&quot;, &quot;enter&quot;, &quot;insert&quot;, &quot;home&quot;, &quot;end&quot;, &quot;page up&quot;, &quot;page down&quot;
</li><li> Function keys: &quot;f1&quot;, &quot;f2&quot;, &quot;f3&quot;, ...
</li></ul>

<p>The names used to identify the keys are the same in the scripting interface and the inspector.
<pre class='codelisting'>
value = Input.GetKey (&quot;a&quot;);
</pre>
</p>



<p>Scripting inside Unity is done by writing simple behaviour scripts in JavaScript, C# or Boo. You can even use multiple scripting languages in a single project. This manual assumes you are using JavaScript unless specifically stated otherwise. This is just a short introduction on how to add scripting to your project. For detailed information, see the  <a href="../ScriptReference/index.html">Script Reference</a>.
</p>


<h2>Creating new scripts</h2>
<p>To create a new script, open the Asset Menu and select Create -&gt; JavaScript, (or C Sharp Script or Boo Script). This will create a new script called NewBehaviourScript and place it in your asset folder.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Scripting-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Scripting-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>You can edit the script by double-clicking on it in the Project View.
</p>

<p>An empty behaviour script:
<pre class='codelisting'>
function Update () {
}
</pre>
</p>

<p>This is the default contents of a new JavaScript file. It does not do a lot though, so let's modify it a bit:
<pre class='codelisting'>
function Update () {
    print(&quot;Hello World&quot;);
}
</pre>
</p>

<h2>Attaching scripts to objects</h2>

<p>Save the above script and create a new object in a scene by opening the GameObject menu and selecting Create Other -&gt; Cube. This should result in a new Cube object appearing in the scene.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Scripting-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Scripting-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Now attach the script to the cube object either by dragging the script from the Project View onto the cube object (in the Scene or Hierarchy Views) or by selecting the cube and then choosing the script from the Scripts submenu inside the Component menu.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Scripting-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/Scripting-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Note that the script is now visible in the cube object's inspector.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Scripting-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/Scripting-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Now press play to test your creation. Your console window will now get filled with the familiar greeting. Exit play mode again.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Scripting-4.jpg%22" --><p><table><tr><td><img class="figure" src="images/Scripting-4.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h1>Manipulating the object</h1>

<p>The print statement in above example, albeit very handy when debugging your script, is not doing anything to the cube it is attached to. It's just sitting there without any movement. Let's change the script so the cube rotates slowly around its Y axis.
</p>

<p><pre class='codelisting'>
function Update () {
    transform.Rotate(0, 5*Time.deltaTime, 0);
}
</pre>
</p>

<p>So what's all this about? The line that has replaced the print statement first fetches the cube object's Transform and then tells it to rotate 0 degrees around its X axis, 5 around the Y axis and 0 around the Z axis every second. We multiply the number of degrees with Time.deltaTime. Remember that the Update function is called on every frame and this variable contains the number of seconds since last time it got called.
</p>

<p>To find out which values you can modify, a good starting point is to look on the inspector window of an object. There you'll see a list of components, with each component having a number of properties. As a rule of thumb, you can modify these properties using the Component.property syntax. So if you add a Rigid Body to the cube (making it a physical object), you can change the mass of the cube on the fly from scripting by assigning a value to RigidBody.mass.
</p>

<h2>Adding Variables</h2>

<p>When playing around with the above script, you might want to adjust the speed of rotation. This can be done by modifying the script directly, but requires Unity to recompile it every time. Also if you attach the script to multiple objects they will all rotate in the same way.
</p>

<p>To get around this, you can add variables to your script.
</p>

<p><pre class='codelisting'>
var speed = 5.0;

function Update () {
    transform.Rotate(0, speed*Time.deltaTime, 0);
}
</pre>
</p>

<p>Note that after recompiling, the speed variable shows up in the cube object's inspector.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Scripting-5.jpg%22" --><p><table><tr><td><img class="figure" src="images/Scripting-5.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Hit play and try modifying the value inside the inspector. The speed will change instantly.
</p>

<h2>Where to go from here</h2>

<p>This was just a short introduction on how to use scripts inside the Editor. For more examples, check out the Script Tutorial project that comes with Unity. You could also read through <a class="wiki"  href="../ScriptReference/index.html">Scripting Overview</a> inside the Script Reference, which contains a more thorough introduction into scripting with Unity plus pointers into the reference itself for in-depth information. Also take a look at the <a class="wiki"  href="http://otee.dk/forum/">Unity Forums</a>.
</p>



<p>You have finished making a game with one or more scenes in it. Now how do you build the publisher demo, beta version, or gold master?
</p>

<p>Use the 'File-&gt;Build Settings...' command. It pops up a list editor, where you assemble the .unity scene files that should go into the game.
</p>

<p>Drag &amp; drop scenes from the project view into the list of path names. Rearrange them by dragging. Remove them using the delete command (cmd-backspace).
If you want to build a player with only one scene file, you can also build a player with no levels in the path name list, this will make Unity include only the scene you are currently working on.
</p>

<p>When you are happy with the contents of the game, select your build target and press the Build button. Unity will ask you where to save the game. It's that simple.
</p>

<h1> Inside the process</h1>

<p><b>Note:</b> this is not necessary to understand. The game builder will place a copy of the player application where you want it. Then it will go through the list of scenes, open them in the editor one at a time and save a copy optimized for the player into the application package. It also calculates all the assets that are required by the different scenes and stores it in a seperate file, which is also placed inside the application package. Any game object in a scene that is tagged with 'EditorOnly' will be removed from the scene before writing the scene file into the game package.
</p>

<p>When the standalone or webplayer starts up the first level in the path name list will be loaded and the game will be started.
</p>

<p>Levels can be loaded via scripting using <a href="../ScriptReference/Application.html#LoadLevel">Application.LoadLevel</a>.
This will load the new level and destroy all game objects in the old level.
</p>

<p>To prevent a game object to be destroyed when loading a new level use
<a href="../ScriptReference/Object.html#DontDestroyOnLoad">Object.DontDestroyOnLoad</a>
</p>

<p>This is most commonly used to keep playing music while loading a level or a game controller script which keeps the game state and controls which levels to load.
</p>

<p>After the loading of a new level is finished the message: <a href="../ScriptReference/MonoBehaviour.html#LevelWasLoaded">LevelWasLoaded</a> will be sent to all active game objects.
</p>

<p>For more information on how to best create a game with multiple scenes, eg. a main menu, highscores and actual game levels see the Scripting Tutorial.pdf
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Shaders.html">Shaders</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/ShaderTut1.html">ShaderTut1</a></li><li class="toclevel"><a href="../Manual/ShaderTut2.html">ShaderTut2</a></li><li class="toclevel"><a href="../Manual/SL-Shader.html">SL-Shader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Properties.html">SL-Properties</a></li><li class="toclevel"><a href="../Manual/SL-SubShader.html">SL-SubShader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Pass.html">SL-Pass</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Material.html">SL-Material</a></li><li class="toclevel"><a href="../Manual/SL-CullAndDepth.html">SL-CullAndDepth</a></li><li class="toclevel"><a href="../Manual/SL-SetTexture.html">SL-SetTexture</a></li><li class="toclevel"><a href="../Manual/SL-Fog.html">SL-Fog</a></li><li class="toclevel"><a href="../Manual/SL-AlphaTest.html">SL-AlphaTest</a></li><li class="toclevel"><a href="../Manual/SL-Blend.html">SL-Blend</a></li><li class="toclevel"><a href="../Manual/SL-NameAndTags.html">SL-NameAndTags</a></li><li class="toclevel"><a href="../Manual/SL-BindChannels.html">SL-BindChannels</a></li></ul><li class="toclevel"><a href="../Manual/SL-GrabPass.html">SL-GrabPass</a></li></ul><li class="toclevel"><a href="../Manual/SL-Fallback.html">SL-Fallback</a></li></ul><li class="toclevel"><a href="../Manual/Reference - Structure.html">Reference - Structure</a></li><li class="toclevel"><a href="../Manual/Reference - Values.html">Reference - Values</a></li><li class="toclevel"><a href="../Manual/ShaderLab Cheat Sheet.html">ShaderLab Cheat Sheet</a></li></ul><li class="toclevel"><a href="../Manual/Plugins.html">Plugins</a></li><li class="toclevel"><a href="../Manual/Reducing File size.html">Reducing File size</a></li><li class="toclevel"><a href="../Manual/Optimizing Graphics Performance.html">Optimizing Graphics Performance</a></li></ul>
</p>



<p>All rendering in Unity is done with <i>Shaders</i> - small scripts that let you configure the how the OpenGL hardware is set up for rendering. Unity ships with 30+ shaders but you can extend this by making more yourself.
</p>

<p>Read on for how!
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/ShaderTut1.html">ShaderTut1</a></li><li class="toclevel"><a href="../Manual/ShaderTut2.html">ShaderTut2</a></li><li class="toclevel"><a href="../Manual/SL-Shader.html">SL-Shader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Properties.html">SL-Properties</a></li><li class="toclevel"><a href="../Manual/SL-SubShader.html">SL-SubShader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Pass.html">SL-Pass</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Material.html">SL-Material</a></li><li class="toclevel"><a href="../Manual/SL-CullAndDepth.html">SL-CullAndDepth</a></li><li class="toclevel"><a href="../Manual/SL-SetTexture.html">SL-SetTexture</a></li><li class="toclevel"><a href="../Manual/SL-Fog.html">SL-Fog</a></li><li class="toclevel"><a href="../Manual/SL-AlphaTest.html">SL-AlphaTest</a></li><li class="toclevel"><a href="../Manual/SL-Blend.html">SL-Blend</a></li><li class="toclevel"><a href="../Manual/SL-NameAndTags.html">SL-NameAndTags</a></li><li class="toclevel"><a href="../Manual/SL-BindChannels.html">SL-BindChannels</a></li></ul><li class="toclevel"><a href="../Manual/SL-GrabPass.html">SL-GrabPass</a></li></ul><li class="toclevel"><a href="../Manual/SL-Fallback.html">SL-Fallback</a></li></ul><li class="toclevel"><a href="../Manual/Reference - Structure.html">Reference - Structure</a></li><li class="toclevel"><a href="../Manual/Reference - Values.html">Reference - Values</a></li><li class="toclevel"><a href="../Manual/ShaderLab Cheat Sheet.html">ShaderLab Cheat Sheet</a></li></ul>
</p>



<p><i>This tutorial will teach you how you can create your own shaders and make you game look a lot better</i>
</p>

<p>Unity is equipped with a powerful shading language, called ShaderLab. The syntax for this is reminiscent  to cgFX and Microsoft's .fx languages, but not identical.
</p>

<p>The shaders in Unity can use both OpenGLs fixed function pipeline, fragment and vertex programs or a combination of both.
</p>

<p>In this tutorial we describe how to write shaders in shaderlab using both fixed function and fragment/vertex programs, therefore we rely on the shader programmer to have an basic understanding of OpenGLs render states and how to create fragment/vertex programs (using Cg from Nvidia corp.).
</p>

<p>Information about render states in OpenGL can be found here: http://fly.cc.fer.hr/~unreal/theredbook/ and tutorials on how to create fragment and vertex programs can be found here: http://www.shadertech.com/articles/.
</p>

<h2> Getting started</h2>
<p>To create a new shader, Either coose <b>Assets-&gt;Create-&gt;Shader</b> from the main menu, or duplicate an existing shader, and work from that. The new shader can be edited by choosing <b>Edit Shader</b> in the inspector.
</p>

<p><pre class='codelisting'>Shader &quot;simple&quot; {
    Properties {
        _Color (&quot;Main Color&quot;, Color) = (1,.5,.5,1)
    }
    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
            }
            Lighting On
        }
    }
}
</pre>
</p>

<p>This simple shader demonstrates one of the most basic shaders possible. It defines a color property called &quot;main Color&quot; and assigns it a default value of (Red: 1, Green: 0.5, blue: 0.5, alpha: 1). It then renders the object by invoking a Pass and in that pass setting the diffuse material component to the property color.
</p>

<p>In the following tutorial we will descripe all the things you need to be able to create your own shaders.
</p>

<h2> Basic Vertex Lighting</h2>
<p>if you open an existing shader, it can be a bit hard to get a good overview. To get you started, we will dissect the built-in VertexLit shader that ships with Unity. This shader uses OpenGL's fixed function pipeline to do per-vertex lighting.
</p>

<p><pre class='codelisting'>Shader &quot; VertexLit&quot; {
  Properties {
    _Color (&quot;Main Color&quot;, Color) = (1,1,1,0)
    _SpecColor (&quot;Spec Color&quot;, Color) = (1,1,1,1)
    _Emission (&quot;Emmisive Color&quot;, Color) = (0,0,0,0)
    _Shininess (&quot;Shininess&quot;, Range (0.01, 1)) = 0.7
    _MainTex (&quot;Base (RGB)&quot;, 2D) = &quot;white&quot; { }
  }

  SubShader {
    Pass {
      Material {
        Diffuse [_Color]
        Ambient [_Color]	
        Shininess [_Shininess]
        Specular [_SpecColor]
        Emission [_Emission]	
      } 
      Lighting On
      SeperateSpecular On
      SetTexture [_MainTex] {
        constantColor [_Color]
        Combine texture * primary DOUBLE, texture * constant 
      } 
    }
  } 
}
</pre>
</p>

<p>All shaders start with the keyword <b>Shader</b> followed by a string that represents the name of the shader. This is the name that is shown in the inspector. All code for this shader must be put within the braces after it {} (called a block).
</p>

<ul><li> The name should be short and descriptive. It does not have to match the .shader file name.
</li><li> To put shaders in submenus in Unity, use slashes - E.g. &quot;MyShaders/test&quot; would be shown as &quot;Test&quot; in a submenu called &quot;MyShaders&quot;
</li></ul>

<h2>Properties</h2>
<p>At the beginning of the shader block you can define any properties that artists can edit. In the VertexLit example the properties looks like this:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/ShaderTut1-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/ShaderTut1-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>The properties are listed on separate lines within the Properties block. Each property starts with the internal name (<b>_Color</b>, <b>_MainTex</b>). After this comes some more info (in parenthises); the name that is shown in the material inspector, and the type of edit control used. After this, the default value is listed.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/ShaderTut1-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/ShaderTut1-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>The list of possible types are in the cheat sheet, along with a hirachial sheet of the way the command structure is built.
It is also possible to set a default value for a property. This is done by using the equals sign, and then the default value. In the example of the color, a default value should be a four component vector, which is written (1, 1, 1, 1) for an vector of ones.
</p>

<p>We now have our properties defined, and are ready to start writing the actual shader.
</p>

<h2> The Shader Body</h2>

<p><i>Before we move on, let's define the basic structure of a shader file.</i>
</p>

<p>Different graphic cards have different capabilities. To allow you to make full use of whatever hardware your user has, a shader can contain multiple subshaders. When Unity renders a shader, it will go over the subshaders and simply use the first one that the hardware supports.
</p>

<p><pre class='codelisting'>
Shader &quot;Test&quot; {
  // Properties here

  SubShader {
    // Subshader that requires fragment programs
  }
  SubShader {
    // Subshader that only requires vertex programs
  }
  SubShader {
    // SubShader that can run on anything.
  }
}
</pre>
</p>

<p>This system allows Unity to support all existing hardware and maximize the quality of each one. It does, however, result in some long shaders.
</p>

<p>Inside the each subshader block you set the render mode for this subshader. A complete list of available commands and the hierarchy can be found in the cheat sheet.
</p>

<h2> Passes</h2>
<p>Each subshader is a collection of passes. For each pass, the object geometry is rendered, so there must be at least one pass. The pass for our VertexLit shader looks like this:
</p>

<p><pre class='codelisting'>Pass {
  Material {
    Diffuse [_Color]
    Ambient [_Color]
    Shininess [_Shininess]
    Specular [_SpecColor]
    Emission [_Emission]	
  } 
  Lighting On
  SeperateSpecular On
  SetTexture [_MainTex] {
    constantColor [_Color]
    Combine texture * primary DOUBLE, texture * constant 
  }
}
</pre>
</p>

<p>Any commands defined in a pass configures the graphics hardware to render the geometry in a specific way.
</p>

<p>In the example above we have a <b>Material</b> block. This binds our property variables to the different parts of the OpenGL hardware. The command <b>Lighting On</b> turns on the standard OpenGl lighting, and <b>SeperateSpecular On</b> enables the use for a separate color for the specular highlight.
</p>

<p>All of these setups map very directly on to the OpenGL hardware API. To read more about this, consult the <a class="wiki"  href="http://fly.cc.fer.hr/~unreal/theredbook/">Red Book</a>.
</p>

<p>The next couple of commands are very important. They define the texture we want to use, and how to apply it in our rendering. The <b>SetTexture</b> command is followed by the property name of the texture we would like to use. This is followed by a block that defines how the texture is applied.
</p>

<p>Within this block we set a constant color value, namely the color of the material, _Color.
</p>

<p>In the next call we specify how to mix the texture with the color values.
We do this with the <b>Combine</b> command that specifies how to blend the texture with another, or with a color. Here <b>texture</b> is the image of the texture specified immediately above (<b>SetTexture</b>). <b>Primary</b> is the vertex color, calculated from the <b>Material</b> values set above. We then have a comma, which specify that we are now working on the alpha channel, so texture here means the alpha value of the texture and constant is the constant value we just described. Another important variable is called previous. This is the result of any previous Combine step, and can be used to apply the result from a previous step to combine several textures and/or colors with each other. The object will now be rendered with the information specified in the Pass scope.
</p>

<p>It is not necessary to start the rendering with a command or alike, it will begin automatically at the end of the pass block.
</p>

<p>We can put more passes into the shader - they would get rendered afterwards. For now, though, that is not nessesary  as we have the desired effect. Also, we only need one subshader, as we make no use of advanced features - this particular shader will work on any card that Unity supports.
</p>

<p>The VertexLit shader is the most basic shader that we can think of. We did not use any hardware specific operations, nor did we utilize any of the more special and cool commands that the build in shading language has to offer.
</p>

<p>In the next chapter, we do something about that by discussing those additional and important concepts.
</p>



<p>Lets start with a small recap of the general structure of a shader:
</p>

<p><pre class='codelisting'>Shader &quot;ShaderName&quot;{
 {
  Properties {
    _Variable (&quot;name in Unitys material&quot;, type) = default value
  }
  Setup Renderstates that should apply to the whole category.
  SubShader {
    Setup rendering passes here, using fixed function or vertex/fragment programs.
    Pass {
    }
    .
    Pass {
    }
  }
  SubShader {
    This subshader should run of ARB cards with no vertex/fragment programs.
    Setup the rendering passes with fixed function commands.
    Pass {
    }
    .
  }
  FallBack &quot; VertexLit&quot;, 1
}
</pre>
To start at the end, we introduce a new command:
</p>

<p><tt> FallBack &quot; VertexLit&quot;, 1</tt>
</p>

<p>This command can be used at the end of a shader that might not work on every kind of hardware. It makes sure that another shader is used, if no subshader in the current shader can run. If you don't do this, you will get a fabulous sold gray on cards not supported by your shader.
</p>

<p>We will now discuss the different commands and scopes one by one, emphasising on what is possible with each command. We start with the Properties:
</p>

<p><pre class='codelisting'>Properties {
    _Variable (&quot;name in Unitys material&quot;, type) = default value
}
</pre>
</p>

<p>As mentioned above _Variable is the variable name, followed by the textstring name and type in parentheses. The variable name should allways begin with an underscore, but otherwise you can use any combination of letters and numbers for the name. The text name is completely free - here you can use any combination of characters. The type should be one of the following types allowed in shaders:
</p>

<p><table class="wikitable"><tr><td class="wikicell" >Color </td><td class="wikicell" >Four component color value - (1,1,1,1).</td></tr><tr><td class="wikicell" >2d </td><td class="wikicell" > 2D texture - &quot;white&quot;</td></tr><tr><td class="wikicell" >Cube </td><td class="wikicell" > Cubemap - &quot;&quot;</td></tr><tr><td class="wikicell" >Range </td><td class="wikicell" >Floating point value with a specified range - 0.5 </td></tr></table>
</p>

<p>The default value depends on which type the programmer specified. In the type table above we give examples on which default values one could use. The default value &quot;white&quot; specifies a white texture image. Another supported value is &quot;bump&quot; which is a blue texture, ie. a bumpmap with no bumps but just regular normals.
</p>

<p>All the variables declared in the Properties scope will  be passed in from the material setting in Unity, and can be used in the body of the shader.
</p>

<p>The next command is the Category. This is a shortcut for defining commonly used shader settings. Any command issued here will be the default in this block. You can override them in a sub-block. In that case the new command becomes valid any blocks contained within. The following state change commands are the ones most commonly used:
</p>

<p><table class="wikitable"><tr><td class="wikicell" >Blend </td><td class="wikicell" > Set the blending mode. Example: Blend One One</td></tr><tr><td class="wikicell" >Lighting </td><td class="wikicell" > Enable or Disable Lighting. Example: Lighting ON</td></tr><tr><td class="wikicell" >Fog </td><td class="wikicell" >Set fog state. Example Fog _fogStart</td></tr></table>
</p>

<p>For a complete list of commands see the Reference Chart.
</p>

<p>The SubShaders should be used to differentiate between different hardware capabilites as discussed earlier. Hence, the different subshaders you use indirectly specifies which render path will be chosen, and how many resources the shader will use during rendering. The subshader can use render state commands, and have any number of passes.
</p>

<p>A quick way of building subshaders is to use passes defined by other subshaders; the command UsePass does just that, so you can reuse shader code in a neat fasion. As an example the following command calls the pass with the name BASE from the glossy shader:
</p>

<p><tt> UsePass &quot; Glossy/BASE&quot;</tt>
</p>

<p>In order for the UsePass to work, a name must be given to the pass one wishes to use. The command: Name &quot;passName&quot; within a pass gives the name passName to the respective pass.
</p>

<h1> Vertex and fragment programs</h1>
<p>We descriped a pass that just used a single combine instruction earlier. Now it is time to demonstrate how we can use a vertex and a fragment program in our pass. The following code demonstrates the more advanced pass of the build in BumpSpec shader, that performs bump mapping with specular highlighting.
</p>

<p><pre class='codelisting'>Pass { 
	Name &quot;PPL&quot;	
	// 0-tex lights.
	Tags {
		&quot;LightMode&quot; = &quot;Pixel&quot; 
		&quot;LightTexCount&quot; = &quot;012&quot;
	}
CGPROGRAM
// profiles arbfp1
// fragment frag
// fragmentoption ARB_fog_exp2
// fragmentoption ARB_precision_hint_fastest

// vertex vert
// autolight 7
#include &quot;UnityCG.cginc&quot;
#include &quot;AutoLight.cginc&quot; 

struct appdata {
	float4 vertex;
	float4 tangent;
	float3 normal;
	float4 texcoord;
};

struct v2f { 
	// Data that should be used by the vertex program and send to the fragment program
}; 

v2f vert (appdata v) {
	return v2f data;
}

uniform sampler2D _BumpMap;
uniform float _Shininess;
float4 frag (v2f2 i, LIGHTDECL(TEXUNIT2))  : COLOR  {
	return color to screen; 
}
</pre>
</p>

<p>Here we have omittet the actual code in the vertex and fragment programs to save space and keep it easy to read. The tag command in the pass specifies when this pass should be run, namely only when the lightmode is set to per pixel lighting, and when there is more than 0, 1 or 2 pixel lights in the scene. Other examples would be: &quot;LightMode&quot; = &quot;None&quot; or &quot;LightMode&quot; = &quot;Vertex&quot;. See all configurations in the Reference Chart.
</p>

<p>The next token: CGPROGRAM specifies that the following code is a program written in Nvidias C for Graphics (commonly known as Cg). The following lines specify that we have a fragment program called frag, we use the arbfp1 profile for the program and we set the two options ARB_fog_exp2 and ARB_precision_hint_fastest. We also have a vertex program called vert and we use the autolight option. (what is the  autolight option?)
In order to use the Cg language we also need to include the following two files:
</p>

<p><tt> #include &quot;UnityCG.cginc&quot;</tt>
</p>
<p><tt> #include &quot;AutoLight.cginc&quot;</tt>
</p>

<p>The struct appdata is now created. If the names and types specified here are used, the appropriate values are automatically bound to the variables specified in the struct. They are then ready for use in the vertex program. If the programmer wishes to use them in the fragment program she must output them to it herself.
The vertex program can now be put in. It is ofcause totally depending on the effect, but one command must allways be called:
</p>

<p><tt> o.hPosition = mul (glstate.matrix.mvp, v.vertex);</tt>
</p>

<p>It multiplies the current vertex position with the modelview matrix, called the clip space transformation.
</p>

<p>After the vertex program is done, the programmer should specify the variables used in the fragment program. This is done by the commands:
</p>

<p><tt> uniform sampler2D _BumpMap;</tt>
</p>
<p><tt> uniform float _Shininess;</tt>
</p>

<p>Here we specify the texture variable _BumpMap and floating point value _Shininess. These values is automatically set to the value specified in the material settings in Unity, because these were bound in the Properties step. They can then be directly accessed in the fragment program.
</p>

<p>After the fragment program it is important to specify the textures used by setting them. This should be done as the last thing in the pass scope. Setting the _BumpMap texture specified above should be done like this:
</p>

<p><tt> SetTexture [_BumpMap]{combine primary texture}</tt>
</p>

<p>You can now put in other passes as needed, or simply end this shader with some &quot;}&quot; charaters, and the shader is hopefully ready to run. If it does not compile, an error messag will be output int the bottom of the screen, telling you what and where the errors are.
</p>

<p>We have now demonstrated how advanced shader programs can be generated in a few easy steps. This can help you to take the full advantage of Unity and recieve optimal rendering results. We have a forum for shader at www.otee.dk/forum/ so go there to get help with your shaders!
</p>

<p>Happy programming, and enjoy the power of Unity and Shaderlab.
</p>



<p>The Shader is the root object of a shader file. Each file must define one (and only one) shader. It specifies how any objects whose material uses this shader is rendered.
</p>

<h2> Syntax</h2>
<p><dl><dt><code><b>Shader</b> &quot;<i>name</i>&quot; <b>{</b> [Properties] Subshaders [Fallback] <b>}</b></code></dt><dd> Defines a shader. It will appear in the material inspector listed under <b>name</b>. Shaders optionally can define a list of <b>properties</b> that show up as material settings. After this comes a list of SubShaders, and optionally a fallback.</dd></dl>
</p>

<h2> Details</h2>

<h3> Properties</h3>

<p>Shaders can have a list of <a href="../Manual/SL-Properties.html">properties</a>. Any properties declared in a shader are shown in the material inspector inside Unity. Typical properties are the object color, textures, or just arbitrary values to be used by the shader.
</p>

<h3> SubShaders &amp; Fallback</h3>

<p>Each shader is comprised of a list of <a href="../Manual/SL-SubShader.html">sub-shaders</a>. You must have at least one. When loading a shader, Unity will go through the list of subshaders, and pick the first one that is supported by the end user's machine. If no subshaders are supported, Unity will try to use <a href="../Manual/SL-Fallback.html">fallback shader</a>.
</p>

<p>Different graphic cards have different capabilities. This raises an eternal issue for game developers; you want your game to look great on the latest hardware, but don't want it to be available only to those 3% of the population. This is where subshaders come in. Create one subshader that has all the fancy graphic effects you can dream of, then add more subshaders for older cards. These subshaders may implement the effect you want in a slower way, or they may choose not to implement some details.
</p>

<h2> Examples</h2>

<p>Here is one of the simplest shaders possible:
<pre class='codelisting'>
// colored vertex lithing
Shader &quot;simple&quot; {
    // a single color property
    Properties {
        _Color (&quot;Main Color&quot;, Color) = (1,.5,.5,1)
    }
    // define one subshader
    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
            }
            Lighting On
        }
    }
}
</pre>
This shader defines a color property <i>_Color</i> (that shows up in material inspector as <i>Main Color</i>) with a default value of <code>(1, 0.5, 0.5, 1)</code>. Then a single subshader is defined. The subshader consists of one <a href="../Manual/SL-Pass.html">Pass</a> that turns on vertex lighting and sets up basic material for it.
</p>



<p>Shaders can define a list of parameters to be set by artists in Unity's material inspector. The Properties block in the shader file defines them.
</p>

<h2>Syntax</h2>
<p><dl><dt><b>Properties</b> { <i>Property</i> [<i>Property ...</i>] }</dt><dd> Defines the property block. Inside braces multiple properties are defined as follows.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Range</b> (<i>min</i>, <i>max</i>)) = <i>number</i></dt><dd> Defines a float property, represented as a slider from <i>min</i> to <i>max</i> in the inspector.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Color</b>) = (<i>number</i>,<i>number</i>,<i>number</i>,<i>number</i>)</dt><dd> Defines a color property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>2D</b>) = &quot;<i>name</i>&quot;</dt><dd> Defines a 2D texture property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Rect</b>) = &quot;<i>name</i>&quot;</dt><dd> Defines a rectangle (non power of 2) texture property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Cube</b>) = &quot;<i>name</i>&quot;</dt><dd> Defines a cubemap texture property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Float</b>) = <i>number</i></dt><dd> Defines a float property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Vector</b>) = (<i>number</i>,<i>number</i>,<i>number</i>,<i>number</i>)</dt><dd> Defines a four component vector property.</dd></dl>
</p>

<h2>Details</h2>

<p>Each property inside the shader is referenced by <b>name</b> (in Unity, it's common to start shader property names with underscore). The property will show up in material inspector as <b>display name</b>. For each property a default value is given after equals sign:
</p>
<ul><li> For <i>Range</i> and <i>Float</i> properties it's just a single number.
</li><li> For <i>Color</i> and <i>Vector</i> properties it's four numbers in parentheses.
</li><li> For texture (<i>2D</i>, <i>Rect</i>, <i>Cube</i>) the default value is either an empty string, or one of builtin default textures: &quot;<i>white</i>&quot;, &quot;<i>black</i>&quot;, &quot;<i>gray</i>&quot; or &quot;<i>bump</i>&quot;.
</li></ul>

<p>Later on in the shader, property values are accessed using property name in square brackets: <b>[name]</b>.
</p>

<h2>Example</h2>
<p><pre class='codelisting'>
Properties {
    // properties for water shader
    _WaveScale (&quot;Wave scale&quot;, Range (0.02,0.15)) = 0.07 // sliders
    _ReflDistort (&quot;Reflection distort&quot;, Range (0,1.5)) = 0.5
    _RefrDistort (&quot;Refraction distort&quot;, Range (0,1.5)) = 0.4
    _RefrColor (&quot;Refraction color&quot;, Color)  = (.34, .85, .92, 1) // color
    _ReflectionTex (&quot;Environment Reflection&quot;, 2D) = &quot;&quot; // textures
    _RefractionTex (&quot;Environment Refraction&quot;, 2D) = &quot;&quot;
    _Fresnel (&quot;Fresnel (A) &quot;, 2D) = &quot;&quot;
    _BumpMap (&quot;Bumpmap (RGB) &quot;, 2D) = &quot;&quot;
}
</pre>
</p>



<p>Each shader in Unity consists of a list of subshaders. When Unity has to display a mesh, it will find the shader to use, and pick the first subshader that runs on the user's graphics card.
</p>

<h2>Syntax</h2>

<p><dl><dt><b>Subshader</b> <b>{</b> [<i>CommonState</i>] <i>Passdef</i> [<i>Passdef ...</i>] <b>}</b></dt><dd> Defines the subshader as optional common state and a list of pass definitions.</dd></dl>
</p>

<h2>Details</h2>

<p>A subshader defines a list of <a href="../Manual/SL-Pass.html"> rendering passes</a> and optionally setup any state that is common to all passes.
</p>

<p>When Unity chooses which subshared to render with, it renders an object once for each Pass defined (and possibly more due to light interactions). As each render of the object is an expensive operation, you want to define the shader in minimum amount of passes possible. Of course, sometimes on some graphics hardware the needed effect can't be done in a single pass; then you have no choice but to use multiple passes.
</p>

<p>Each pass definition can be a <a href="../Manual/SL-Pass.html"> regular Pass</a>, a <a > Use Pass</a> or a  <a href="../Manual/SL-GrabPass.html"> Grab Pass</a>.
</p>

<p>Any statements that are allowed in a Pass definition can also appear in Subshader block. This will make all passes use this &quot;shared&quot; state.
</p>

<h2>Example</h2>

<p><pre class='codelisting'>
SubShader {
    Pass {
        Lighting Off
        SetTexture [_MainTex] {}
    }
}
</pre>
This subshader defines a single Pass that turns off any lighting and just displays a mesh with texture named <i>_MainTex</i>.
</p>


<p>The Pass block causes the geometry of an object to be rendered once.
</p>

<h2>Syntax</h2>
<p><dl><dt><b>Pass</b> <b>{</b> <i>[Name and Tags]</i> <i>[RenderSetup]</i> <i>[TextureSetup]</i> <b>}</b> </dt><dd> The basic pass command contains an optional list of render setup commands, optionally followed by a list of textures to use.</dd></dl>
</p>

<h3> Name and tags</h3>

<p>A Pass can define it's name and arbitrary number of Tags - name/value strings that communicate Pass' intent to the rendering engine. More details <a href="../Manual/SL-NameAndTags.html"> here</a>.
</p>

<h3> Render Setup</h3>
<p><dl><dt><b>Material</b> <b>{</b> <i>Material Block</i> <b>}</b></dt><dd> Defines a material to use in a vertex lighting pipeline.</dd><dt><b>Lighting</b> On | Off</dt><dd> Turn vertex lighting on or off.</dd><dt><b>SeparateSpecular</b> On | Off</dt><dd> Turns separate specular color for vertex lighting on or off.</dd><dt><b>Cull</b> Back | Front | Off</dt><dd> Set polygon culling mode.</dd><dt><b>ZTest</b> Less | Greater | LEqual | GEqual | Always</dt><dd> Set depth testing mode.</dd><dt><b>ZWrite</b> On | Off</dt><dd> Set depth writing mode.</dd><dt><b>Fog</b></dt><dd></dd><dt><b>AlphaTest</b> (Less | Greater | LEqual | GEqual) <i>CutoffValue</i></dt><dd> Turns on alpha testing.</dd><dt><b>Blend</b> <i>SourceBlendMode</i> <i>DestBlendMode</i></dt><dd></dd><dt><b>Color</b> <i>Color value</i></dt><dd> Sets color to use if vertex lighting is turned off.</dd><dt><b>ColorMask</b> RGB | A | or any combination of R, G, B, A</dt><dd> Set color writing mask.</dd><dt><b>DepthOffset</b></dt><dd></dd></dl>
</p>

<h3> Texture Setup</h3>
<p>After the render setup, you can specify a number of textures and their combining modes to apply.
<dl><dt><b>SetTexture</b> <i>texture property</i> { <i>[Combine options]</i> }</dt><dd></dd></dl>
</p>


<h2>Details</h2>

<h3> Lighting</h3>

<p>The per-pixel lighting pipeline works by rendering objects in multiple passes. Unity renders the object once to get ambient and any vertex lights in. Then it renders each pixel light affecting the object in a separate additive pass.
</p>

<p>This is where the performance-critical PixelLightCount in <a href="../Components/class-RenderSettings.html"> Render Settings</a> variable comes in. If the pixel light count is 4, Unity renders an object 5 times, whereas if it is 0 (effectively turning off all pixel effects such as bumpmapping), Unity only renders the VertexLit pass.
</p>

<h2> See Also</h2>

<p>There are a selection of special passes available for reusing common functionality or implementing various high-end effects:
<dl><dt><a >UsePass</a></dt><dd> Includes named passes from another shader.</dd><dt><a href="../Manual/SL-GrabPass.html">GrabPass</a></dt><dd> Grabs the contents of the screen into a texture, for use in a later pass.</dd><dt><a >OffScreenPass</a></dt><dd> Works like a normal pass, but renders into a texture. Used for deferred shading or special effects.</dd></dl>
</p>

<h2> Subsections</h2>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Material.html">SL-Material</a></li><li class="toclevel"><a href="../Manual/SL-CullAndDepth.html">SL-CullAndDepth</a></li><li class="toclevel"><a href="../Manual/SL-SetTexture.html">SL-SetTexture</a></li><li class="toclevel"><a href="../Manual/SL-Fog.html">SL-Fog</a></li><li class="toclevel"><a href="../Manual/SL-AlphaTest.html">SL-AlphaTest</a></li><li class="toclevel"><a href="../Manual/SL-Blend.html">SL-Blend</a></li><li class="toclevel"><a href="../Manual/SL-NameAndTags.html">SL-NameAndTags</a></li><li class="toclevel"><a href="../Manual/SL-BindChannels.html">SL-BindChannels</a></li></ul>
</p>



<p>The material and lighting parameters are used to control the built-in vertex lighting.
</p>

<p>Pixel lights are usually implemented with custom vertex/fragment programs and don't use vertex lighting. For these you don't use any of the commands described here, instead you define your own <a > vertex and fragment programs</a> where you do all lighting, textuting and anything else yourself.
</p>

<p><map name="GraffleExportLight">
	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling">
	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest">
	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend">
	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog">
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-SetTexture">
</map>
<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/SL-Material-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/SL-Material-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Vertex Coloring &amp; Lighting is the first effect to gets calculated for any rendered geometry. It operates on the vertex level, and calculates the base color that is used before textures are applied.
</p>

<h2>Syntax</h2>
<p>The toplevel commands control whether to use OpenGL lighting or not, and some configuration options. The main setup is in the <b>Material Block</b>, detailed further below.
<dl><dt><b>Color</b> <i>Color</i></dt><dd> Sets the object to a solid color. A color is either four RGBA values in parenthesis, or a color property name in square brackets.</dd><dt><b>Material</b> <b>{</b> <i>Material Block</i> <b>}</b></dt><dd>The Material block is used to define the material properties of the object.</dd><dt><b>Lighting</b> On | Off</dt><dd> For the settings defined in the Material block to have any effect, you must enable Lighting with the <i>Lighting On</i> command. If lighting is off instead, the color is taken straight from the <i>Color</i> command.</dd><dt><b>SeperateSpecular</b> On | Off</dt><dd> This command makes specular lighting be added to the end of the shader pass, so specular lighting is unaffected by texturing. Only has effect when <i>Lighting On</i> is used.</dd></dl>
</p>

<h3>Material Block</h3>

<p>This contains settings for how the material reacts to the light. Any of these properties can be left out, in which case they default to black (i.e. have no effect).
</p>

<p><dl><dt><b>Diffuse</b> <i>Color</i></dt><dd> The diffuse color component. This is an object's base color.</dd><dt><b>Ambient</b> <i>Color</i></dt><dd> The ambient color component. This is the color the object has when it's hit by the ambient light set in the <a href="../Components/class-RenderSettings.html">RenderSettings</a>.</dd><dt><b>Specular</b> <i>Color</i></dt><dd> The color of the object's specular highlight.</dd><dt><b>Shininess</b> <i>Number</i></dt><dd> The sharpness of the highlight, between 0 and 1. At 0 you get a huge highlight that looks a lot like diffuse lighting, at 1 you get a tiny speck.</dd><dt><b>Emission</b> <i>Color</i></dt><dd> The color of the object when it is not hit by any light.</dd></dl>
</p>

<p>The full color of lights hitting the object is:
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'><p><b>Ambient</b> * <a href="../Components/class-RenderSettings.html"> RenderSettings ambient setting</a> + <br>(Light color * <b>Diffuse</b> + Light Color * <b>Specular</b>) + <br><b>Emission</b>
</p>
<p></div></div></td></tr></table>
</p>

<p>The light parts of the equation (within parenthesis) is repeated for all lights that hit the object.
</p>

<p>Typically you want to keep the Diffuse and Ambient colors the same (all builtin Unity shaders do this).
</p>

<h2>Examples</h2>

<p>Always render object in pure red:
<pre class='codelisting'>
Shader "Solid Red" {
    SubShader {
        Pass {
            Color (1,0,0)
        }
    }
}
</pre>
</p>


<p>Basic Shader that colors the object white and applies vertex lighting:
<pre class='codelisting'>
Shader "VertexLit White" {
    SubShader {
        Pass {
            Material {
                Diffuse (1,1,1,1)
                Ambient (1,1,1,1)
            }
            Lighting On
        }
    }
}
</pre>
</p>


<p>An extended version that adds material color as a property visible in Material Inspector:
<pre class='codelisting'>
Shader "VertexLit Simple" {
    Properties {
        _Color ("Main Color", COLOR) = (1,1,1,1)
    }
    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
                Ambient [_Color]
            }
            Lighting On
        }
    }
}
</pre>
</p>


<p>And finally, a full fledges vertex-lit shader (see also <a href="../Manual/SL-SetTexture.html">SetTexture</a> reference page):
<pre class='codelisting'>
Shader "VertexLit" {
    Properties {
        _Color ("Main Color", Color) = (1,1,1,0)
        _SpecColor ("Spec Color", Color) = (1,1,1,1)
        _Emission ("Emmisive Color", Color) = (0,0,0,0)
        _Shininess ("Shininess", Range (0.01, 1)) = 0.7
        _MainTex ("Base (RGB)", 2D) = "white" {}
    }

    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
                Ambient [_Color]        
                Shininess [_Shininess]
                Specular [_SpecColor]
                Emission [_Emission]    
            } 
            Lighting On
            SeperateSpecular On
            SetTexture [_MainTex] {
                Combine texture * primary DOUBLE, texture * primary
            } 
        } 
    }
}
</pre>
</p>




<p><map name="GraffleExportCull">
<!--	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling"> -->
	<area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material">
	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest">
	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend">
	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog">
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-Texture">
</map>
Culling is used as an optimization to not render polygons facing away from the viewer.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/SL-CullAndDepth-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/SL-CullAndDepth-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>All polygons have a front and a back side. Culling makes use of the fact that most objects are closed; if you have a cube, you will never see the sides facing away from you - there is always a side facing you in front of it - hence we don't need to draw the sides facing away from you. Hence the term: Backface culling
</p>

<p>The other feature that makes rendering looks correct is Depth testing. Depth testing makes sure that only the foremost objects are drawn in a scene.
</p>

<h2> Syntax</h2>
<p><dl><dt>Cull Back | Front | Off</dt><dd> Controls which sidedness of polygons should be culled (not drawn)</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Back</b> Don't render polygons facing away from the viewer (default).</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Front</b> Don't render polygons facing towards the viewer. Used for turning objects inside-out.</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Off</b> Disables culling - all faces are drawn. Used for special effects.</dd></dl>
<dl><dt>ZWrite On | Off</dt><dd> Controls whether pixels from this object are written to the depth buffer (the default). If you're making solid objects, leave this on. If you're making semitransparent effects, switch to ZWrite Off. For full info, read below.</dd><dt>ZTest <i>ZTestMode</i></dt><dd> </dd><dt>DepthOffset</dt><dd> </dd></dl>
</p>

<h2> Details</h2>
<p>Depth Testing explained.
</p>

<p>Drawing transparent objects Back To Front.
</p>

<h2> Examples</h2>

<p>This object will render only the backfaces of an object:
<pre class='codelisting'>
Shader "Show Insides" {
	SubShader {
		Pass {
			Material {
				Diffuse (1,1,1,1)
			}
			Lighting On
			Cull Front
		}
	}
}
</pre>
Try to apply it to a cube, and notice how the geometry feels all wrong when you orbit around it. This is because you're only seeing the inside parts of the cube.
</p>

<h3> Debugging Normals</h3>
<p>The nex one is more interesting; first we render the object with normal vertex lighting, then we render the backfaces in bright pink. This has the effects of highlighting anywhere your normals need to be flipped. If you see physically-controlled objects getting 'sucked in' by any meshes, try to assign this shader to them. If any pink parts are visible, these parts will pull in anything unfortunate enough to touch it.
</p>

<p>Here we go:
<pre class='codelisting'>
Shader "Reveal Backfaces" {
	Properties {
		_MainTex ("Base (RGB)", 2D) = "white" { }
	}
	SubShader {
		// Render the front-facing parts of the object. 
		// We use a simple white material, and apply the main texture.
		Pass {
			Material {
				Diffuse (1,1,1,1)
			}
			Lighting On
			SetTexture [_MainTex] { 
				Combine Primary * Texture
			}
		}

		// Now we render the back-facing triangles in the most 
		// irritating color in the world: BRIGHT PINK!
		Pass {
			Color (1,0,1,1)
			Cull Front
		}
	}
}
</pre>
</p>

<h3> Glass Culling</h3>
<p>Controlling Culling is useful for more than debugging backfaces. If you have transparent objects, you quite often want to show the backfacing side of an object. If you render without any culling (<b>Cull Off</b>), you'll most likely have some rear faces overlapping some of the front faces.
</p>

<p>MORE TEXT HERE
</p>

<p>Here is a simple shader that will work for convex objects (spheres, cubes, car windscreens).
<pre class='codelisting'>
SubShader "Simple Glass" {
	Properties {
		_Color ("Main Color", Color) = (1,1,1,0)
		_SpecColor ("Spec Color", Color) = (1,1,1,1)
		_Emission ("Emmisive Color", Color) = (0,0,0,0)
		_Shininess ("Shininess", Range (0.01, 1)) = 0.7
		_MainTex ("Base (RGB)", 2D) = "white" { }
	}

	SubShader {
		// We use the material in many passes by defining them in the subshader.
		// Anything defined here becomes default values for all contained passes.
		Material {
			Diffuse [_Color]
			Ambient [_Color]        
			Shininess [_Shininess]
			Specular [_SpecColor]
			Emission [_Emission]    
		} 
		Lighting On	
		SeperateSpecular On

		// Set up alpha blending
		Blend SrcAlpha OneMinusSrcAlpha

		// Render the back facing parts of the object. 
		// If the object is convex, these will always be further away
		// than the front-faces.
		Pass {
			Cull Front
			SetTexture [_MainTex] { 
				Combine Primary * Texture
			}
		}
		// Render the parts of the object facing us.
		// If the object is convex, these will be closer than the 
		// back-faces.
		Pass {
			Cull Back
			SetTexture [_MainTex] { 
				Combine Primary * Texture
			}
		}
	}
}
</pre>
</p>



<p>After the basic vertex lighting has been calculated, textures are applied. In ShaderLab this is done using <b>SetTexture</b> command.
</p>

<p>Note that if you use <a > fragment programs</a>, all texture combiner modes are ignored. You only need to write empty <i>SetTexture</i> command.
</p>

<p><map name="GraffleExportTexture">
</p>
<p><tt> <area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling"></tt>
</p>
<p><tt> <area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material"></tt>
</p>
<p><tt> <area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest"></tt>
</p>
<p><tt> <area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend"></tt>
</p>
<p><tt> <area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog"></tt>
</map>
<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/SL-SetTexture-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/SL-SetTexture-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Texturing is the place to do old-style combiner effects. You can have multiple SetTexture commands inside a pass - all textures are applied in sequence, like layers in a painting program. SetTexture commands must be placed at the end of a <a href="../Manual/SL-Pass.html">Pass</a>.
</p>

<h2>Syntax</h2>
<p><dl><dt><b>SetTexture</b> <i>[TexturePropertyName]</i> <b>{</b> <i>Texture Block</i> <b>}</b></dt><dd> Assigns a texture. <i>TextureName</i> must be defined as a texture property. How to apply the texture is defined inside the <i>TextureBlock</i>.</dd></dl>
</p>

<h3> Texture Block</h3>
<p>The texture block controls how the texture is applied.
</p>

<p><dl><dt>combine <i>src1</i> * <i>src2</i></dt><dd> Multiplies src1 and src2 together. The result will be darker than either input.</dd><dt>combine <i>src1</i> + <i>src2</i></dt><dd> Adds  src1 and src2 together. The result will be lighter than either input.</dd><dt>combine <i>src1</i> - <i>src2</i></dt><dd>  subtracts src2 from src1.</dd><dt>combine <i>src1</i> +- <i>src2</i></dt><dd> Adds src1 to src2, then subtracts .5. </dd><dt>combine <i>src1</i> lerp (<i>src2</i>) <i>src3</i></dt><dd> Alphablends between src1 and src3, using the alpha of src3.</dd><dt>combine <i>src1</i> * <i>src2</i> + <i>src3</i></dt><dd> Multiplies src1 with the alpha component of src2, then adds src3.</dd><dt>combine <i>src1</i> * <i>src2</i> +- <i>src3</i></dt><dd> Multiplies src1 with the alpha component of src2, then does a signed add with src3.</dd><dt>combine <i>src1</i> * <i>src2</i> - <i>src3</i></dt><dd>  Multiplies src1 with the alpha component of src2, then adds src3.</dd></dl>
</p>

<p><dl><dt></dt><dd>All the <b>src</b> properties can be either one of <i>previous</i>, <i>constant</i>, <i>primary</i> or <i>texture</i>. </dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Previous</b> is the the result of the previous SetTexture.</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Primary</b> is the color from the <a href="../Manual/SL-Material.html">lighting calculation</a> or the vertex color if it is <a href="../Manual/SL-BindChannels.html">bound</a>.</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Texture</b> is the color of the texture specified by <i>[_TextureName]</i> in the SetTexture (see above).</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Constant</b> is the color specified in <b>ConstantColor</b>, described below.</dd></dl>
<dl><dt></dt><dd> The formula specified above can optionally be followed by the keywords <b>Double</b> or <b>Quad</b> to make the resulting color 2x or 4x as bright.</dd></dl>
<dl><dt>ConstantColor <i>color</i></dt><dd> Defines a constant color that can be used in the values above.</dd></dl>
</p>

<h2> Details</h2>

<p>Older graphics cards use a layered approach to textures. The textures are applied one after each other, modifying the color that will be written to the screen. For each texture, the texture is typically combined with the result of the previous operation.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/SL-SetTexture-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/SL-SetTexture-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h3> Separate Alpha &amp; Color blending</h3>
<p>By default, the combiner formula is used for calculating both the RGB and alpha component of the color settexture. Optionally, you can specify a separate formula for the alpha calculation. This looks like this:
</p>

<p><pre class='codelisting'>
SetTexture [_MainTex] { combine previous * texture, previous + texture }
</pre>
</p>

<p>Here, we multiply the RGB colors and add the alpha.
</p>

<h3> Specular highlights</h3>
<p>By default the <b>primary</b> color is the sum of the diffuse, ambient and specular colors (as defined in the <a href="../Manual/SL-Material.html">Lighting calculation</a>). If you specify <b>SeperateSpecular On</b> in the pass options, the specular color will be added in <i>after</i> the combiner calculation, rather than before. This is the default behavior of the built-in VertexLit shader.
</p>

<h3> Graphic cards</h3>
<p>The combiner options are supported by the following graphic cards: NVidia TNT, NVidia GeForce (all versions), ATI Rage, ATI Radeon (all versions). The number of <b>SetTexture</b> blocks you can have is also dependant on the card:
</p>

<p><dl><dt>ATI Rage</dt><dd>2 SetTexture commands only. Does not support the following combiner modes - combine&nbsp;src1&nbsp;*&nbsp;src2&nbsp;+&nbsp;src3, combine&nbsp;src1&nbsp;*&nbsp;src2&nbsp;+-&nbsp;src3 or combine&nbsp;src1&nbsp;*&nbsp;src2&nbsp;-&nbsp;src3.</dd><dt>ATI Radeon 7500</dt><dd> 3 SetTexture commands. Supports all combiner modes</dd><dt>ATI Radeon 8500, 9000, 9200</dt><dd> 6 SetTexture commands. Supports all combiner modes</dd><dt>ATI Radeon 9500 and above</dt><dd> 8 SetTexture commands.</dd><dt>NVidia TNT, GeForce 1, GeForce 2, GeForce 4MX</dt><dd> 2 SetTexture commands. Supports all the combiner modes.</dd><dt>All later NVidia graphic cards</dt><dd> 4 SetTexture. Supports all the combiner modes.</dd></dl>
</p>

<h2> Examples</h2>

<h3> Alpha Blending Two Textures</h3>
<p>This small examples takes two textures. First it sets the first combiner to just take the <b>_MainTex</b>, then is uses the alpha channel of <b>_BlendTex</b> to fade in the RGB colors of <b>_BlendTex</b>
<pre class='codelisting'>
Shader "Examples/2 Alpha Blended Textures" {
	Properties {
		_MainTex ("Base (RGB)", 2D) = "white"
		_BlendTex ("Alpha Blended (RGBA) ", 2D) = "white" 
	}
	SubShader {
		Pass {
			// Apply base texture
			SetTexture [_MainTex] { 
				combine texture
			}
			// Blend in the alpha texture using the lerp operator
			SetTexture [_BlendTex] { 
				combine texture lerp (texture) previous
			}
		}
	} 
}
</pre>
</p>

<h3> Alpha Controlled Self-illumination</h3>
<p>This shader uses the alpha component of the <b>_MainTex</b> to decide where to apply lighting. It does this by applying the texture to two stages; In the first stage, the alpha value of the texture is used to blend between the vertex color and solid white. In the second stage, the RGB values of the texture are multiplied in.
</p>

<p><pre class='codelisting'>
Shader "Examples/Self-Illumination" {
	Properties {
		_MainTex ("Base (RGB) Self-Illumination (A)", 2D) = "white"
	}
	SubShader {
		Pass {
			// Set up basic white vertex lighting
			Material {
				Diffuse (1,1,1,1)
				Ambient (1,1,1,1)
			}
			Lighting On
			
			// Use texture alpha to blend up to white (= full illumination)
			SetTexture [_MainTex] {
				constantColor (1,1,1,1)
				combine constant lerp(texture) previous
			}
			// Multiply in texture
			SetTexture [_MainTex] {
				combine previous * texture
			}
		}
	} 
}
</pre>
</p>

<p>We can do something else for free here, though; instead of blending to solid white, we can add a self-illumination color and blend to that. Note the use of <b>ConstantColor</b> to get a _SolidColor from the properties into the texture blending.
</p>

<p><pre class='codelisting'>
Shader "Examples/Self-Illumination 2" {
	Properties {
		_IlluminCol ("Self-Illumination color (RGB)", Color) = (1,1,1,1)
		_MainTex ("Base (RGB) Self-Illumination (A)", 2D) = "white"
	}
	SubShader {
		Pass {
			// Set up basic white vertex lighting
			Material {
				Diffuse (1,1,1,1)
				Ambient (1,1,1,1)
			}
			Lighting On
			
			// Use texture alpha to blend up to white (= full illumination)
			SetTexture [_MainTex] {
				// Pull the color property into this blender
				constantColor [_IlluminCol] 
				// And use the texture's alpha to blend between it and 
				// vertex color
				combine constant lerp(texture) previous
			}
			// Multiply in texture
			SetTexture [_MainTex] {
				combine previous * texture
			}
		}
	} 
}
</pre>
</p>

<p>And finally, we take all the lighting properties of the vertexlit shader and pull that in:
<pre class='codelisting'>
Shader "Examples/Self-Illumination 3" {
	Properties {
		_IlluminCol ("Self-Illumination color (RGB)", Color) = (1,1,1,1)
		_Color ("Main Color", Color) = (1,1,1,0)
		_SpecColor ("Spec Color", Color) = (1,1,1,1)
		_Emission ("Emmisive Color", Color) = (0,0,0,0)
		_Shininess ("Shininess", Range (0.01, 1)) = 0.7
		_MainTex ("Base (RGB)", 2D) = "white" { }
	}

	SubShader {
		Pass {
			// Set up basic vertex lighting
			Material {
				Diffuse [_Color]
				Ambient [_Color]        
				Shininess [_Shininess]
				Specular [_SpecColor]
				Emission [_Emission]    
			}
			Lighting On
			
			// Use texture alpha to blend up to white (= full illumination)
			SetTexture [_MainTex] {
				constantColor [_IlluminCol] 
				combine constant lerp(texture) previous
			}
			// Multiply in texture
			SetTexture [_MainTex] {
				combine previous * texture
			}
		}
	} 
}
</pre>
</p>




<p>Fogging blends the color of the generated pixels down towards a constant color based on distance from camera.
</p>

<p><map name="GraffleExportTextureFog">
	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling">
	<area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material">
	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest">
	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend">
<!--	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog"> -->
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-Texture">
</map>
<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/SL-Fog-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/SL-Fog-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Fogging does not modify a blended pixel's alpha value, only it's RGB components.
</p>

<h2> Syntax</h2>
<p>Fog {
</p>
<p><tt>  Mode</tt>
}
</p>



<p>The alpha test is a last chance to reject a pixel from being written to the screen.
</p>

<p><map name="alphatest">
	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling">
	<area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material">
<!--	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest"> -->
	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend">
	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog">
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-Texture">
</map>
<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/SL-AlphaTest-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/SL-AlphaTest-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>After the final output color has been calculated, the color can optionally have its alpha value compared to a fixed value. If the test fails, the pixel is not written to the display
</p>


<h2> Syntax</h2>
<p><dl><dt>AlphaTest Off</dt><dd> Render all pixels (default).</dd><dt>AlphaTest <i>comparison</i> <i>AlphaValue</i></dt><dd> Set up the alpha test to only render pixels whose alpha value is within a certain range.</dd></dl>
</p>

<h3>Comparison</h3>
<p>Comparison is one of the following words:
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>greater</nobr></b></td><td> Only render pixels whose alpha is greater than <i>AlphaValue</i>. Can be abbreviated as >
</td></tr><tr><td><b><nobr>gequal</nobr></b></td><td> Only render pixels whose alpha is greater than or equal to <i>AlphaValue</i>. Can be abbreviated as >=
</td></tr><tr><td><b><nobr>less</nobr></b></td><td>  Only render pixels whose alpha value is less than <i>AlphaValue</i>. Can be abbreviated as <
</td></tr><tr><td><b><nobr>lequal</nobr></b></td><td> Only render pixels whose alpha value is less than or equal to from <i>AlphaValue</i>. Can be abbreviated as <=
</td></tr><tr><td><b><nobr>equal</nobr></b></td><td>  Only render pixels whose alpha value equals <i>AlphaValue</i>. Can be abbreviated as =
</td></tr><tr><td><b><nobr>notequal</nobr></b></td><td> Only render pixels whose alpha value differ from <i>AlphaValue</i>. Can be abbreviated as !=
>=
</td></tr><tr><td><b><nobr>allways</nobr></b></td><td> Render all pixels. This is functionally equivalent to <i>AlphaTest Off</i>.
Never</td></tr></tr></table>
</p>

<h3> AlphaValue</h3>
<p>A floating-point number between 0 and 1. This can also be a variable reference to a float or a range, in which case it should be written using the standard square bracket notation (<i>[VariableName]</i>)
</p>

<h2> Details</h2>
<p>The alpha test is important when rendering concave objects with transparent parts. The graphics card maintains a record of the depth of every pixel written to the screen. If a new pixel is further away than one already rendered, the new pixel is not written to the display. This means that even with <a href="../Manual/SL-Blend.html">blending</a>, objects will not show through.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/SL-AlphaTest-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/SL-AlphaTest-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>In this figure, the tree on the left is rendered using <b>AlphaTest</b>. Note how the pixels in it are either completely transparent or Opaque. The center tree is rendered using only <b>alpha blending</b> - notice how transparent parts of nearby branches cover the distant leaves because of the depth buffer. The tree on the right is rendered using the last example shader - which implements a combination of blending and alpha testing to hide any artifacts.
</p>



<h2> Examples</h2>
<p>The simplest possible example, assign a texture with an alpha channel to it. The object will only be visible where alpha is greater than .5
</p>

<p><pre class='codelisting'>
Shader "Simple Alpha" {
	Properties {
		_MainTex ("Base (RGB) Transparency (A)", 2D) = "" {}
	}
	SubShader {
		Pass {
			// Only render pixels with an alpha larger than .5
			AlphaTest Greater .5
			SetTexture [_MainTex]
		}
	}
}
</pre>
</p>

<p>This is not much good by itself. Let us add some lighting and make the cutoff value tweakable
<pre class='codelisting'>
Shader "Cutoff Alpha" {
	Properties {
		_MainTex ("Base (RGB) Transparency (A)", 2D) = "" {}
		_Cutoff ("Alpha cutoff", Range (0,1)) = .5
	}
	SubShader {
		Pass {
			// Use the Cutoff parameter defined above to determine
			// what to render.
			AlphaTest Greater [_Cutoff]
			Material {
				Diffuse (1,1,1,1)
				Ambient (1,1,1,1)
			}
			Lighting On
			SetTexture [_MainTex] {
				combine texture * primary
			}
		}
	}
}
</pre>
</p>

<p>When rendering plants and trees, many games have the hard edges typical of alpha testing. A way around that is to render the object twice. In the first pass, we use alpha testing to only render pixels that are more than 50% opaque. In the second pass, we alpha-blend the graphic in the parts that were cut away, without recording the depth of the pixel. We might get a bit of confusion as further away branches overwrite the nearby ones, but in practice, that is hard to see  as leaves have a lot of visual detail in them.
</p>

<p><pre class='codelisting'>
Shader "Vegetation" {
	Properties {
		_Color ("Main Color", Color) = (.5, .5, .5, .5)
		_MainTex ("Base (RGB) Alpha (A)", 2D) = "white" {}
		_Cutoff ("Base Alpha cutoff", Range (0,.9)) = .5
	}
	SubShader {
		// Set up basic lighting
		Material {
			Diffuse [_Color]
			Ambient [_Color]
		}	
		Lighting On

		// Render both front and back facing polygons.
		Cull Off

		// first pass:
		//   render any pixels that are more than [_Cutoff] opaque
		Pass {	
			AlphaTest Greater [_Cutoff]
			SetTexture [_MainTex] {
				combine texture * primary, texture
			}
		}

		// Second pass:
		//   render in the semitransparent details.
		Pass {
			// Dont write to the depth buffer
			ZWrite off
			// Don't write pixels we have already written.
			ZTest Less
			// Only render pixels less or equal to the value
			AlphaTest LEqual [_Cutoff]
			
			// Set up alpha blending
			Blend SrcAlpha OneMinusSrcAlpha

			SetTexture [_MainTex] {
				combine texture * primary, texture
			}
		}
	}
}
</pre>
Note that we have some setup inside the SubShader, rather than in the individual passes. Any state set in the SubShader is inherited as defaults in passes inside it.
</p>



<p>Blend is used to make transparent objects.
</p>

<p><map name="GraffleExport">
	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling">
	<area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material">
	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest">
<!--	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend"> -->
	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog">
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-Texture">
</map>
<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/SL-Blend-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/SL-Blend-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>When graphics are rendered, after all shaders have executed and all textures have been applied, thye are written to the screen. How they are combined with what is already there is controlled by the Blend command.
</p>

<h2> Syntax</h2>
<p><dl><dt>Blend Off </dt><dd> Turn off blending</dd><dt>Blend <i>SrcFactor</i> <i>DstFactor</i></dt><dd> Configure &amp; enable color blending. The generated color is multiplied by the <b>SrcFactor</b>. The color already on screen is multiplied by <b>DstFactor</b> and the two are added together.</dd></dl>
</p>

<h2> Properties</h2>
<p>All following properties are valid for both SrcFactor &amp; DstFactor. <b>Source</b> refers to the calculated color, <b>destination</b> is the color already on the screen.
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>One</nobr></b></td><td> The value 1 - use this to let either the source or the destination color come through fully.
</td></tr><tr><td><b><nobr>Zero</nobr></b></td><td> The value 0 - use this to remove either the source or the destination values.
</td></tr><tr><td><b><nobr>SrcColor</nobr></b></td><td>  The value of this stage is multiplied by the source color value.
</td></tr><tr><td><b><nobr>SrcAlpha</nobr></b></td><td> The value of this stage is multiplied by the source alpha value.
</td></tr><tr><td><b><nobr>DstColor</nobr></b></td><td>  The value of this stage is multiplied by frame buffer source color value.
</td></tr><tr><td><b><nobr>DstAlpha</nobr></b></td><td> The value of this stage is multiplied by frame buffer source alpha value.
</td></tr><tr><td><b><nobr>OneMinusSrcColor</nobr></b></td><td> The value of this stage is multiplied by 1 - source color.
</td></tr><tr><td><b><nobr>OneMinusSrcAlpha</nobr></b></td><td> The value of this stage is multiplied by 1 - source alpha.
</td></tr><tr><td><b><nobr>OneMinusDstColor</nobr></b></td><td> The value of this stage is multiplied by 1 - destination.
</td></tr><tr><td><b><nobr>OneMinusDstAlpha</nobr></b></td><td> The value of this stage is multiplied by 1 - destination.
<p></td></tr></tr></table>
</p>

<h2> Details</h2>
<p>Below are the most common blend types.
<pre class='codelisting'>
Pass {
    Blend Off                           // No Blending (default)
    Blend SrcAlpha OneMinusSrcAlpha     // Alpha
    Blend One One                       // Additive 
    Blend One OneMinusDstColor          // Soft Additive
    Blend DstColor Zero                 // Multiplicative
    Blend DstColor SrcColor             // 2x Multiplicative
}
</pre>
</p>

<h2> Example</h2>
<p>Here is a small example shader that adds a texture to whatever is on the screen already:
<pre class='codelisting'>
Shader "Simple Additive" {
    Properties {
        _MainTex ("Texture to blend", 2D) = "black"  {}
    }
    SubShader {
        Blend One One
        SetTexture [_MainTex]	
    }
}
</pre>
</p>

<p>And a more complex one, Glass. This is a 2-pass shader:
</p>
<ol><li> The first pass renders a lighted, alpha-blended texture on to the screen. The alpha channel decides the transparency
</li><li> The second pass renders a reflection cubemap on top of the alpha-blended window, using additive transparency
</li></ol>


<p><pre class='codelisting'>
Shader "Glass" {
    Properties {
        _Color ("Main Color", Color) = (1,1,1,1)
        _MainTex ("Base (RGB) Transparency (A)", 2D) = "white"
        _Reflections ("Base (RGB) Gloss (A)", Cube) = "skybox" { TexGen CubeReflect }
    }
    SubShader {
        Pass {
            Tags {"Queue" = "Transparent" }
            Blend SrcAlpha OneMinusSrcAlpha
            Material {
                Diffuse [_Color]
            }
            Lighting On
            SetTexture [_MainTex] {
                combine texture * primary double, texture * primary
            }
        }
        Pass {
            Blend One One
            Material {
                Diffuse [_Color]
            }
            Lighting On
            SetTexture [_Reflections] {
                combine texture
                Matrix [_Reflection]
            }
        }
    } 
}
</pre>
</p>


<p>Passes and subshaders use tags to communicate back to the main rendering engine how and when they expect to be rendered. The tags available depends whether the block is inside a Pass or a SubShader.
</p>
<h2> Syntax</h2>
<p><dl><dt>Tags { &quot;<i>TagName1</i>&quot; = &quot;<i>Value1</i>&quot; &quot;<i>TagName2</i>&quot; = &quot;<i>Value2</i>&quot; }</dt><dd> Specifies <b>TagName1</b> to have <b>Value1</b>, <b>TagName2</b> to have <b>Value2</b>. You can have as many tags as you like.</dd></dl>
</p>
<h2> Details</h2>
<p>Tags are basic key-value pairs. Inside a SubShader tags are used to determine rendering order. Inside a pass, tags are used to control which role this pass has in the per-pixel lighting pipeline
</p>
<h3> SubShader Tags</h3>
<h3> Pass Tags</h3>

<h2> Examples</h2>
<h3></h3>



<p><b>BindChannels</b> command allows you to map vertex data from mesh data to the rendered triangles.
</p>

<p>By default, Unity figures out the bindings for you, but in some cases you want custom bindings to be used.
</p>

<p>For example you could map the primary UV set to be used in the first texture stage and the secondary UV set to be used in the second texture stage.
</p>

<h2> Syntax</h2>
<p><dl><dt><b>BindChannels</b> <b>{</b> <b>Bind</b> &quot;<i>source</i>&quot;, <i>target</i> <b>}</b> </dt><dd> Specifies <i>source</i> to be mapped to <i>target</i></dd></dl>
<b>Source</b> can be one of:
<dl><dt>Vertex</dt><dd> vertex position</dd><dt>Normal</dt><dd> vertex normal</dd><dt>Tangent</dt><dd> vertex tangent</dd><dt>Texcoord</dt><dd> primary UV coordinate</dd><dt>Texcoord1</dt><dd> secondary UV coordinate</dd><dt>Color</dt><dd> per-vertex color</dd></dl>
<b>Target</b> can be one of:
<dl><dt>Vertex</dt><dd> position input</dd><dt>Normal</dt><dd> normal input</dd><dt>Tangent</dt><dd> tangent input</dd><dt>Texcoord0, Texcoord1, ...</dt><dd> texture coordinates for corresponding texture stage</dd><dt>Texcoord</dt><dd> texture coordinates for all texture stages</dd><dt>Color</dt><dd> per-vertex color input</dd></dl>
</p>

<h2> Examples</h2>

<p><pre class='codelisting'>
// Maps the first UV set to the first texture stage
// and the second UV set to the second texture stage
BindChannels {
   Bind &quot;Vertex&quot;, vertex
   Bind &quot;texcoord&quot;, texcoord0
   Bind &quot;texcoord1&quot;, texcoord1
} 
</pre>
</p>

<p><pre class='codelisting'>
// Maps the first uv set to all texture stages
BindChannels {
   Bind &quot;Vertex&quot;, vertex
   Bind &quot;texcoord&quot;, texcoord
} 
</pre>
</p>

<p><pre class='codelisting'>
// Maps the first uv set to all texture stages
// and vertex colors to the per-vertex color
BindChannels {
   Bind &quot;Vertex&quot;, vertex
   Bind &quot;texcoord&quot;, texcoord
   Bind &quot;Color&quot;, color
} 
</pre>
</p>



<p>GrabPass is a special passtype - it grabs the contents of the screen where the object is about to be drawn into a texture. This texture can be used in subsequent passes to do advanced displacement effects.
</p>

<h2>Syntax</h2>
<p>The GrabPass belongs inside a subshader. All properties are optional.
</p>

<p><pre class='codelisting'>
GrabPass {
    Tags { &quot;RenderMode&quot; = &quot;VertexLit&quot; }
    Name BASE
    TextureScale .5
    TextureSize 256
    BorderScale .3
}
</pre>
</p>

<h2> Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Name</nobr></b></td><td> The name of this pass. Used in conjunction with <a >SL-UsePass</a>
</td></tr><tr><td><b><nobr>Tags</nobr></b></td><td> Any tags that you might want to set. See ((SL-Pass#Tags)) for docs.
</td></tr><tr><td><b><nobr>TextureSize</nobr></b></td><td> Specifies that you want the grabbed texture to have a certain pixel dimension.
</td></tr><tr><td><b><nobr>TextureScale</nobr></b></td><td> Specifies that you want the texture to be a certain scale of the object's screen size. This is the default behaviour.
</td></tr><tr><td><b><nobr>BorderScale</nobr></b></td><td> Specifies that you want to grab an extra region around the object. The value is relative to the object's bounding box.
<p></td></tr></tr></table>
</p>

<h2> Details</h2>

<h4> Screen Grabbing</h4>
<p>You can grab the screen behind the object being rendered in order to use it in a later pass. This is done with the GrabPass command. In a subsequent pass, you can access the grabbed screen distorting what is behind the object. This is typically used to create stained glass and other refraction-like effects.
</p>

<p>See <a href="../Manual/SL-GrabPass.html">GrabPass</a>.
</p>

<h4> Offscreen rendering</h4>
<p>Sometimes you want to render one or more passes into a temporary texture and then use this texture in a later pass (know as deferred shading). This is done using the OffScreenPass command
</p>

<p>See <a >OffScreenPass</a>.
</p>

<ul><li> The Region grabbed from the screen is available to subsequent passes as _GrabTexture.
</li><li> After grabbing, BorderScale gets converted into screenspace coords as _GrabBorderPixels. This is the maximum amount you can displace with in subsequent passes.
</li></ul>

<p>Unity will reuse the screen texture between different objects doing GrabPass. This means that one refractive object will not refract another.
</p>

<h2> Example</h2>

<h3> So Much For So Little</h3>
<p>Here is the most complex way ever of rendering nothing.
<pre class='codelisting'>
Shader &quot;ComplexInvisble&quot; {
    SubShader {
        // Grab the screen behind the object into _GrabTexture, using default values
        GrabPass { }
        
        // Render the object with the texture generated above.
        Pass {
            SetTexture [_GrabTexture] 
        }
    }
}
</pre>
</p>

<p>This shader has 2 passes: First pass grabs whatever is behind the object at the time of rendering, then applies that in the second pass. Note that the _GrabTexture is configured to display at the exact position of the object - hence it becomes transparent.
</p>

<h2> See Also</h2>
<ul><li> <a href="../Manual/SL-Pass.html">SL-Pass</a>
</li><li> <a >SL-OffScreenPass</a>
</li></ul>



<p>After all Subshaders a Fallback can be defined. It basically says &quot;if none of subshaders can run on this hardware, try using the ones from another shader&quot;.
</p>

<h2> Syntax</h2>
<p><dl><dt><b>Fallback</b> &quot;name&quot;</dt><dd> Fallback to shader with a given <i>name</i>.</dd><dt><b>Fallback off</b></dt><dd> Explicitly state that there is no fallback and no warning should be printed, even if no subshaders can run on this hardware.</dd></dl>
</p>

<h2> Details</h2>

<p>A fallback statement has the same effect as if all subshaders from the other shader would be inserted into it's place.
</p>

<h2> Example</h2>

<p><pre class='codelisting'>
Shader &quot;example&quot; {
    // properties and subshaders here...
    Fallback &quot;otherexample&quot;
}
</pre>
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Reference - Structure-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Reference - Structure-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h2>Tags</h2>


<h3>RenderQueue</h3>
<p>Unity renders all objects in 4 render queues in order to make effects like transparency work properly. A Shader decides which render queue any objects using it belongs to.
</p>

<p><table class="wikitable"><tr><td class="wikicell" >Background</td><td class="wikicell"  colspan="2">This render queue is rendered before any others. It is used for skyboxes and the like.</td></tr><tr><td class="wikicell" >Geometry (default)</td><td class="wikicell"  colspan="2">This render queue is rendered in whatever way is fastest for the end user's hardware (sorted by shaders, textures in order to minimize state changes). This is where normal opaque geometry goes</td></tr><tr><td class="wikicell" >Transparent</td><td class="wikicell"  colspan="2">This render queue is rendered in back-to-front order. Anything alpha-blended should go here (glass, particle effects)</td></tr><tr><td class="wikicell" >overlay</td><td class="wikicell"  colspan="2">This render queue is meant for overlay effects. Anything rendered last should go here (e.g. lens flares)</td></tr></table>
</p>


<h3>LightMode</h3>

<p><table class="wikitable"><tr><td class="wikicell" >VertexOnly(default)</td><td class="wikicell"  colspan="2"> This is executed once with the setup for vertexlighting</td></tr><tr><td class="wikicell" >Vertex</td><td class="wikicell"  colspan="2"> This is used if we have vertex lighted lights</td></tr><tr><td class="wikicell" >Pixel</td><td class="wikicell"  colspan="2"> This is executed if we have any lights that do pixelshading</td></tr><tr><td class="wikicell" >PixelOnly</td><td class="wikicell"  colspan="2"> This is executed if we have no vertex lights.  </td></tr><tr><td class="wikicell" >NoLights</td><td class="wikicell"  colspan="2"> This is executed if we have no lights at all</td></tr></table>
<b>combinations</b>
</p>

<p><table class="wikitable"><tr><td class="wikicell" ><b>Light type</b> </td><td class="wikicell"  colspan="2"> <b>Passes rendered</b></td></tr><tr><td class="wikicell" >No lights </td><td class="wikicell"  colspan="2"> NoLights</td></tr><tr><td class="wikicell" >Vertex only</td><td class="wikicell"  colspan="2"> Vertex, VertexOnly</td></tr><tr><td class="wikicell" >Pixel only</td><td class="wikicell"  colspan="2"> Pixel, PixelOnly</td></tr><tr><td class="wikicell" >Both </td><td class="wikicell"  colspan="2">  vertex, pixel</td></tr></table>
</p>

<h3>LightCount</h3>
<p>If LightType is Pixel or PixelOnly, this sets how many ppl lights are set up for each pass.
If this is set to zero, the pass is executed once with no lights (good for doing a single pass after summing light contributions.
<table class="wikitable"><tr><td class="wikicell" >LightCount</td><td class="wikicell"  colspan="2">How many lights can we do in 1 pass</td></tr></table>
</p>


<h3>LOD</h3>
<p>Which level-of-detail this subshader is for. It works as follows:
When we have to find a shader for a given LOD, we first try the requested LOD, then increase the LOD value until we find one that matches. We pick the first shader inside a LOD and use that for everything.
<table class="wikitable"><tr><td class="wikicell" >0 Many passes, vertex programs</td><td class="wikicell"  colspan="2">This is as good as its going to get. We don\'t really care how many passes it takes to implement an effect</td></tr><tr><td class="wikicell" >1 Fewer passes, vertex programs</td><td class="wikicell"  colspan="2"> This is with vertex programs, as few passes as possible to get the effect we want. some slight degredation in graphics quality IS acceptable.</td></tr><tr><td class="wikicell" >2 No vertex programs</td><td class="wikicell"  colspan="2"> This is for cards like the Radeon7500 &amp; Geforce 2MX. try not to use vertex programs unless you have to (e.g. VP\'s for bumpmapping is fine, but otherwise try not). as many passes as it takes.</td></tr><tr><td class="wikicell" >3 No VP, few passes</td><td class="wikicell"  colspan="2"> Like 2, but as few passes as possible.</td></tr><tr><td class="wikicell" >4 Just get something on the screen</td><td class="wikicell"  colspan="2"> pref. in 1 pass. Vertex lighting only is the order of the day.</td></tr></table>
</p>

<p>The basic principle is that the artist chooses between hi / lo GFX quality, and the user a GFX level. The LOD is then calculated as follows by (artistQualitySetting + UserQualitySetting * 2)
</p>
<hr />
<h2>Channels</h2>

<p>Unity defines the following channel types for getting data into your shader. If you use these values as varying inputs to a Cg vertex program, they are mapped automatically
<table class="wikitable"><tr><td class="wikicell" ><b>Channel name</b></td><td class="wikicell"  colspan="2"><b>Data type</b></td></tr><tr><td class="wikicell" >Vertex</td><td class="wikicell"  colspan="2">Vertex positions. Unless you are doing something strange, map this to the vertex target</td></tr><tr><td class="wikicell" >Normal</td><td class="wikicell"  colspan="2">The vertex normals. Map this to normal when using OpenGL lighting</td></tr><tr><td class="wikicell" >TexCoord</td><td class="wikicell"  colspan="2">The texture coordinates defined by geometry</td></tr><tr><td class="wikicell" >DiffuseDot3</td><td class="wikicell"  colspan="2">Vertex colors for doing the traditional Texture-space Unity bumpmapping</td></tr><tr><td class="wikicell" >SpecularDot3 (NI)</td><td class="wikicell"  colspan="2">Vertex colors for doing the specular Texture-space bumpmapping</td></tr><tr><td class="wikicell" >TangentBase</td><td class="wikicell"  colspan="2">Compressed quaternions for calculating the Diffuse &amp; specular DOT3 values in a vertex program</td></tr></table>
</p>

<hr />

<h2> Properties</h2>
<h3>Lighting setup</h3>
<p><table class="wikitable"><tr><td class="wikicell" ><b>Property name</b> </td><td class="wikicell" > <b>Value</b> </td><td class="wikicell" > <b>Used for</b></td></tr><tr><td class="wikicell" >_SceneAmbient </td><td class="wikicell" > Scene ambient light value </td><td class="wikicell" > Getting the scene ambient light value</td></tr><tr><td class="wikicell" >_ModelAmbient* </td><td class="wikicell" > Ambient light for this model </td><td class="wikicell" > Normally used for ambient light contribution</td></tr><tr><td class="wikicell" >_MultiModelAmbient* </td><td class="wikicell" > Ambient light for this model in 1st pass, black in others </td><td class="wikicell" > Ambient lighting for pixel-lighted shaders</td></tr><tr><td class="wikicell" >_ModelLightColor0 - _ModelLightColorN* </td><td class="wikicell" > Lighted color for this model in 1st pass, black in others </td><td class="wikicell" > Diffuse &amp; specular lighting for pixel-lighted shaders</td></tr><tr><td class="wikicell" >_DOT3Light</td><td class="wikicell" >DOT3 light direction for objectspace bumpmaps</td><td class="wikicell" > Use this as a constant color when using objectspace bumpmaps</td></tr><tr><td class="wikicell" >_LightHackedDiffuse</td><td class="wikicell" >RGB = diffuse light, A = ambient</td><td class="wikicell" >Use this to multiply in the light and add a monochrome ambient for the SrcAlpha bumpmap trick (read 'practical per-pixel effects' for an explanation)</td></tr></table>
</p>

<h3>Fog setup</h3>

<p>By default, the shaders are set up correctly regarding fog. When using multipass, you often want to change the fog value for each pass to avoid applying it multiple times.
</p>

<p><table class="wikitable"><tr><td class="wikicell" ><b>Property name</b></td><td class="wikicell"  colspan="2"><b>Value</b></td></tr><tr><td class="wikicell" >_FogColor</td><td class="wikicell"  colspan="2">The fog color</td></tr><tr><td class="wikicell" >_AddFog </td><td class="wikicell"  colspan="2"> Fog color used for Additive passes.</td></tr><tr><td class="wikicell" >_MultiplyFog </td><td class="wikicell"  colspan="2"> Fog color used for multiply passes.</td></tr><tr><td class="wikicell" >_FogStart</td><td class="wikicell"  colspan="2">The fog starting distance</td></tr><tr><td class="wikicell" >_FogEnd</td><td class="wikicell"  colspan="2">The fog end distance</td></tr><tr><td class="wikicell" >_FogDensity</td><td class="wikicell"  colspan="2">The fog density</td></tr></table>
</p>

<h3>Material setup</h3>

<p>You can change the OpenGL material settings from within a shader using the following properties:
</p>

<p><table class="wikitable"><tr><td class="wikicell" ><b>Property name</b></td><td class="wikicell"  colspan="2"><b>Value</b></td></tr><tr><td class="wikicell" >Ambient</td><td class="wikicell"  colspan="2">The Ambient color</td></tr><tr><td class="wikicell" >Diffuse </td><td class="wikicell"  colspan="2"> Diffuse material color</td></tr><tr><td class="wikicell" >Specular </td><td class="wikicell"  colspan="2"> Specular material color</td></tr><tr><td class="wikicell" >Emissive</td><td class="wikicell"  colspan="2"> Emissive material color</td></tr><tr><td class="wikicell" >Shininess</td><td class="wikicell"  colspan="2">Shininess factor</td></tr></table>
</p>

<h3>Simple state commands</h3>
<p><table class="wikitable"><tr><td class="wikicell" >Name string </td><td class="wikicell"  colspan="2"> Sets the name of this pass to string</td></tr><tr><td class="wikicell" >Color color </td><td class="wikicell"  colspan="2"> Sets the current color to color</td></tr><tr><td class="wikicell" >Blendcolor color </td><td class="wikicell"  colspan="2"> uses color  as the blending color</td></tr><tr><td class="wikicell" >Lighting bool </td><td class="wikicell"  colspan="2"> Turns OpenGL lighting on/off</td></tr><tr><td class="wikicell" >Colormask rgbflags  </td><td class="wikicell"  colspan="2">  Disables rendering to the color channels that are set. f.eks will no rendering to the alpha channel occur when writing Colormask Alpha</td></tr><tr><td class="wikicell" >Cull cullorient  </td><td class="wikicell"  colspan="2">  cullorient can be Front, Back or FrontAndBack and sets culling of those faces. It is also possible to write Cull false for no culling.</td></tr><tr><td class="wikicell" >Shademodel model  </td><td class="wikicell"  colspan="2">  Sets the shading model in OpenGL. Can be Smooth or Flat.</td></tr><tr><td class="wikicell" >Seperatespecular bool  </td><td class="wikicell"  colspan="2">  Turn Seperate specular on/off.</td></tr></table>
</p>


<h3>Misc. values - you mostly use these from Cg</h3>

<p><table class="wikitable"><tr><td class="wikicell"  colspan="3"><b>float4 props</b></td></tr><tr><td class="wikicell" >_Time _SinTime _CosTime</td><td class="wikicell"  colspan="2">The time value in seconds, scaled by different factors  (.5t, t, 2t, 4t)</td></tr><tr><td class="wikicell" >_LightRange (r, rr, 1/r, 1/rr)</td><td class="wikicell"  colspan="2">The range of the current PerPixel light, as well as inverse, etc.</td></tr><tr><td class="wikicell"  colspan="3"><b>vector3 props</b></td></tr><tr><td class="wikicell" >_ObjectSpaceLightPos</td><td class="wikicell"  colspan="2"> Light position in object space</td></tr><tr><td class="wikicell" >_ObjectSpaceLightDir</td><td class="wikicell"  colspan="2"> Light direction in object space (what <i>exactly</i> is this for?)</td></tr><tr><td class="wikicell"  colspan="3"><b>float3x3 matrices</b></td></tr><tr><td class="wikicell" >_LightSpecularRotation</td><td class="wikicell"  colspan="2">Matrix to rotate a cubemap correctly for specular lighting</td></tr><tr><td class="wikicell"  colspan="3"><b>float4x4 matrices</b></td></tr><tr><td class="wikicell" >_World2Light _Light2World</td><td class="wikicell"  colspan="2">Matrices to get from object to world space</td></tr><tr><td class="wikicell" >_Object2World _World2Object</td><td class="wikicell"  colspan="2">Matrices to get from world to light space</td></tr><tr><td class="wikicell" >_Object2Light</td><td class="wikicell"  colspan="2">Shotcut - equiv. to ObjectToWorld * World2Light</td></tr><tr><td class="wikicell" >_SpotlightProjectionMatrix</td><td class="wikicell"  colspan="2">If the light is a spotlight, this is the matrix to apply to linear texgen in order to get into projection space</td></tr></table>
</p>

<p>Print this &amp; stick on the wall
</p>

<h2>Basic syntax</h2>

<p><table class="wikitable"><tr><td class="wikicell"  colspan="4"><div align="center"><b>State modifiers</b></div></td></tr><tr><td class="wikicell" ><b>Culling</b></td><td class="wikicell" ><b>Blending</b></td><td class="wikicell" ><b>Material &amp; Lighting</b></td><td class="wikicell" ><b>Esoteric stuff</b></td></tr><tr><td class="wikicell" >ZTest<br>ZWrite<br>AlphaTest<br>Cull</td><td class="wikicell" >Blend<br>BlendColor</td><td class="wikicell" >Material<br>Lighting<br>Fog<br>SeparateSpecular<br>color</td><td class="wikicell" >ColorMask<br>ShadeModel<br>Matrix<br>Offset</td></tr><tr><td class="wikicell" ><b>Texturing</b></td><td class="wikicell" ><b>Channels</b></td><td class="wikicell" ><b>Programs</b></td><td class="wikicell" ><b>Tags</b></td></tr><tr><td class="wikicell" >SetTexture<br>Texgen<br>Bind<br>ConstantColor<br>Combine <br>Matrix</td><td class="wikicell" >indChannels<br>Bind<br><br>DefineProgram<br>LoadProgram</td><td class="wikicell" >Bind<br>Properties<br>Local</td><td class="wikicell" >Tags</td></tr></table>
</p>
<hr />
<p><table class="wikitable"><tr><td class="wikicell" ><b>Material</b></td><td class="wikicell"  colspan="3">Diffuse Specular Ambient Emission Shininess</td></tr><tr><td class="wikicell" ><b>BlendModes</b></td><td class="wikicell"  colspan="3">One Zero SrcAlpha DstAlpha SrcColor DstColor OneMinusXXX</td></tr><tr><td class="wikicell" ><b>Fog</b></td><td class="wikicell"  colspan="3">Mode Color Start End</td></tr></table>
</p>

<p><table class="wikitable"><tr><td class="wikicell"  colspan="4"><div align="center"><b>Tags</b></div></td></tr><tr><td class="wikicell" >RenderQueue</td><td class="wikicell"  colspan="3">Background Geometry Transparent Overlay</td></tr><tr><td class="wikicell" >LightMode</td><td class="wikicell"  colspan="3"> VertexOnly(d) Vertex Pixel PixelOnly NoLights<br><b>No lights</b>->NoLights   <b>Vertex only</b>->Vertex, VertexOnly   <b>Pixel only</b>->Pixel, PixelOnly  <b>Both</b>->vertex, pixel</td></tr><tr><td class="wikicell" >LightCount</td><td class="wikicell"  colspan="3">(int)Lights per pass (0 = render once without lighting)</td></tr><tr><td class="wikicell"  colspan="4"><div align="center"><b>Channels</b></div></td></tr><tr><td class="wikicell"  colspan="4">Vertex Normal TexCoord DiffuseDot3 SpecularDot3(NI) Color</td></tr><tr><td class="wikicell"  colspan="4"><div align="center"><b>Properties</b></div></td></tr><tr><td class="wikicell" >Lighiting</td><td class="wikicell"  colspan="3">_LightAmbient _LightColor _LightDiffuseAmbient _LightAmbientDivDiffuse _LightHackedDiffuse<br>_DOTLight</td></tr><tr><td class="wikicell" >Fog </td><td class="wikicell"  colspan="3"> _FogColor _FogStart _FogEnd _FogDensity</td></tr><tr><td class="wikicell"  colspan="4"><div align="center"><b>Cg</b></div></td></tr><tr><td class="wikicell" ><b>float4 props</b></td><td class="wikicell"  colspan="3">_Time _SinTime _CosTime<br>_LightRange (r, r<sup>2</sup>, 1/r, 1/r<sup>2</sup>)</td></tr><tr><td class="wikicell" ><b>vector3 props</b></td><td class="wikicell"  colspan="3">_ObjectSpaceLightPos _ObjectSpaceLightDir</td></tr><tr><td class="wikicell" ><b>float3x3 matrices</b></td><td class="wikicell"  colspan="3">_LightDiffuseRotation _LightSpecularRotation</td></tr><tr><td class="wikicell" ><b>float4x4 matrices</b></td><td class="wikicell"  colspan="3">_World2Light _Light2World _Object2World _World2Object _Object2Light _SpotlightProjectionMatrix</td></tr></table>
</p>



<p>Unity has extensive support for C, C++ or Objective-C based plugins.
In order to use a plugin you need to do two things:
</p>
<ul><li> Write a plugin in a C based language and compile it.
</li><li> Create a C# script which calls functions in the plugin to do something.
</li></ul>

<p>So the plugin provides a simple c interface. The Script then invokes the functions exposed by the plugin.
Here is a very simple example:
</p>

<h2>The C file of a minimal plugin:</h2>
<p><pre class='codelisting'>
float FooPluginFunction () { return 5.0F; }
</pre>
</p>

<h2>A C# script that uses the plugin:</h2>
<p><pre class='codelisting'>
using UnityEngine; 
using System.Runtime.InteropServices; 

class SomeScript : MonoBehaviour 
{
   // This tells unity to look up the function FooPluginFunction inside the plugin named &quot;PluginName&quot;
   [DllImport (&quot;PluginName&quot;)]
   private static extern float FooPluginFunction ();

   void Awake () 
   {
      // Calls the FooPluginFunction inside the PluginName plugin
      // And prints 5 to the console 
      print (FooPluginFunction ());
   }
}
</pre>
</p>

<h1>Building a plugin for Mac OS X</h1>

<p>If you are building a plugin for Mac OS X, you have to create a bundle.
The easiest way to do this is using xCode. Use Edit-&gt;NewProject... and select the Bundle - Carbon Bundle preset.
</p>

<p>If you are using C++ or Objective-C to implement the plugin you have to make sure the functions are declared as C in the header file to avoid name mangling issues.
<pre class='codelisting'>
extern &quot;C&quot;
{
  float FooPluginFunction ();
}
</pre>
</p>


<h1>Using your plugin from C#</h1>

<p>Once you have built your bundle you have to copy it to the Assets/Plugins folder.
Unity will then find it by its name when you define a function like this:
<pre class='codelisting'>
[DllImport (&quot;PluginName&quot;)]
private static extern float FooPluginFunction ();
</pre>
</p>

<p>Please note that PluginName should not include the extension of the filename.
</p>

<h1>Cross Platform Plugins</h1>

<p>If you are building a plugin for windows it has to be placed inside the Assets/Plugins folder as well but it's extension has to be .dll instead of .bundle.
</p>

<p>So if you want to create an application using a plugin for both windows and Mac OS X you need to place two plugins:
SomePlugin.dll
SomePlugin.bundle
inside the Assets/Plugins folder.
</p>

<h1>Deployment</h1>
<p>Once you have placed your plugins in the Plugins folder there is no more work required on your side.
Unity automatically picks the right plugin for the right deployment platform and includes it with the player.
</p>

<h1>Examples</h1>
<p>A complete example of the Plugin interface can be found <a class="wiki"  href="http://www.otee.dk/tutorials/midiplugin.zip">here</a>.
</p>


<p>This is a complete MidiPlugin which uses Apple's CoreMidi API.
It provides a simple C API and a C# class using the C API.
The C# class contains a high level API, with easy access to NoteOn and NoteOff events and their velocity.
</p>

<h1>More information</h1>
<p><a class="wiki"  href="http://www.mono-project.com/Interop_with_Native_Libraries">Mono Interop with native libraries</a>.
</p>

<p><a class="wiki"  href="http://msdn.microsoft.com/library/default.asp?url=/library/en-us/cpguide/html/cpconmarshalingdatawithplatforminvoke.asp">Microsoft p-invoke</a>.
</p>



<p><i>Premature optimization is the root of all evil</i>
</p>

<p><i>&ndash; Donald Knuth.</i>
</p>

<h3> Unity post-processes all imported assets</h3>
<p>Unity always post-processes imported files, thus storing a file as a multi layered psd file instead of a jpg will make absolutely zero difference in the size of the player you will deploy. Save your files in the format you are working with (eg. .mb files, psd files, tiff files) to make your life easier.
</p>

<h3> Unity strips out unused assets</h3>
<p>The amount of assets in your project folder does <b>not</b> influence the size of your built player. Unity is very smart about detecting which assets are used in your game and not. Unity follows all references to assets before building a game and builds a list of assets that need to be included in the game. Thus you can safely keep unused assets in your project folder.
</p>

<h3> Unity prints an overview of the used file size</h3>

<p>After Unity has completed building a player, it prints an overview of what type of asset took up most file size, and it prints which assets were included in the build:
</p>

<p>To see it just open <b>/Applications/Utilities/Console.app</b>
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Reducing File size-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/Reducing File size-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>An overview of what took up space</i>
</p>

<h3> Optimizing texture size</h3>

<p>Often textures take up most space in the build. The first thing to do is to turn on texture compression when building the player.
</p>

<p>If that doesnt get the size down, it is about reducing the size of the textures. The trick here is that you don't need to modfiy the actual source content. Simply select the texture in the project view and choose <b>Assets -&gt; Import Settings...</b>.
</p>

<p>Here you can specify the maximum texture size which will be used when importing the texture. It is a good idea to zoom in on an object that uses the texture, then adjust the maximum texture size until it starts looking worse in the scene view.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/Reducing File size-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/Reducing File size-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Tuning texture size</i>
</p>

<h3> How much memory does my texture take up</h3>

<p><table class="wikitable"><tr><td class="wikicell" ><div align="center"><b>Compression</b></td><td class="wikicell" ><b>Memory consumption</b></div></td></tr><tr><td class="wikicell" >DXTC1 RGB</td><td class="wikicell" >0.5 Bpp (bytes/pixel)</td></tr><tr><td class="wikicell" >DXTC3 RGBA</td><td class="wikicell" >1 Bpp</td></tr><tr><td class="wikicell" >DXTC5 RGBA</td><td class="wikicell" >1 Bpp</td></tr><tr><td class="wikicell" >RGB 16bit</td><td class="wikicell" >2 Bpp </td></tr><tr><td class="wikicell" >RGB 24bit</td><td class="wikicell" >3 Bpp</td></tr><tr><td class="wikicell" >Alpha 8bit</td><td class="wikicell" >1 Bpp</td></tr><tr><td class="wikicell" >RGBA 16bit</td><td class="wikicell" >2 Bpp</td></tr><tr><td class="wikicell" >RGBA 32bit</td><td class="wikicell" >4 Bpp</td></tr></table>
</p>

<p>To figure out total texture size: width * height * bpp.
Add 33% if you have Mipmaps.
</p>

<p>When building a game there is a button <b>Compress textures</b>.
</p>

<p>By default Unity does not compress textures when importing, even if you choose DXTC compression. This is because compressing textures takes a long time and it is better to have fast iteration time when importing textures into your game. (You can  change this behaviour in the preferences though)
</p>

<p>The compress textures button in the build settings will make sure that all textures that have DXTC texturing enabled will actually be compressed, before building the player.
</p>



<p>Making your game run smoothly is of prime importance to its success. Thankfully Unity is there with you. We have spent a lot of time and energy making it run fast on a wide variety of hardware. Below are some simple guidelines to maximizing the speed of your game.
</p>

<h2> In summary - combine, combine, combine</h2>

<ul><li> If you care about performance, combine meshes.
</li><li> If you care about performance make sure all your combined meshes also share the same material and texture.
</li></ul>

<h2> In detail:</h2>

<p>Todays graphics cards are really good at pushing a lot of polygons but they have quite some overhead for every batch that you submit to the graphics card. So if you have a 100 triangle object it is going to be just as expensive to render as a 1500 poly object. The sweet spot for optimal rendering performance is somewhere around 1500-4000 triangles per mesh.
</p>

<p>You only pay rendering cost for objects that have a mesh renderer attached. And you only pay for those that are within the view frustum. There is no attached rendering cost to having a lot of empty game objects in your scene.
</p>

<ul><li> The best way to improve rendering performance, is to combine objects together so each mesh has around 1500 or more triangles and uses only one material for the entire mesh.
</li></ul>

<p>There is one thing to be aware of when combining objects though.
If you use a lot of small lights in your scene, it might make sense to combine only objects that are close to each other.
</p>

<p>The rendering cost for a mesh that has multiple materials is the same as having multiple renderers for each material. The most common reason why you have multiple materials is because two meshes don't share the same textures. So if you want to optimize rendering performance you need to make sure that the objects you combine share textures.
</p>


<ul><li> Unity is very good at pushing lots of polygons. Unity uploads all geometry to the graphics card for good cache utilization and optimal data alignment.
</li><li> You simply have to make sure that the graphics card doesn't have to handle a huge amount of batches.
</li><li> The number of pixel lights affecting an object heavily affects performance.
</li></ul>

<p>If you want to have the best performance and don't care about bumpmapping or per pixel lighting just go to Edit -&gt; Render Settings ... and set pixel light count to zero. This will simply use vertex lighting for all objects.
This means all geometry will be rendered only once every frame. This is an extremely useful LOD setting, so your game can run fine on older graphics cards.
</p>

<h3> Pixel lights</h3>

<p>If you use pixel lighting, then we have to render every object as many times as we have pixel lights that affect the object.
If you combine two objects that are very far apart, it might increase the size of the object and now you have a lot of lights affecting this big object. If your objects were seperate however, the light wouldn't have to be applied on the part of the mesh which is far away. This can result in rendering the combined mesh as many times as the uncombined mesh thus you didn't save anything.
</p>

<p>When rendering a mesh unity finds all lights surrounding the mesh. It then figures out what lights affect the mesh the most. The Edit -&gt; Render Settings are used to modify how many of the lights end up as pixel lights and how many as vertex lights.
</p>

<p>Every light calculates it's importance based on how far away it is from the mesh and how intense it is.
</p>

<p>Some lights are more important than others depending on the game context. For this every light has a Render Mode setting which can be set to &quot;Force Pixel&quot; or &quot;Force Vertex&quot;.
</p>

<p>Imagine the player's car with head lights driving through the night. The head light is the most important light in the game. Thus set the head lights Render Mode to &quot;Force Pixel&quot;.
</p>

<p>If you have a light that isn't very important and also visually doesn't gain much from being a pixel light, set the lights Render Mode to &quot;Force Vertex&quot;. This way you don't waste rendering performance without gaining any visual quality.
</p>

<p>The following is a list of common tasks in Unity and how to accomplish them.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Graphics how-tos.html">Graphics how-tos</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-bumpmap.html">HOWTO-bumpmap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseDetailTexture.html">HOWTO-UseDetailTexture</a></li><li class="toclevel"><a href="../Manual/HOWTO-MakeCubemap.html">HOWTO-MakeCubemap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseSkybox.html">HOWTO-UseSkybox</a></li><li class="toclevel"><a href="../Manual/HOWTO-MeshParticleEmitter.html">HOWTO-MeshParticleEmitter</a></li><li class="toclevel"><a href="../Manual/HOWTO-SplashScreen.html">HOWTO-SplashScreen</a></li><li class="toclevel"><a href="../Manual/HOWTO-LightCookie.html">HOWTO-LightCookie</a></li><li class="toclevel"><a href="../Manual/HOWTO-FixZAxisIsUp.html">HOWTO-FixZAxisIsUp</a></li><li class="toclevel"><a href="../Manual/HOWTO-Water.html">HOWTO-Water</a></li></ul><li class="toclevel"><a href="../Manual/HOWTO-importObject.html">HOWTO-importObject</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectMax.html">HOWTO-ImportObjectMax</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectBlender.html">HOWTO-ImportObjectBlender</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectCinema4D.html">HOWTO-ImportObjectCinema4D</a></li><li class="toclevel"><a href="../Manual/HOWTO-importObjectLightwave.html">HOWTO-importObjectLightwave</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectMaya.html">HOWTO-ImportObjectMaya</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectModo.html">HOWTO-ImportObjectModo</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectCheetah3D.html">HOWTO-ImportObjectCheetah3D</a></li></ul><li class="toclevel"><a href="../Manual/Workflow.html">Workflow</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-exportpackage.html">HOWTO-exportpackage</a></li><li class="toclevel"><a href="../Manual/HOWTO-InstallStandardAssets.html">HOWTO-InstallStandardAssets</a></li></ul></ul>
</p>

<p>The following is a list of graphics tasks in Unity and how to accomplish them.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-bumpmap.html">HOWTO-bumpmap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseDetailTexture.html">HOWTO-UseDetailTexture</a></li><li class="toclevel"><a href="../Manual/HOWTO-MakeCubemap.html">HOWTO-MakeCubemap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseSkybox.html">HOWTO-UseSkybox</a></li><li class="toclevel"><a href="../Manual/HOWTO-MeshParticleEmitter.html">HOWTO-MeshParticleEmitter</a></li><li class="toclevel"><a href="../Manual/HOWTO-SplashScreen.html">HOWTO-SplashScreen</a></li><li class="toclevel"><a href="../Manual/HOWTO-LightCookie.html">HOWTO-LightCookie</a></li><li class="toclevel"><a href="../Manual/HOWTO-FixZAxisIsUp.html">HOWTO-FixZAxisIsUp</a></li><li class="toclevel"><a href="../Manual/HOWTO-Water.html">HOWTO-Water</a></li></ul>
</p>



<p>Bump maps are greyscale images that use as a height map on your objects in order to give an appearance of depth. Assuming you have a model that looks like this:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-bumpmap-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-bumpmap-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>we want to make the light parts of the object stand out.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Draw a grayscale height map of your texture in photoshop. White is high, black is low. Something like this:<br /><!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-bumpmap-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-bumpmap-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li><li> Save the image next to your main texture.
</li><li> In Unity, select the image and choose <b>Asset-&gt;Import Settings...</b> from the main menu.
</li><li> The Texture inspector pops up; select the 24 bit RGB format and enable 'Generate Bump map':<br /> <!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-bumpmap-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-bumpmap-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li><li> In the material inspector on the right, select 'Bumped' from the Shader drop-down:<br /><!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-bumpmap-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-bumpmap-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li><li> Drag your texture from the project window to the 'Bumpmap' texture slot:<br /><!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-bumpmap-4.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-bumpmap-4.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>Your object now has a bump map applied:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-bumpmap-5.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-bumpmap-5.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h2>Hints</h2>
<ul><li> To make the bumps more noticable, either use the Bumpyness slider in the texture import settings or blur the texture in photoshop. Play with both to get a feel for it.
</li></ul>






<p>A detail texture is small, fine pattern which is faded in as you approach a surface, for example wood grain, imperfections in stone, or earthly details on a terrain.
</p>

<p>Detail textures must tile in all directions. Color values from 0-127 makes the object it's applied to darker, 128 doesn't change anything, and lighter colors makes the object lighter. It's very important that the image is centered around 128 - otherwise the object it's applied to will get lighter or darker as you approach.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Draw or find a grayscale image of the detail texture. <br><!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-UseDetailTexture-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-UseDetailTexture-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li><li> Save the image next to your main texture.
</li><li> In Unity, select the image and choose <b>Asset->Import Settings...</b> from the main menu.
</li><li> The Texture importer pops up; Under mip maps, enable <b>Fades Out</b> and set the sliders to something like this:<br> <!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-UseDetailTexture-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-UseDetailTexture-1.jpg"></td></tr></table></p><!-- #EndLibraryItem --><br> The top slider determines how small the texture should before before beginning to fade out, and the bottom determines how far away it is completely gone
</li><li> In the material inspector on the right, select 'DiffuseDetail' from the Shader drop-down:<br><!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-UseDetailTexture-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-UseDetailTexture-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li><li> Drag your texture from the project window to the 'Detail' texture slot.
</li><li> Click the texture in the material inspector, and set the scale values to a high value below <br> <!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-UseDetailTexture-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-UseDetailTexture-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li></ol>

<p></div></div></td></tr></table>
</p>





<p>Cubemaps are used by the <i>Reflective</i> builtin shaders. To build one, you either create six 2D textures and create a new Cubemap asset, or built Cubemap from a single square texture.
</p>

<p>More details are in <a href="../Components/class-CubemapTexture.html">Cubemap Texture</a> documentation page.
</p>



<p>A skybox is a 6-sided cube that is drawn behind all graphics in the camera. To create one, do as follows:
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Make 6 textures that correspond to each of the 6 sides of the skybox and import by putting them into the Assets folder.
</li><li> For each texture you need to change the wrap mode from Repeat to Clamp. If you don't do this colors on the edges will not match up:<br /> <!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-UseSkybox-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-UseSkybox-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li><li> Create a new material by choosing <b>Assets-&gt;Create-&gt;Material</b> from the main menu.
</li><li> Select the shader drop-down in the top of the inspector, choose <b>RenderFX-&gt;Skybox</b> from the drop-down.
</li><li> Assign the 6 textures to each texture slot in the material. You can do this by dragging each texture from the project view onto each slot in the material.<br /> <!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-UseSkybox-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-UseSkybox-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>To Assign the skybox to the scene you're working on, do like this:
<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Choose <b>Edit-&gt;Render Settings</b> from the main menu.
</li><li> Drag the material you created above to the Skybox Material slot in the inspector.
</li></ol>

</div></div></td></tr></table>
</p>




<p>Mesh Particle Emitters are generally used when you need high control over where to emit particles.
For example when you want to do a flaming sword.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Drag a mesh into the scene.
</li><li> Remove the MeshRenderer by right-clicking on the MeshRenderer's inspector titlebar and choosing Remove Component.
</li><li> Choose MeshParticleEmitter from the Component-&gt;Particles menu
</li><li> Choose ParticleAnimator from the Component-&gt;Particles menu
</li><li> Choose ParticleRenderer from the Component-&gt;Particles menu
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>You should now see particles emitting from the mesh.
</p>

<p>Play around with the values in the <a href="../Components/class-MeshParticleEmitter.html">MeshParticleEmitter</a>.
</p>

<p>Especially enable Interpolate Triangles in the Mesh Particle Emitter Inspector and set Min Normal Velocity and Max Normal Velocity to 1.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Choose Material from the Assets -&gt; Create menu
</li><li> In the shader popup select the Particles/Additive shader
</li><li> Drag&amp;Drop a texture from the project view onto the texture slot in the material
</li><li> Drag the material from project view on the particle system in the scene view
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>You should now see textured particles emitting from the mesh.
</p>

<h2>See Also</h2>
<ul><li> <a href="../Components/class-MeshParticleEmitter.html">MeshParticleEmitter</a>
</li></ul>



<p>Here's how to do a splash screen or any other type of full-screen image in Unity. This HOWTO takes care to work for multiple different resolutions and aspect ratios.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> First you need a big texture. Remember that textures have to be power of two in size. You might for example use 1024x512 as this fits most screens.
</li><li> Make a box using the &quot;GameObject-&gt;Create Other-&gt;Cube&quot; menu item.
</li><li> Scale it to be in 16:9 format by switching the Inspector to &quot;Full&quot; mode, then entering 16 and 9 as the first two value in the Scale:<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-SplashScreen-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-SplashScreen-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</li><li> Put the texture on a cube and make a camera to point at it. Place the camera at such a distance so that the cube is still visible on a widescreen.
</li><li> Apply the texture to the box by dragging it on.
</li></ol>

<p></div></div></td></tr></table>
</p>



<p>Unity ships with a few Light Cookies. They can be found in Standard Assets/Light Cookies.
Sometimes you want to create your own though.
</p>

<p>A light cookie modulates the color of the light with the alpha channel, thus allows you to
</p>

<p>An interesting way to add a lot of visual detail to your scenes is to use cookies - greyscale textures you use to control the precise look of in-game lighting. This is fantastic for making moving clouds and giving an impression of dense foilage. The Light page has more info on all this, but the main thing is that for textures to be usable for cookies, the following properties need to be set:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-LightCookie-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-LightCookie-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>To create a light cookie for a spot light:
</p>

<ol><li> Paint a cookie texture in photoshop. The image should be grayscale. White pixels means full lighting intensity, black pixels mean no lighting. The borders of the texture need to be completely black, otherwise the light will appear to leak outside of the spotlight.
</li><li> In the texture inspector change the &quot;Repeat&quot; Wrap mode to &quot;Clamp&quot;
</li><li> Select the Texture and bring up the Import Settings using the Assets -&gt; Import Settings... menu.
</li></ol>

<p>Use the following settings:
</p>
<ol><li> Enable Border Mipmaps
</li><li> Enable Build Alpha From Grayscale (This way you can make a grayscale cookie and unity converts it to a alpha map automatically)
</li><li> Set the Texture Format to Alpha 8 Bit
</li></ol>
<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-LightCookie-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-LightCookie-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>To create a light cookie for a directional light:
</p>




<p>Some 3D art packages export their models so that the z-axis faces upwards. Most of the standard scripts in Unity assume that the y-axis is upwards. It is usually easier to fix the rotation in Unity than to modify the scripts to make things fit.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-FixZAxisIsUp-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-FixZAxisIsUp-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Your model with z-axis point upwards</i>
</p>

<p>If at all possible it is recommended that you fix the model in your 3d modeller to have the y-axis face upwards before exporting.
</p>

<p>If this is not possible, you can fix it in Unity by adding an extra parent transform:
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Create an empty game object using the <b>GameObject -&gt; Create Empty</b> menu
</li><li> Place the new game object so that it is at the center of your mesh or which ever point you want your object to rotate around.
</li><li> Drag the mesh on the empty game object
</li></ol>

<p></div></div></td></tr></table>
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-FixZAxisIsUp-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-FixZAxisIsUp-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>The model with an extra empty transform</i>
</p>




<p>Unity includes several water prefabs (including needed shaders, scripts and art assets) among it's <a href="../Manual/HOWTO-InstallStandardAssets.html">standard asset packages</a>. Indie version includes a basic water, while Unity Pro includes a reflective and reflective+refractive water prefabs.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-Water-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-Water-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p><i>Reflective&amp;Refractive water on the left, Reflective water on the right</i>
</p>

<h2>Water setup</h2>

<p>In most cases you just drag a prefab into your scene (make sure to have the <a href="../Manual/HOWTO-InstallStandardAssets.html">standard assets installed</a>):
</p>
<ul><li> Unity Indie has <b>Daylight Water</b> and <b>Nighttime Water</b> in <i>Standard Assets/Water</i>.
</li><li> Unity Pro has <b>Daylight Reflective Water</b>, <b>Nighttime Reflective Water</b> and <b> Reflective-Refractive Water</b> in <i>Pro Standard Assets/Water</i> (but it needs some assets from <i>Standard Assets/Water</i> as well).
</li></ul>

<p>The prefab uses oval-shaped mesh for the water. If you need to use different <a href="../Components/class-Mesh.html">Mesh</a> the easiest way is just changing it in Mesh Filter of water object:
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-Water-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-Water-1.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>


<h2>Creating water from scratch (Advanced)</h2>

<p>The simple water in Unity Indie does not require any special setup; the most you can do is tweak values of the material. The rest of this section will describe how to setup reflective and/or refractive water from scratch (without using prefabs described above).
</p>

<p>Water needs:
</p>
<ul><li> A geometry of the water. This should be flat mesh, oriented horizontally. UV coordinates are not required. The water game object should use Water layer.
</li><li> One of water materials to render with (''FX/WaterPlane ...&quot;).
</li><li> A camera and a RenderTexture for the reflections. Refractive water needs additional camera and render texture.
<ul><li> The camera(s) should be placed exactly on the water plane, and transform's y-axis should point upwards.
</li><li> Cameras should exclude Water layer from their culling mask. This makes water itself not visible in reflections/refractions.
</li><li> Target textures should be setup accordingly (e.g. reflections render texture for reflection camera).
</li><li> Attach <i>Pro Standard Assets/Water/Sources/ReflectionRenderTexture</i> script to the cameras. This script places the controlled camera into correct position (e.g. for reflection camera it reflects main camera along water plane), sets up the correct culling mode and sets up oblique projection matrix so that geometry gets properly clipped along water plane.
</li></ul></li><li> In water material, the render textures connected to corresponding properties.
</li></ul>

<h2>Properties in water materials</h2>
<p>These properties are used in Reflective&amp;Refractive water shader. Most of them are used in other water shaders as well.
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Wave scale</nobr></b></td><td> Scaling of waves bumpmap. The smaller the value, the larger water waves.
</td></tr><tr><td><b><nobr> Reflection/refraction distort</nobr></b></td><td> how much reflection/refraction is distorted by the waves bumpmap.
</td></tr><tr><td><b><nobr> Refraction color</nobr></b></td><td> additional tint for refraction.
</td></tr><tr><td><b><nobr> Environment reflection/refraction</nobr></b></td><td> render textures for real-time reflection and refraction.
</td></tr><tr><td><b><nobr> Bumpmap</nobr></b></td><td> Defines the shape of the waves. The final waves are produced by combining two these bumpmaps, each scrolling at different direction, scale and speed. The second bumpmap is twice smaller than the first one.
</td></tr><tr><td><b><nobr> Wave speed</nobr></b></td><td> Scrolling speed for first bumpmap (1st and 2nd numbers) and the second bumpmap (3rd and 4th numbers).
</td></tr><tr><td><b><nobr> Fresnel</nobr></b></td><td> A texture with alpha channel controlling the Fresnel efffect - how much reflection vs. refraction is visible, based on viewing angle.
</td></tr></tr></table>
</p>

<p>The rest of properties are not used by Reflective&amp;Refractive shader by itself, but need to be set up in case user's video card does not suppor it and must fallback to the simpler shader:
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Color ramp/cube and fresnel</nobr></b></td><td> A texture that defines water color (RGB) and Fresnel effect (A) based on viewing angle.
</td></tr><tr><td><b><nobr> Horizon color</nobr></b></td><td> The color of the water at horizon. <i>(Used only in the simple water shader)</i>
</td></tr><tr><td><b><nobr> Fallback texture</nobr></b></td><td> Texture used to represent the water on really old video cards, if none of better looking shaders can't run on it.
<p></td></tr></tr></table>
</p>




<p>Unity supports importing from a lot of 3D applications. Choose the one you're working with below:
</p>
<ul><li> <a href="../Manual/HOWTO-ImportObjectMaya.html">Maya</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectCinema4D.html">Cinema 4D</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectMax.html">3D Studio MAX</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectCheetah3D.html">Cheetah3D</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectModo.html">Modo</a>
</li><li> <a href="../Manual/HOWTO-importObjectLightwave.html">Lightwave</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectBlender.html">Blender</a>
</li></ul>

<h2> Other applications</h2>
<p>Unity can read <b>.FBX</b>, <b>.3DS</b>, <b>.dxf</b> and <b>.obj</b> files, so if your program can export to this format you're home free. FBX exporters for popular 3D packages can be found <a class="wiki"  href="http://autodesk.com/fbx">here</a>.
</p>

<h2>Hints</h2>
<ul><li> Store textures in a folder called <b>Textures</b> next to the exported mesh. This will guarantee that Unity can always find the Texture and automatically connect the Texture to the Material. For more information, see the <a href="../Components/class-Texture2D.html">Textures</a> reference.
</li></ul>

<h2>See Also</h2>
<ul><li> <a href="../Manual/HOWTO-bumpmap.html">How do I use bump maps?</a>
</li><li> <a href="../Components/class-Mesh.html">Mesh Import Settings</a>
</li><li> <a href="../Manual/HOWTO-FixZAxisIsUp.html">Fixing a mesh that has the z-axis facing upwards</a>
</li></ul>



<p>If you make your 3D objects in 3dsMax, you can export them into Unity using the <b>.FBX</b> format.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Download the fbx exporter from <a class="wiki"  href="http://autodesk.com/fbx">here</a> and install it.
</li><li> Export your scene in <b>.fbx</b> format on your PC.
</li><li> Move the exported fbx file into your Unity project folder on the Mac.
</li><li> When you switch back into Unity, the <b>.fbx</b> file is imported automatically.
</li><li> Drag the file from the project window into the scene view.
</li></ol>

<p></div></div></td></tr></table>
</p>

<h2> Unity currently imports from 3ds Max</h2>
<ol><li> Meshes with vertex colors, normals and UV's
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li><li> Animations FK &amp; IK
</li><li> Bone based animations
</li></ol>




<p>Unity natively imports Blender files. To get started, simply place your <b>.blend</b> file in your project's assets folder.
When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<p>If you modify your .blend file, Unity will automatically update whenever you save.
</p>

<h2> Unity currently imports</h2>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> All objects with position, rotation and scale.
</li><li> Meshes with vertices, polygons, triangles, UV's and Normals.
</li></ol>

<h4>Requirements</h4>
<ol><li> You need to have at least Blender version 2.4 installed.
</li></ol>

<p>Textures are not assigned automatically but you can easily do this via drag &amp; drop in Unity. Animation is current not imported from blender, this is a limitation of Blender's Collada exporter. As soon as Blender's Collada importer supports this Unity wil be updated to import animations from Blender.
</p>



<p>Unity natively imports Cinema 4D files. To get started, simply place your <b>.C4D</b> file in your project's assets folder.
When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<p>If you modify your .c4d file, Unity will automatically update whenever you save.
</p>

<h3>Unity currently imports</h3>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> Meshes with UV's, Normals
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li><li> Animations
</li><li> Bone based animations
</li></ol>

<p>Unity does not import Point Level Animations (PLA) at the moment. Use Bone based animations instead.
</p>

<h4>Requirements</h4>
<ol><li> You need to have at least Cinema 4D version 8.5 installed to import the .C4D file
</li></ol>

<p>If you don't have Cinema 4D installed on your machine but want to import a Cinema 4D file from another machine, you can export to the fbx format, which Unity imports natively.
</p>
<ol><li> Open the Cinema 4D file
</li><li> In Cinema 4D choose <b>File -&gt; Export-&gt; FBX 6.0</b>
</li><li> Place the exported fbx file in the Unity project folder. Unity will now automatically import the fbx file.
</li></ol>

<h4>Hints</h4>
<ol><li>To maximize import speed when importing Cinema 4D files. Go to the Cinema 4D preferences <b>Edit -&gt; Preferences</b> and select the FBX 6.0 preferences. Now uncheck <b>Embed Textures</b>.
</li></ol>


<h4> Behind the import process (Advanced)</h4>
<p>When Unity imports a Cinema 4D file it will automatically install a Cinema 4D plugin and launch Cinema 4D in the background. Unity then communicates with Cinema 4D to convert the .C4D file into a format Unity can read. The first time you import a .c4d time and Cinema 4D is not open yet it will take a short while to launch it but afterwards import .c4d files will be very quick.
</p>



<p>You can import meshes and animations from Lightwave using the FBX plugin for Lightwave.
</p>

<h2>Unity currently imports</h2>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> Meshes with UV's and Normals
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li><li> Animations
</li><li> Bone based animations
</li></ol>

<h3> Installation</h3>
<p>Download the latest Lightwave FBX exporter from:
</p>
<h3> By downloading these plugins you automatically agree to <a class="wiki"  href="http://www.otee.dk/lightwave_plugins/License.txt">this</a> license.</h3>
<p><a class="wiki"  href="http://www.otee.dk/lightwave_plugins/mbr_FBX200508_LW80_MACOS.pkg.sit"> os x lighwave 8.0 plugin</a> <br />
<a class="wiki"  href="http://www.otee.dk/lightwave_plugins/mbr_FBX200508_LW82_MACOS.pkg.sit"> os x lighwave 8.2 plugin</a> <br />
<a class="wiki"  href="http://www.otee.dk/lightwave_plugins/mbr_FBX200508_LW80_WIN.zip"> windows lighwave 8.0 plugin</a> <br />
<a class="wiki"  href="http://www.otee.dk/lightwave_plugins/mbr_FBX200508_LW82_WIN.zip"> windows lighwave 8.2 plugin</a> <br />
</p>


<p>There are three versions of the plugin, one for LightWave 7.5, one for LightWave 8.0 and one for LightWave 8.2. Make sure you have the correct version: the LW7 plugin doesn't work properly with LW8.
</p>

<p>The plugin comes in a OS X package. If  you double click the package to install it, the installer will try put it in the correct folder. If it can't find your LightWave plugin folder, it will create its own LightWave folder in your Application folder and dump it there. If the latter occurs you should move it to your LightWave plugin folder (or any sub-folder). Once there you have to add the plugin to LightWave via the &quot;Edit Plugins&quot; panel (option-F11) -  see the LightWave manual for more details on how to add plugins.
</p>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-importObjectLightwave-0.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-importObjectLightwave-0.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<p>Once added to LightWave the plugin is acessible via the Generics menu (on the Utiliies) tab.  If the Generic menu is not present you will have to add it using the Config Menus panel. In the latter panel it can be found in the Plug-ins category and is calld &quot;Generic Plugins&quot;. Add it to any convenient menu (see the LightWave manual for more details on how to do this).
</p>

<p>More information about installation can also be found in the release notes that can downloaded with the installer.
</p>

<h2> Exporting</h2>
<p>All objects and animations have to be exported from Layout (there is no Modeler FBX exporter).
</p>

<h3>1. Select Export to FBX from the Generics menu</h3>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-importObjectLightwave-1.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-importObjectLightwave-1.jpg"></td></tr></table></p><!-- #EndLibraryItem --> <!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-importObjectLightwave-2.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-importObjectLightwave-2.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h3>2. Select the appropriate settings in the fbx export dialog</h3>
<ul><li> Select the fbx file name. Make sure to save the exported fbx file in the Assets folder of your current Unity project.
</li><li> In the FBX dialogue panel you MUST select &quot;Embed Textures&quot; else the exported object will have no UVs. This is a bug in the lightwave fbx exporter and will be fixed in a future version according to Alias.
</li><li> If you want to export animations into unity you must have &quot;Animations&quot; checked. You also need to have &quot;Lights&quot; or &quot;Cameras&quot; checked.
</li><li> To change the name of the exported animation clip in unity, change the name from &quot;LW Take 001&quot; to your liking.
</li></ul>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-importObjectLightwave-3.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-importObjectLightwave-3.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>

<h3>3. Switch to unity.</h3>
<ul><li> Unity will automatically import the fbx file and automatically generate materials for the textures.
</li><li> Drag the imported fbx file from the project view into the scene view.
</li></ul>

<!-- #BeginLibraryItem name="/Library/doc-figure.lbi" src="%22images/HOWTO-importObjectLightwave-4.jpg%22" --><p><table><tr><td><img class="figure" src="images/HOWTO-importObjectLightwave-4.jpg"></td></tr></table></p><!-- #EndLibraryItem -->
</p>


<h2>Important notes</h2>
<ul><li>  You must select &quot;Embed Textures&quot; in the FBX panel when exporting or no UVs are exported
</li><li>  If you want to export animations you must enable &quot;Animations&quot; and either &quot;Camera&quot; or &quot;Lights&quot;.
</li><li>  It is strongly recommended to always place your textures in a folder called &quot;Textures&quot; next to the fbx file. This will guarantee that Unity can always find the Texture and automatically connect the texture to the material.
</li></ul>



<p>Unity natively imports Maya files. To get started, simply place your <b>.mb</b> or <b>.ma</b> file in your project's assets folder.
When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<h2> Unity currently imports from Maya</h2>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> Meshes with vertex colors, normals and up to 2 UV sets
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li><li> Animations FK &amp; IK
</li><li> Bone based animations
</li></ol>

<p>Unity does not import blend shapes. Use Bone based animations instead. Unity automatically triangulates polygonal meshes when importing. Thus there is no need to do this manually in Maya.
</p>

<p>If you are using IK to animate characters you have to select the imported .mb file in project view and choose <b>Assets -&gt; Import Settings...</b>. In the import settings dialog, you have to choose <b>Bake IK &amp; Simulation</b>.
</p>


<h2>Requirements</h2>
<p>In order to import Maya <b>.mb</b> and <b>.ma</b> files, you need to have Maya installed on the machine you are using Unity to import the .mb/.ma file. Maya 5.0 and up is supported.
</p>

<p>If you don't have Maya installed on your machine but want to import a Maya file from another machine, you can export to the fbx format, which Unity imports natively.
</p>
<ol><li> Open the Maya file
</li><li> If you don't have the fbx plugin already installed. Download and install it from <a class="wiki"  href="http://www.alias.com/eng/products-services/fbx/download.shtml">here</a>.
</li><li> Place the exported fbx file in the Unity project folder. Unity will now automatically import the fbx file.
</li></ol>

<h3> Behind the import process (Advanced)</h3>
<p>When Unity imports a Maya file it will launch Maya in the background. Unity then communicates with Maya to convert the .mb file into a format Unity can read. The first time you import a Maya file in Unity, Maya has to launch in a command line process, this can take around 20 seconds, but the second time importing will be very quick.
</p>



<p>Unity imports from Modo through their pipelining features using fbx. In Modo 201, simply save your modo scene as an <b>.fbx</b> file to the project folder. When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<p>If you modify the .fbx file, Unity will automatically update whenever you save.
</p>

<h2> Unity currently imports</h2>
<ol><li> All objects with position, rotation and scale.
</li><li> Meshes with vertices, normals and UV's
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li></ol>



<p>Unity natively imports Cheetah3D files. To get started, simply place your <b>.jas</b> file in your project's assets folder.
When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<p>If you modify your .jas file, Unity will automatically update whenever you save.
</p>

<h2> Unity currently imports from Cheetah3D</h2>
<ol><li> All objects with position, rotation and scale.
</li><li> Meshes with vertices, polygons, triangles, UV's and Normals.
</li><li> Animations
</li><li> Materials with diffuse color and textures
</li></ol>

<h4>Requirements</h4>
<ol><li> You need to have at least Cheetah3D 2.6 installed.
</li></ol>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-exportpackage.html">HOWTO-exportpackage</a></li><li class="toclevel"><a href="../Manual/HOWTO-InstallStandardAssets.html">HOWTO-InstallStandardAssets</a></li></ul>
</p>



<p>Unity stores a lot of metadata about your assets - import settings, links to other assets, etc... Here's how to move them between projects, while preserving all this info.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Select all the asset files you want to export from the project window.
</li><li> Choose <b>Assets-&gt;Export Package...</b> from the main menu.
</li><li> Save the package somewhere
</li><li> Open the project you want to import the assets to.
</li><li> Choose <b>Assets-&gt;Import Package...</b> from the main menu.
</li><li> Select the package file you created in step 3
</li></ol>

<p></div></div></td></tr></table>
</p>

<h2>Hints</h2>
<ul><li> If you place the assets file in the Standard Packages folder next to your Unity application, they will appear in the Create New Project dialog.
</li></ul>



<p>Unity ships with Standard Assets and Pro Standard Assets.
</p>

<p>Standard Assets contain useful things like a first person controller, some skyboxes, flares, a water plane prefab and common camera scripts.
</p>

<p>Pro Standard Assets contain all kinds of Image Effects, like <a href="../Components/script-GlowEffect.html">Glow</a>, <a href="../Components/script-MotionBlur.html">Motion Blur</a>, <a href="../Components/script-ColorCorrectionEffect.html">Color Correction</a>, <a href="../Components/script-NoiseEffect.html">Noise</a> and others; as well as several advanced <a href="../Manual/HOWTO-Water.html"> Water prefabs</a>.
</p>

<h3> Installing</h3>
<p>When creating a new project Unity automatically installs the Standard Assets and Pro Standard Assets for Pro users.
</p>

<h3> Upgrading</h3>

<p>Sometimes you might want to upgrade your Standard Assets, for example because a new version of Unity ships with new Standard Assets:
</p>

<ol><li> Open your project.
</li><li> Choose <b>Assets -&gt; Import Package</b> from the menu.
</li><li> Select <i>Standard Assets.unitypackage</i> or <i>Pro Standard Assets.unitypackage</i>.
</li><li> A list of new or replaced assets will be presented, click <i>Apply Now</i>.
</li></ol>



