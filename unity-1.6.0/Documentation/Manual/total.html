
</p>
<h1>Unity Manual</h1>

<p>Thank you for trying Unity.  Unity is made to empower users to create the best interactive entertainment or multimedia experience that they can.  This manual is designed to help you learn how to use Unity, from basic to advanced techniques.  It can be read from start to finish or used as a reference.
</p>

<p>The basic structure is divided into three sections.  The first section, <a href='User Guide.html'>User Guide</a>, is an introduction to Unity's interface, asset workflow, and the basics of building a game.  If you are new to Unity, it is recommended that you start learning by reading the <a href='Unity Basics.html'>Unity Basics</a> sub-section.
</p>

<p>The second section, <a href='FAQ.html'>FAQ</a>, is a set of frequently asked questions about performing common tasks that require a few steps.
</p>

<p>The third section, <a href='Advanced.html'>Advanced</a>, addresses topics such as game optimization, shaders, file sizes, and deployment.
</p>

<p>If you find that any question you have is not answered in this manual please ask in the <a class="wiki"  href="http://forum.unity3d.com">forum</a>.  You'll definitely find your answer there.
</p>

<p>Happy reading,
</p>

<p><i>OverTheEdge (OTEE)</i>
</p>

<h2>Table of Contents</h2>
<p><ul class="toc"><li class="toclevel"><a href='User Guide.html'>User Guide</a></li><ul class="toc"><li class="toclevel"><a href='Unity Basics.html'>Unity Basics</a></li><ul class="toc"><li class="toclevel"><a href='Learning the Interface.html'>Learning the Interface</a></li><li class="toclevel"><a href='Asset Workflow.html'>Asset Workflow</a></li><li class="toclevel"><a href='Creating Scenes.html'>Creating Scenes</a></li><li class="toclevel"><a href='Publishing Builds.html'>Publishing Builds</a></li><li class="toclevel"><a href='Tutorials.html'>Tutorials</a></li></ul><li class="toclevel"><a href='Building Scenes.html'>Building Scenes</a></li><ul class="toc"><li class="toclevel"><a href='GameObjects.html'>GameObjects</a></li><li class="toclevel"><a href='Using Components.html'>Using Components</a></li><li class="toclevel"><a href='Prefabs.html'>Prefabs</a></li><li class="toclevel"><a href='Lights.html'>Lights</a></li><li class="toclevel"><a href='Cameras.html'>Cameras</a></li><li class="toclevel"><a href='Particle Systems.html'>Particle Systems</a></li></ul><li class="toclevel"><a href='Working with Assets.html'>Assets</a></li><ul class="toc"><li class="toclevel"><a href='Importing Assets.html'>Importing Assets</a></li><li class="toclevel"><a href='Meshes.html'>Meshes</a></li><li class="toclevel"><a href='Textures.html'>Texture 2D</a></li><li class="toclevel"><a href='Materials.html'>Materials and Shaders</a></li><li class="toclevel"><a href='Audio Files.html'>Audio Files</a></li><li class="toclevel"><a href='Scripting.html'>Scripting</a></li></ul><li class="toclevel"><a href='Creating Gameplay.html'>Creating Gameplay</a></li><ul class="toc"><li class="toclevel"><a href='Instantiating Prefabs.html'> Instantiating Prefabs at runtime</a></li><li class="toclevel"><a href='Input.html'>Input</a></li><li class="toclevel"><a href='Transforms.html'>Tranforms</a></li><li class="toclevel"><a href='Physics.html'>Physics</a></li><li class="toclevel"><a href='Animation.html'>Animation</a></li><li class="toclevel"><a href='Character-Animation.html'>Character Animation</a></li><li class="toclevel"><a href='Sound.html'>Sound</a></li><li class="toclevel"><a href='Game Interface Elements.html'> Making a GUI</a></li></ul></ul><li class="toclevel"><a href='FAQ.html'>FAQ</a></li><ul class="toc"><li class="toclevel"><a href='Graphics how-tos.html'>Graphics how-tos</a></li><ul class="toc"><li class="toclevel"><a href='HOWTO-bumpmap.html'> How Do I Use Bump Maps?</a></li><li class="toclevel"><a href='HOWTO-UseDetailTexture.html'> How do I use Detail Textures?</a></li><li class="toclevel"><a href='HOWTO-MakeCubemap.html'>How Do I Make a Cubemap Texture?</a></li><li class="toclevel"><a href='HOWTO-UseSkybox.html'>How do I Make a Skybox?</a></li><li class="toclevel"><a href='HOWTO-MeshParticleEmitter.html'>How Do I make a Mesh Particle Emitter?</a></li><li class="toclevel"><a href='HOWTO-SplashScreen.html'> How do I make a Splash Screen</a></li><li class="toclevel"><a href='HOWTO-LightCookie.html'> How do I make a Spot Light Cookie?</a></li><li class="toclevel"><a href='HOWTO-FixZAxisIsUp.html'>Fixing the rotation of an imported model</a></li><li class="toclevel"><a href='HOWTO-Water.html'>How do I use Water?</a></li><li class="toclevel"><a href='HOWTO-Lightmap.html'> How to lightmap an environment</a></li></ul><li class="toclevel"><a href='HOWTO-importObject.html'> How do I import objects from my 3D app?</a></li><ul class="toc"><li class="toclevel"><a href='HOWTO-ImportObjectMax.html'> Importing Objects From 3dsMax</a></li><li class="toclevel"><a href='HOWTO-ImportObjectBlender.html'> Importing Objects From Blender</a></li><li class="toclevel"><a href='HOWTO-ImportObjectCinema4D.html'> Importing Objects From Cinema 4D</a></li><li class="toclevel"><a href='HOWTO-importObjectLightwave.html'> Importing Objects From Lightwave</a></li><li class="toclevel"><a href='HOWTO-ImportObjectMaya.html'> Importing Objects From Maya</a></li><li class="toclevel"><a href='HOWTO-ImportObjectModo.html'> Importing Objects From Modo</a></li><li class="toclevel"><a href='HOWTO-ImportObjectCheetah3D.html'> Importing Objects From Cheetah3D</a></li></ul><li class="toclevel"><a href='Workflow.html'>Workflow</a></li><ul class="toc"><li class="toclevel"><a href='HOWTO-exportpackage.html'>How do I reuse assets between projects?</a></li><li class="toclevel"><a href='HOWTO-InstallStandardAssets.html'>How do I install or upgrade Standard Assets</a></li></ul><li class="toclevel"><a href='Game Code How-to.html'>Game Code How-to</a></li><ul class="toc"><li class="toclevel"><a href='HOWTO-First Person Walkthrough.html'> How to make a simple first person walkthrough</a></li></ul></ul><li class="toclevel"><a href='Advanced.html'>Advanced</a></li><ul class="toc"><li class="toclevel"><a href='Optimizing Graphics Performance.html'>Optimizing Graphics Performance</a></li><li class="toclevel"><a href='Shaders.html'>Shaders</a></li><ul class="toc"><li class="toclevel"><a href='ShaderTut1.html'>Shaders: Getting started</a></li><li class="toclevel"><a href='ShaderTut2.html'>Shaders: Vertex and Fragment Programs</a></li><li class="toclevel"><a href='SL-Shader.html'>Shader</a></li><ul class="toc"><li class="toclevel"><a href='SL-Properties.html'>Properties</a></li><li class="toclevel"><a href='SL-SubShader.html'>SubShaders</a></li><ul class="toc"><li class="toclevel"><a href='SL-Pass.html'> Pass</a></li><ul class="toc"><li class="toclevel"><a href='SL-Material.html'> Color, Material &amp; Lighting</a></li><li class="toclevel"><a href='SL-CullAndDepth.html'>Culling &amp; Depth Testing</a></li><li class="toclevel"><a href='SL-SetTexture.html'>Texturing</a></li><li class="toclevel"><a href='SL-Fog.html'>Fog</a></li><li class="toclevel"><a href='SL-AlphaTest.html'> Alpha testing</a></li><li class="toclevel"><a href='SL-Blend.html'> Blend</a></li><li class="toclevel"><a href='SL-NameAndTags.html'> Name and Tags</a></li><li class="toclevel"><a href='SL-BindChannels.html'> Bind Channels</a></li></ul><li class="toclevel"><a href='SL-UsePass.html'> UsePass</a></li><li class="toclevel"><a href='SL-GrabPass.html'> GrabPass</a></li></ul><li class="toclevel"><a href='SL-Fallback.html'>Fallback statement</a></li></ul><li class="toclevel"><a href='SL-RenderPipeline.html'> Unity's Rendering Pipeline</a></li><ul class="toc"><li class="toclevel"><a href='SL-Attenuation.html'> Attenuation and cookies for pixel lights</a></li></ul><li class="toclevel"><a href='SL-BuiltinValues.html'>ShaderLab builtin values</a></li><li class="toclevel"><a href='Reference - Structure.html'>Reference - Structure</a></li><li class="toclevel"><a href='Reference - Values.html'>Reference - Values</a></li><li class="toclevel"><a href='ShaderLab Cheat Sheet.html'>ShaderLab Cheat Sheet</a></li></ul><li class="toclevel"><a href='Reducing File size.html'>Reducing File Size</a></li><li class="toclevel"><a href='Web Player Deployment.html'> Web Player Deployment</a></li><ul class="toc"><li class="toclevel"><a href='Web-LoaderImages.html'>Customizing Web Player loading screen</a></li><li class="toclevel"><a href='Web-GeneratedHtml.html'>HTML code to load Unity content</a></li><li class="toclevel"><a href='Web-BrowserCommunication.html'> Web Player and Browser communication</a></li></ul><li class="toclevel"><a href='Plugins.html'>Plugins - Pro only feature</a></li><li class="toclevel"><a href='Build Player Pipeline.html'>Build Player pipeline</a></li></ul></ul>


<p>This section of the Manual is focused on the features and functions of Unity.  It focuses on the interface, core Unity building blocks, asset workflow, and basic gameplay creation.  By the time you are done reading the user guide, you will have a solid understanding of how to use Unity to put together an interactive scene and publish it.
</p>

<p>It is recommended that new users begin by reading the <a href="../Manual/Unity Basics.html">Unity Basics</a> section.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Unity Basics.html">Unity Basics</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Learning the Interface.html">Learning the Interface</a></li><li class="toclevel"><a href="../Manual/Asset Workflow.html">Asset Workflow</a></li><li class="toclevel"><a href="../Manual/Creating Scenes.html">Creating Scenes</a></li><li class="toclevel"><a href="../Manual/Publishing Builds.html">Publishing Builds</a></li><li class="toclevel"><a href="../Manual/Tutorials.html">Tutorials</a></li></ul><li class="toclevel"><a href="../Manual/Building Scenes.html">Building Scenes</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/GameObjects.html">GameObjects</a></li><li class="toclevel"><a href="../Manual/Using Components.html">Using Components</a></li><li class="toclevel"><a href="../Manual/Prefabs.html">Prefabs</a></li><li class="toclevel"><a href="../Manual/Lights.html">Lights</a></li><li class="toclevel"><a href="../Manual/Cameras.html">Cameras</a></li><li class="toclevel"><a href="../Manual/Particle Systems.html">Particle Systems</a></li></ul><li class="toclevel"><a href="../Manual/Working with Assets.html">Working with Assets</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Importing Assets.html">Importing Assets</a></li><li class="toclevel"><a href="../Manual/Meshes.html">Meshes</a></li><li class="toclevel"><a href="../Manual/Textures.html">Textures</a></li><li class="toclevel"><a href="../Manual/Materials.html">Materials</a></li><li class="toclevel"><a href="../Manual/Audio Files.html">Audio Files</a></li><li class="toclevel"><a href="../Manual/Scripting.html">Scripting</a></li></ul><li class="toclevel"><a href="../Manual/Creating Gameplay.html">Creating Gameplay</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Instantiating Prefabs.html">Instantiating Prefabs</a></li><li class="toclevel"><a href="../Manual/Input.html">Input</a></li><li class="toclevel"><a href="../Manual/Transforms.html">Transforms</a></li><li class="toclevel"><a href="../Manual/Physics.html">Physics</a></li><li class="toclevel"><a href="../Manual/Animation.html">Animation</a></li><li class="toclevel"><a href="../Manual/Character-Animation.html">Character-Animation</a></li><li class="toclevel"><a href="../Manual/Sound.html">Sound</a></li><li class="toclevel"><a href="../Manual/Game Interface Elements.html">Game Interface Elements</a></li></ul></ul>
</p>




<p>This section is your key to getting started with Unity.  It will explain the Unity interface, menu items, using assets, creating scenes, and publishing builds.  When you are finished reading this section, you will understand how Unity works, how to use it effectively, and the steps to put a basic game together.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Learning the Interface.html">Learning the Interface</a></li><li class="toclevel"><a href="../Manual/Asset Workflow.html">Asset Workflow</a></li><li class="toclevel"><a href="../Manual/Creating Scenes.html">Creating Scenes</a></li><li class="toclevel"><a href="../Manual/Publishing Builds.html">Publishing Builds</a></li><li class="toclevel"><a href="../Manual/Tutorials.html">Tutorials</a></li></ul>
</p>

<p>The following is a list of common tasks in Unity and how to accomplish them.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Graphics how-tos.html">Graphics how-tos</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-bumpmap.html">HOWTO-bumpmap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseDetailTexture.html">HOWTO-UseDetailTexture</a></li><li class="toclevel"><a href="../Manual/HOWTO-MakeCubemap.html">HOWTO-MakeCubemap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseSkybox.html">HOWTO-UseSkybox</a></li><li class="toclevel"><a href="../Manual/HOWTO-MeshParticleEmitter.html">HOWTO-MeshParticleEmitter</a></li><li class="toclevel"><a href="../Manual/HOWTO-SplashScreen.html">HOWTO-SplashScreen</a></li><li class="toclevel"><a href="../Manual/HOWTO-LightCookie.html">HOWTO-LightCookie</a></li><li class="toclevel"><a href="../Manual/HOWTO-FixZAxisIsUp.html">HOWTO-FixZAxisIsUp</a></li><li class="toclevel"><a href="../Manual/HOWTO-Water.html">HOWTO-Water</a></li><li class="toclevel"><a href="../Manual/HOWTO-Lightmap.html">HOWTO-Lightmap</a></li></ul><li class="toclevel"><a href="../Manual/HOWTO-importObject.html">HOWTO-importObject</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectMax.html">HOWTO-ImportObjectMax</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectBlender.html">HOWTO-ImportObjectBlender</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectCinema4D.html">HOWTO-ImportObjectCinema4D</a></li><li class="toclevel"><a href="../Manual/HOWTO-importObjectLightwave.html">HOWTO-importObjectLightwave</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectMaya.html">HOWTO-ImportObjectMaya</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectModo.html">HOWTO-ImportObjectModo</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectCheetah3D.html">HOWTO-ImportObjectCheetah3D</a></li></ul><li class="toclevel"><a href="../Manual/Workflow.html">Workflow</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-exportpackage.html">HOWTO-exportpackage</a></li><li class="toclevel"><a href="../Manual/HOWTO-InstallStandardAssets.html">HOWTO-InstallStandardAssets</a></li></ul><li class="toclevel"><a href="../Manual/Game Code How-to.html">Game Code How-to</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-First Person Walkthrough.html">HOWTO-First Person Walkthrough</a></li></ul></ul>
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Optimizing Graphics Performance.html">Optimizing Graphics Performance</a></li><li class="toclevel"><a href="../Manual/Shaders.html">Shaders</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/ShaderTut1.html">ShaderTut1</a></li><li class="toclevel"><a href="../Manual/ShaderTut2.html">ShaderTut2</a></li><li class="toclevel"><a href="../Manual/SL-Shader.html">SL-Shader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Properties.html">SL-Properties</a></li><li class="toclevel"><a href="../Manual/SL-SubShader.html">SL-SubShader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Pass.html">SL-Pass</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Material.html">SL-Material</a></li><li class="toclevel"><a href="../Manual/SL-CullAndDepth.html">SL-CullAndDepth</a></li><li class="toclevel"><a href="../Manual/SL-SetTexture.html">SL-SetTexture</a></li><li class="toclevel"><a href="../Manual/SL-Fog.html">SL-Fog</a></li><li class="toclevel"><a href="../Manual/SL-AlphaTest.html">SL-AlphaTest</a></li><li class="toclevel"><a href="../Manual/SL-Blend.html">SL-Blend</a></li><li class="toclevel"><a href="../Manual/SL-NameAndTags.html">SL-NameAndTags</a></li><li class="toclevel"><a href="../Manual/SL-BindChannels.html">SL-BindChannels</a></li></ul><li class="toclevel"><a href="../Manual/SL-UsePass.html">SL-UsePass</a></li><li class="toclevel"><a href="../Manual/SL-GrabPass.html">SL-GrabPass</a></li></ul><li class="toclevel"><a href="../Manual/SL-Fallback.html">SL-Fallback</a></li></ul><li class="toclevel"><a href="../Manual/SL-RenderPipeline.html">SL-RenderPipeline</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Attenuation.html">SL-Attenuation</a></li></ul><li class="toclevel"><a href="../Manual/SL-BuiltinValues.html">SL-BuiltinValues</a></li><li class="toclevel"><a href="../Manual/Reference - Structure.html">Reference - Structure</a></li><li class="toclevel"><a href="../Manual/Reference - Values.html">Reference - Values</a></li><li class="toclevel"><a href="../Manual/ShaderLab Cheat Sheet.html">ShaderLab Cheat Sheet</a></li></ul><li class="toclevel"><a href="../Manual/Reducing File size.html">Reducing File size</a></li><li class="toclevel"><a href="../Manual/Web Player Deployment.html">Web Player Deployment</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Web-LoaderImages.html">Web-LoaderImages</a></li><li class="toclevel"><a href="../Manual/Web-GeneratedHtml.html">Web-GeneratedHtml</a></li><li class="toclevel"><a href="../Manual/Web-BrowserCommunication.html">Web-BrowserCommunication</a></li></ul><li class="toclevel"><a href="../Manual/Plugins.html">Plugins</a></li><li class="toclevel"><a href="../Manual/Build Player Pipeline.html">Build Player Pipeline</a></li></ul>
</p>



<p>This section of the Manual is focused on the features and functions of Unity.  It focuses on the interface, core Unity building blocks, asset workflow, and basic gameplay creation.  By the time you are done reading the user guide, you will have a solid understanding of how to use Unity to put together an interactive scene and publish it.
</p>

<p>It is recommended that new users begin by reading the <a href="../Manual/Unity Basics.html">Unity Basics</a> section.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Unity Basics.html">Unity Basics</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Learning the Interface.html">Learning the Interface</a></li><li class="toclevel"><a href="../Manual/Asset Workflow.html">Asset Workflow</a></li><li class="toclevel"><a href="../Manual/Creating Scenes.html">Creating Scenes</a></li><li class="toclevel"><a href="../Manual/Publishing Builds.html">Publishing Builds</a></li><li class="toclevel"><a href="../Manual/Tutorials.html">Tutorials</a></li></ul><li class="toclevel"><a href="../Manual/Building Scenes.html">Building Scenes</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/GameObjects.html">GameObjects</a></li><li class="toclevel"><a href="../Manual/Using Components.html">Using Components</a></li><li class="toclevel"><a href="../Manual/Prefabs.html">Prefabs</a></li><li class="toclevel"><a href="../Manual/Lights.html">Lights</a></li><li class="toclevel"><a href="../Manual/Cameras.html">Cameras</a></li><li class="toclevel"><a href="../Manual/Particle Systems.html">Particle Systems</a></li></ul><li class="toclevel"><a href="../Manual/Working with Assets.html">Working with Assets</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Importing Assets.html">Importing Assets</a></li><li class="toclevel"><a href="../Manual/Meshes.html">Meshes</a></li><li class="toclevel"><a href="../Manual/Textures.html">Textures</a></li><li class="toclevel"><a href="../Manual/Materials.html">Materials</a></li><li class="toclevel"><a href="../Manual/Audio Files.html">Audio Files</a></li><li class="toclevel"><a href="../Manual/Scripting.html">Scripting</a></li></ul><li class="toclevel"><a href="../Manual/Creating Gameplay.html">Creating Gameplay</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Instantiating Prefabs.html">Instantiating Prefabs</a></li><li class="toclevel"><a href="../Manual/Input.html">Input</a></li><li class="toclevel"><a href="../Manual/Transforms.html">Transforms</a></li><li class="toclevel"><a href="../Manual/Physics.html">Physics</a></li><li class="toclevel"><a href="../Manual/Animation.html">Animation</a></li><li class="toclevel"><a href="../Manual/Character-Animation.html">Character-Animation</a></li><li class="toclevel"><a href="../Manual/Sound.html">Sound</a></li><li class="toclevel"><a href="../Manual/Game Interface Elements.html">Game Interface Elements</a></li></ul></ul>
</p>




<p>This section is your key to getting started with Unity.  It will explain the Unity interface, menu items, using assets, creating scenes, and publishing builds.  When you are finished reading this section, you will understand how Unity works, how to use it effectively, and the steps to put a basic game together.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Learning the Interface.html">Learning the Interface</a></li><li class="toclevel"><a href="../Manual/Asset Workflow.html">Asset Workflow</a></li><li class="toclevel"><a href="../Manual/Creating Scenes.html">Creating Scenes</a></li><li class="toclevel"><a href="../Manual/Publishing Builds.html">Publishing Builds</a></li><li class="toclevel"><a href="../Manual/Tutorials.html">Tutorials</a></li></ul>
</p>



<p>Let's begin learning Unity.  If you have not yet opened Unity, you can launch it by double-clicking the Unity icon inside your <i>/Applications/Unity</i> folder.  When it launches for the first time, you will see a screen like this:
</p>

<p><img class='figure' src='images/Learning the Interface-0.jpg' /><br>
<i>The default project when Unity launches.  If you have downloaded and opened any example projects, your screen may look different</i>
</p>

<p>There is a lot to learn, so take the time you need to observe and understand the interface.  We will walk through each interface element together.
</p>

<h2>First Glance</h2>

<p>Each section of the main window is called a <b>View</b>.  There are several types of Views in Unity, but you may not need to view them all at once.  Different <b>Layout modes</b> contain different arrangements of the Views.  You can observe the combinations of Views by clicking on the Layout drop-down selector, in the upper-right hand corner of the window, and clicking on a different Layout name.
</p>

<p><img class='figure' src='images/Learning the Interface-1.jpg' /><br>
<i>Layout mode selector drop-down</i>
</p>

<p>For now, please click the Layout selector, highlight <b>Animation</b>, and click again to switch to Animation layout. You can also use <b>Window -> Layouts -> Animation</b> from the menu.  The Animation layout contains all the views, and is the best way to introduce them all.
</p>

<p>You can immediately tell which view is which by looking at the name displayed in the upper-left corner of the view area.  The different views are Scene, Game, Project, Hierarchy, Inspector, and Keyframe.  Here's a brief description of how each view is used.
</p>

<ul><li> <b>Scene View</b> - used for placing game objects.
</li><li> <b>Game View</b> - representation of how the game will look when run.
</li><li> <b>Hierarchy View</b> - a list of all the game objects currently in the scene.
</li><li> <b>Project View</b> - all the assets &amp; resources available in the open project.
</li><li> <b>Inspector View</b> - displays details and properties of the currently highlighted object.
</li><li> <b>Timeline View</b> - used to create basic animations on a timeline for the currently highlighted object.
</li></ul>

<h2>Scene View</h2>

<p><img class='figure' src='images/Learning the Interface-2.jpg' /><br>
<i>The Scene View</i>
</p>

<p><b>Scene View</b> is your interactive sandbox.  You will use the Scene View to place environments, the player, the camera, enemies, and all other Game Objects.  Maneuvering and manipulating the Scene View are some of the most important functions in Unity.  It is your best way to look at your game world through the eyes of a designer instead of a player.  You have free range to move and manipulate objects in the Scene View, but there are some basic commands you should know to use Scene View effectively.
</p>

<p>The first command you should know is the <b>Frame Selected</b> command.  This command will focus your Scene View on the game object you currently have selected.  To use it, click on any object in the Hierarchy View, move your mouse over the Scene View, and press <b>F</b> on the keyboard.  Scene View window will move to focus on the selected object.  This command is extremely useful, and you will use it lots while you're putting your scenes together.
</p>

<h3>Manipulating in Scene View</h3>

<p>There is a <b>Toolbar</b> above the Scene View, the one that contains the Layout mode selector.
</p>

<p><img class='figure' src='images/Learning the Interface-3.jpg' /><br>
<i>The Toolbar</i>
</p>

<p>Although this Toolbar is not attached to the Scene View window, the four Tools on the left side are used to navigate around in the Scene View and manipulate the Game Objects inside it.  The first tool from the left is the <b>View Tool</b> which is described further below. The other three tools in the Toolbar are the <b>Manipulation Tools</b>.  Highlighting one of them will allow you to move, rotate, or scale your Game Objects visually.  When you have one of these tools selected, you can click on any Game Object in the Scene View window to select it.  Now press <b>F</b> to frame the object in the center of your view.
</p>

<p>The different Manipulation Tools are:
</p>

<p><img class='figure' src='images/Learning the Interface-4.jpg' /><br>
<i>Translate Tool - Hotkey "W"</i>
</p>

<p><img class='figure' src='images/Learning the Interface-5.jpg' /><br>
<i>Rotate Tool - Hotkey "E"</i>
</p>

<p><img class='figure' src='images/Learning the Interface-6.jpg' /><br>
<i>Scale Tool - Hotkey "R"</i>
</p>

<p>When you have a Game Object selected, you will see a <b>Gizmo</b>  drawn around the three dimensional axes X, Y, and Z.  Each of the Manipulation Tools has a different Gizmo that is drawn around the Game Object.
</p>

<p><img class='figure' src='images/Learning the Interface-7.jpg' /><br>
<i>Different Gizmos for the Manipulation Tools</i>
</p>

<ul><li>Click and drag any axis on your current Gizmo to translate, rotate, or scale the <b>Transform</b> component of the currently selected Game Object.
</li><li>You can also click and drag in the center of the Gizmo to manipulate the object on multiple axes at once.
</li><li>If you have a three button mouse, you can click the middle button to adjust the last-adjusted axis without clicking directly on it.
</li></ul>

<p>For more information on transforming Game Objects, please view the <a href="../Components/class-Transform.html">Transform Component</a> page.
</p>

<h3>Navigating in Scene View</h3>

<p>There are different ways to look around your scene depending on the kind of mouse you are using.
</p>

<h4>Three-button mouse</h4>

<p>We recommend that you use a three-button mouse with Unity.
</p>

<ul><li> To use Orbit mode, hold down ALT and drag with the left mouse button pressed.
</li><li> To use Drag mode, hold down ALT and drag with the middle button pressed.
</li><li> To use Zoom mode, hold down ALT and drag with the right button pressed. If you have a mouse with a scroll wheel, you can use that instead.
</li></ul>

<h4>One-button mouse</h4>

<p>If you don't have a three-button mouse, you will have to use the <b>View Tool</b> to navigate the scene.  Click the left-most button in the toolbar with the hand on it.  This is the View Tool, and its different modes allow you to travel within the Scene View using a single-button mouse.  When this tool is selected, you must use the left mouse button to navigate.
</p>

<ul><li> To orbit around the scene, hold down the ALT and drag the mouse.
</li><li> To pan the view, drag the mouse.
</li><li> To zoom the view in and out, hold down the CMD and drag the mouse.
</li></ul>

<h4>Trackpad</h4>

<p>The shortcuts for using a trackpad are identical to the single-button mouse shortcuts.  We have also included keyboard shortcuts to each of the tools in the Toolbar, so you don't have to do too much dragging on the trackpad.
</p>

<h4>The different View Tool modes</h4>

<p><img class='figure' src='images/Learning the Interface-8.jpg' /><br>
<i>View Tool in Drag Mode - Hotkey "Q"</i>
</p>

<p>With Drag Mode selected, move your mouse over the Scene View, click and hold the mouse button, and drag the mouse around.  This will move your view up, down, left, and right.  You will also need to access the <b>Orbit</b> and <b>Zoom Modes</b> to make the most use of the View Tool.  To enter Orbit Mode, keep the View Tool selected and hold the <i>Option</i> key.  Now click &amp; drag your mouse, and see how the view rotates around.  Also notice how the View Tool icon has changed from a hand to an eye.
</p>

<p><img class='figure' src='images/Learning the Interface-9.jpg' /><br>
<i>View Tool in Orbit Mode - Option key</i>
</p>

<p>Finally, you can access the Zoom Mode by holding the <b>Command</b> key.  In this mode, clicking and dragging the mouse will zoom your view forward and backward.  Notice that the icon for Zoom Mode is a magnifying glass.
</p>

<p><img class='figure' src='images/Learning the Interface-10.jpg' /><br>
<i>View Tool in Zoom Mode - Command key</i>
</p>

<p>Using the View Tool modes and dragging the mouse is the basic way of navigating in Scene View.
</p>


<h3>Scene View Control Bar</h3>

<p>All of the Views have a different <b>Control Bar</b> at the top of the window.  The Scene View Control Bar has the most options, and it looks like this:
</p>

<p><img class='figure' src='images/Learning the Interface-11.jpg' /><br>
<i>Scene View Control Bar</i>
</p>

<p>The first drop-down is the View Selector.  Expanding this will let you change the current View to any other, and back again.  All the Views have this selector, and it comes in very handy when you want to create your own custom layout on the Unity interface.
</p>

<p><img class='figure' src='images/Learning the Interface-12.jpg' /><br>
<i>Every View has a View Selector</i>
</p>

<p>The next drop-down is the Draw Mode for the Scene View.  You can choose to view all objects in the Scene View as Textured, Wireframe, or Textured with Wireframe overlay.  This has no effect on your game when it is published.
</p>

<p><img class='figure' src='images/Learning the Interface-13.jpg' /><br>
<i>Draw Mode drop-down</i>
</p>

<p>The third drop-down is the Render Mode for the Scene View.  You can choose to view the RGB or the Alpha value of all objects in the scene.  Again, this has no effect on your published game.
</p>

<p><img class='figure' src='images/Learning the Interface-14.jpg' /><br>
<i>Render Mode drop-down</i>
</p>

<p>The next item on the Control Bar is a series of three buttons.
</p>

<p><img class='figure' src='images/Learning the Interface-15.jpg' /><br>
<i>Three buttons on the Scene View Control Bar</i>
</p>

<p>The left button toggles generic lighting on and off.  When the button is disabled, you will see typical, plain lighting on your entire scene.  When it is enabled, you will see the effects of the light objects you have placed.  Having this button enabled will allow you to see the lighting your game will use when it is published.
</p>

<p>The middle button will toggle various effects on and off, such as the Scene View Grid, skyboxes, and GUI Elements.  Keeping the button enabled will allow you to see your game as it will look when published.
</p>

<p>The right button toggles Orthographic mode.  Turning this on removes all perspective from the Scene View.  This button will not affect how your game will look when published.  This is useful for precise placement of objects.
</p>

<p><img class='figure' src='images/Learning the Interface-16.jpg' /><br>
<i>Orthographic button disabled on the left, enabled on the right</i>
</p>

<p>The next drop-down is the Direction drop-down.  It moves the Scene View to the position you choose.
</p>

<p>The last drop-down is the Layers drop-down.  You can use it to selectively view objects assigned to different Layers.  For more information on Layers, view <a href="../ScriptingConcepts/Layers.html">this page</a>.  This will not have an effect on your published game.
</p>


<h2>Game View</h2>
<p><img class='figure' src='images/Learning the Interface-17.jpg' /><br>
<i>Game View &mdash; What you'll see when playing your game</i>
</p>

<p>The <b>Game View</b> is rendered using information from the Camera(s) in your game.  This view will show you what will be seen when you are playing your game.  You can see the Game View change when you translate or rotate the main camera in the scene.
</p>

<p>You will need to use one or more Cameras to control what the player actually sees when they are playing your game.  For more information about Cameras, please view the <a href="../Components/class-Camera.html">Camera Component page</a>.
</p>

<h3>The Play Buttons &amp; Status Bar</h3>

<p>The buttons to play, pause, and step through your game are immediately beneath the Game View.  At any time while you're building a scene, you can enter Play mode and see how your game is working.
</p>

<p><img class='figure' src='images/Learning the Interface-18.jpg' /><br>
<i>The Play buttons and Status Bar</i>
</p>

<p>Press the Play button to enter Play mode.  While your scene is in Play mode, you can still move, rotate, add, and delete objects.  You can also change variable settings.  Any changes you make while in Play mode are temporary, and will be reset when you exit Play mode.  You can exit by clicking the Play button again.  When in Play mode, you can Pause and Step your game. Pausing and then inspecting your scene is a great way to figure out what's going on, and if you have a problem, what's amiss.
</p>

<p>The Status Bar area to the left  serves multiple purposes.  It will provide context-sensitive messages and tips, error messages, and statements printed from scripts.  If there is a problem with your game, keeping an eye on the Status Bar is the best way to find the error.  You can double-click on the Status Bar to bring up the Console window, which has all script or run-time errors visible.
</p>

<h3>Game View Control Bar</h3>

<p>Immediately to the right of the View drop-down on the control bar is the Aspect drop-down.  Here, you can force the aspect ratio of the Game View window to different values.  This will affect the positioning of any GUI Elements you have inside Unity, but not in your published game.  It can be used to test how your game will look in different aspect ratios.
</p>

<p>Furthest to the right on this Control Bar is the Gizmos button. This controls whether user-drawn <a class="wiki"  href="../ScriptReference/Gizmos.html">Gizmos</a> are shown in the game view.
</p>


<h2>Project View</h2>
<p><img class='figure' src='images/Learning the Interface-19.jpg' /><br>
<i>Project View &mdash; where all your asset files are stored</i>
</p>

<p>When you create a project, a group of folders is created.  One of these is called the Assets folder.  The <b>Project View </b> gives a look into the project's Assets folder.  If you were to open the Assets folder itself, you would find that all the items there can be seen inside the Project View.  The difference is that inside Project View, you will create and link objects together.  Those relationships are stored elsewhere in the group of project folders.  Moving assets from within the Project View will maintain and update the relationships between files.  Moving assets from within the Finder will break the relationships.  Therefore, you should only ever add files to the Assets folder in the Finder.  Any other actions with assets should be performed within Project View.
</p>

<h3>Importing Objects</h3>

<p>Once you have created an asset (3D model, image file, sound effect, or script), you can use the Finder to put the asset right into your project's Assets folder.  Unity can be open while do you do this.  As soon as you change focus back to Unity, the new asset will be detected and imported automatically.  You will now see your asset in the Project View.
</p>

<p>For more information about working with assets, skip ahead to the <a href="../Manual/Asset Workflow.html">Asset Workflow</a> page.
</p>

<h3>Creating Assets</h3>

<p>Use the Create button on the Control Bar to see a drop-down list of objects you can create.  Alternatively, you can Control-click or right-click inside the Project View window to see the same drop-down list.
</p>

<p><img class='figure' src='images/Learning the Interface-20.jpg' /><br>
<i>The Create drop-down list</i>
</p>

<h3>Organizing the Project View</h3>

<p>Use the Create drop-down to create folders in the Project View.  You can then rename and use folders just as you would in the Finder, and drag any asset in the Project View into the folder.  For example you could create a folder called <b>Scripts</b> and keep all your script files inside it.
</p>

<p>Whichever folder you have highlighted when you use the Create drop-down will contain the new object when it is created.  Use nested folders to keep your Project View neat and tidy.
</p>

<h3>Import Settings</h3>

<p>There is an <b>Import Settings</b> button on the Control Bar, next to the Create drop-down list.  Depending on the type of asset that is highlighted when the button is clicked, a different set of options will appear in the Import Settings pop-up window.  For more information about Import Settings, please read the page on <a href="../Manual/Importing Assets.html">Importing Assets</a>.
</p>

<h3>Project View Control Bar</h3>

<p>The Settings button will bring up the import settings for the asset you currently have selected.
</p>

<p>The Create drop-down selector will create the item you select within the directory you have selected.  Creating folders is a great and quick way to organize your Project View.
</p>


<h2>Hierarchy View</h2>
<p><img class='figure' src='images/Learning the Interface-21.jpg' /><br>
<i>Hierarchy View &mdash; All the objects currently in the scene</i>
</p>

<p>This view displays every Game Object that exists in the currently open .unity Scene file. It is used to select and group objects.  As objects are added and removed from the scene, they will appear and disappear from the Hierarchy view as well.  This way, if you cannot see all the objects at once in the Scene View, you can use the Hierarchy view to select and inspect them.
</p>

<h3>Object Hierarchies</h3>

<p>Unity uses a concept called <b>Parenting</b>.  Any Game Object can become the parent or child of any other Game Object.  A child will inherit the movement and rotation of its parent.  Parenting is very useful for organizing environments, characters, interface elements, or just to keep scenes tidy.  To make a Game Object the child of another, click and drag it onto the object you wish to become its parent, all in the Hierarchy View.  You will see a triangular arrow appear to the left of the new parent Game Object.  You can now expand and contract the parent to see its children in the Hierarchy View without affecting your game.
</p>

<h3>Show Prefab Button</h3>

<p>When this button on the Control Bar is enabled, any instance of a Prefab that is selected in the Hierarchy View will show a visual reference to its Prefab in the Project View.  This is especially useful if you change names of Prefab instances inside the scene.
</p>


<h2>Inspector View</h2>
<p><img class='figure' src='images/Learning the Interface-22.jpg' /><br>
<i>Inspector View &mdash; Details about settings for the selected object</i>
</p>

<p>The Inspector View is fondly referred to as "the Inspector".  The Inspector displays some basic information about your currently selected Game Object, as well as the Components it contains and their properties.  It is where you set up the functionality of the Game Objects in your scene.  When creating engaging gameplay, you'll do lots of trial and error tweaking with the Inspector.
</p>

<p><img class='figure' src='images/Learning the Interface-23.jpg' /><br>
<i>The Inspector shows information about the currently selected object and its settings.</i>
</p>

<p>Every Game Object contains a number of different <b>Components</b>.    When you are viewing a Game Object in the Inspector, each Component has its own mini title bar.  For example, every Game Object contains a Transform Component.  The settings and variables of every Component in the Game Object can be changed in the Inspector.
</p>

<h2>The Structure of Game Objects</h2>
<p>The Components inside the Game Object are what defines what the Game Object is and does.  Think of a new Game Object as an empty canvas, and each Component is a different shade of paint.  As you combine and set-up different Components, you are painting the behavior of your Game Object.  Certain Components, like certain colors, work very well together.  Others do not.
</p>

<p>Components can be added to your Game Objects by using the <b>Component</b> menu:
</p>

<p><img class='figure' src='images/Learning the Interface-24.jpg' />
</p>

<p>For a complete and detailed guide to Unity's Components, please use the <a class="wiki"  href="../Components/index.html">Component Reference</a>.
</p>

<p>Additionally, all the Components will display a tiny question mark beside their name in the Inspector.
</p>


<h2>Timeline View</h2>

<p>The Timeline View is used to create animations for the currently selected object.  Unity will import files containing animations, but you can use the Timeline View to make basic animations without a 3D animation application.
</p>

<p><img class='figure' src='images/Learning the Interface-25.jpg' /><br>
<i>Timeline View will help you make animations for your Game Object</i>
</p>

<p>For more information about using the Timeline View, please read the <a href="../Manual/Animation.html">Animation</a> page.
</p>

<h2>Adjusting the View Layout</h2>

<p>Now that you know about all the different Views, you can create your own arrangement of Views that fits your style of working.  Please look again at the Layout drop-down.
</p>

<p><img class='figure' src='images/Learning the Interface-26.jpg' /><br>
<i>The Layout drop-down lets you choose or save different View Layouts</i>
</p>

<p>Try choosing different Layouts to get an idea of what is possible.  Now, choose "New Layout" from the drop-down, and name it anything.
</p>

<p>To customize this Layout, you will need to <b>Split</b> and <b>Combine</b> Views.  To do this, control-click or right-click on any dividing line between Views, or on any View Control Bar.  When your mouse is over a dividing line, you can click and drag back and forth to change the sizes of the divided Views.  Experiment to find the way you like the interface.
</p>

<p><img class='figure' src='images/Learning the Interface-27.jpg' /><br>
<i>A completely custom Layout</i>
</p>

<p>You can toggle any View in and out of full-screen mode.  Hover the mouse over the Scene View and press the space bar. This maximizes the current View and hides all other views temporarily.  This allows you to see your view in more detail when you need the extra screen size.  To return to normal view, simply press the space bar again.  To do this on a Game view while in Play mode, you'll need to pause the game before pressing the space bar.
</p>



<p>Here we'll explain the steps to use a single asset with Unity.  These steps are general and are meant only as an overview for basic actions.  For the example, we'll talk about using a 3D mesh.
</p>

<h2>Create Rough Asset</h2>

<p>Use any supported 3D modeling package to create a rough version of your asset.  Our example will use Maya.  Work with the asset until you are ready to save.
</p>

<h2>Import</h2>

<p>When you save your asset initially, you should save it directly to the assets folder in your project folder.  Use the normal Save As dialog for Mac OS X.  When you open the Unity project, the asset will be detected and imported into the project.  When you look in the Project View, you'll see the asset located there.
</p>

<h2>Import Settings</h2>

<p>If you select the asset and click the Import Settings button, a dialog with different options for importing the asset will appear.  The options that are displayed will change based on the type of asset that is selected.
</p>

<h2>Adding Asset to the Scene</h2>

<p>Simply click and drag the mesh from the Project View to the Hierarchy or Scene Views to add it to the scene.  When you drag a mesh to the scene, you are creating a Game Object that has a Mesh Renderer Component.  If you are working with a texture or a sound file, you will have to add it to a Game Object that is already in the scene.
</p>

<h2>Putting Different Assets Together</h2>

<p>Here is a brief description of the relationships between the most common assets
</p>

<ul><li> A Texture is applied to a Material
</li><li> A Material is applied to a Game Object (with a Mesh Renderer Component)
</li><li> An Animation is applied to a Game Object (with an Animation Component)
</li><li> A Sound file is applied to a Game Object (with an Audio Source Component)
</li></ul>

<h2>Creating a Prefab</h2>

<p>Prefabs are a collection of Game Objects &amp; Components that can be re-used in your scenes.  Several identical objects can be created from a single Prefab, called <b>cloning</b> or <b>instancing</b>.  Take trees for example.  Creating a tree Prefab will allow you to clone several identical trees and place them in your scene.  Because the trees are all linked to the Prefab, any changes that are made to the Prefab will automatically be applied to all other trees.  So if you want to change the mesh, material, or anything else, you just make the change once in the Prefab and all the other trees inherit the change.  This can save you lots of time during setup and updating of assets.
</p>

<p>When you have a Game Object that contains multiple Components and a hierarchy of other Game Objects, you can make a Prefab of the top-most Game Object, and re-use the entire collection of Components &amp; Game Objects as Prefab clones.
</p>

<p>Think of a Prefab as a blueprint for a structure of GameObjects.  All the Prefab clones are identical to the blueprint.  Therefore, if the blueprint is updated, so are all the clones.  There are different ways you can update the Prefab itself by changing one of its clones and applying those changes to the blueprint.  To read more about using and updating Prefabs, please view the <a href="../Manual/Prefabs.html">Prefabs</a> page.
</p>

<p>To actually create a Prefab from a Game Object in your scene, first create a new Prefab in your Project View.  Name the new Prefab whatever you like.  Then, click on the Game Object in the scene that you want to make into a Prefab.  Drag it to the new Prefab, and you should see the Game Object's name text turn blue.  You have now created a re-usable prefab.
</p>

<h2>Updating Assets</h2>

<p>You have imported, instantiated, and linked your asset to a Prefab.  Now when you want to update your asset, just double-click it from the Project View.  The appropriate application will launch, and you can make any changes you want.  When you're done updating it, just Save it.  Then, when you switch back to Unity, the update will be detected, and the asset will be re-imported.  The asset's link to the Prefab will also be maintained.  So the effect you will see is that your Prefab will update.  That's all you have to know to update assets.  Just open it and save!
</p>



<p>Scenes are the heart of your game.  They can be used to create menus, levels, and everything else.  Different Scenes can be different levels, different areas, or different sub-games.  In each Scene, you will place your environments, obstacles, and decorations, essentially designing and building your game in pieces.
</p>

<h2>Instancing Prefabs</h2>

<p>Use the method described in the last section to create Prefabs.  You can also read more details about Prefabs <a href="../Manual/Prefabs.html">here</a>.  Once you've created a prefab, you can quickly and easily make copies of the Prefab, called an <b>Instance</b>.  To create an instance of any prefab, drag the prefab from the Project View to the Hierarchy or Scene View. Now you have a unique instance of your prefab to position and tweak as you like.
</p>

<h2>Adding Component &amp; Scripts</h2>

<p>When you have a Prefab or any Game Object highlighted, you can add additional functionality to it with Components.  Please view the <a class="wiki"  href="../Components/index.html">Component Reference</a> for details about all the different Components.  Scripts are a type of Component.  To add a Component, just highlight your Game Object and select a Component from the Component Menu.  You will then see the Component appear in the Game Object's inspector.  Scripts are contained in the Component Menu by default.
</p>

<p>If adding a Component breaks the Game Object's connection to its Prefab, you can always use <b>GameObject -&gt; Upload Changes to Prefab</b> from the menu to re-establish the link.
</p>

<h2>Placing Game Objects</h2>

<p>Once your Game Object is in the scene, you can use the View Tools to position it wherever you like.  Additionally, you can use the Transform values in the Inspector to fine-tune placement and rotation.  Please view the <a href="../Components/class-Transform.html">Transform Component page</a> for more information about positioning and rotating Game Objects.
</p>

<h2>Working with Cameras</h2>

<p>Cameras are the eyeballs of your game.  Everything the player will see when playing is through one or more cameras.  You can position, rotate, and parent cameras just like any other Game Object.  In fact a camera is just a Game Object with a Camera component attached to it.  There are also some helpful camera scripts that are installed with the standard assets package when you create a new project.  You can find them in <b>Components -&gt; Camera-Control</b> from the menu.  There are some additional aspects to cameras which will be good to understand.  To read about cameras, view the <a href="../Components/class-Camera.html">Camera component page</a>.
</p>

<h2>Lights</h2>

<p>Except for some very few cases, you will always need to add Lights to your scene.  There are three different types of lights, and all of them behave a little differently from each other.  The important thing is that they add atmosphere and ambience to your game.  Different lighting can completely change the mood of your game, and using lights effectively will be an important subject to learn.  To read about the different lights, please view the <a href="../Components/class-Light.html">Light component page</a>.
</p>



<p>At any time while you are building your game, you might want to see how it looks when you build and run it outside of the editor as a real game.  This section will explain how to access the Build Settings and how to create different builds of your games.
</p>

<p><b>File -> Build Settings...</b> is the menu item to access the build Build Settings window.  It pops up an editable list of the scenes in your soon-to-be-built game.  Using this list, you add and rearrange any <b>.unity</b> scene files that will be included in the game build.
</p>

<p><img class='figure' src='images/Publishing Builds-0.jpg' />
</p>

<p><i>The Build Settings window</i>
</p>

<p>Don't panic if your scene list is blank.  It is easy to add scene files to the list.  There are two ways to add them.  The first way is to click the <b>Add Open Scene</b> button.  You will see the current scene appear in the list.  The second way to add scene files is to click &amp; drag them from the Project View to the list.
</p>

<p>At this point, notice that each of your scenes has a different index value.  Scene 0 is the first scene that will be loaded when you build the game.  When you want to load a new scene, use <a class="wiki"  href="../ScriptReference/Application.LoadLevel.html">Application.LoadLevel()</a> inside your scripts.
</p>

<p>If you've added more than one scene file and want to rearrange them, simply click and drag the scenes on the list above or below others until you have them all in the right order.
</p>

<p>If you want to remove a scene from the list, click to highlight the scene and press <b>Command-Delete</b>.  The scene will disappear from the list.
</p>

<p>When you are ready to publish your build, select a build target platform and press the Build button. You will be able to select a name and location for the game. When you click Save, Unity builds your game pronto.  It's that simple.
</p>

<p>If you want to quickly build a test player with only one scene file, you can build a player with a blank scene list. In this case, Unity just includes the scene that is currently open.
</p>

<p>Enabling the <b>Compress Textures</b> checkbox will compress all the textures in your project when it is built.  You only need to compress a texture once, but the first time you perform the compression it could take a few minutes.  When you update assets after compressing them, they will need to be re-compressed next time you build a player.  Alternatively, you can enable texture compression upon import from the <b>Unity -> Preferences</b> menu.
</p>

<p>Enabling the <b>Strip Debug Symbols</b> checkbox will remove debugging information from the built player.  This will reduce the filesize.  For any future build, you can re-enable this if you need to.  Your final release should always have this checkbox enabled.
</p>

<h2> Inside the process</h2>

<p><b>Note:</b> this is not necessary to read, but could be helpful to understand. The building process will place a blank copy of the built game application wherever you specify. Then it will work through the scene list in the build settings, open them in the editor one at a time, optimize them, and integrate them into the application package. It will also calculate all the assets that are required by the included scenes and stores that data in a seperate file within the application package.
</p>

<ul><li>Any game object in a scene that is tagged with 'EditorOnly' will be not be included in the published build. This is useful for debugging scripts that you don't want to include in the final game.
</li></ul>

<ul><li>When a new level loads, all the objects in the previous level are destroyed. To prevent this, use <a class="wiki"  href="../ScriptReference/Object.DontDestroyOnLoad.html">DontDestroyOnLoad()</a> on any objects you don't want destroyed.  This is most commonly used to keeping music playing while loading a level, or for game controller scripts which keep game state and progress.
</li></ul>

<ul><li>After the loading of a new level is finished, the message: <a class="wiki"  href="../ScriptReference/MonoBehaviour.OnLevelWasLoaded.html">OnLevelWasLoaded()</a> will be sent to all active game objects.
</li></ul>

<ul><li>For more information on how to best create a game with multiple scenes, for instance a main menu, a high-score screen, or actual game levels, see the Scripting Tutorial.pdf
</li></ul>

<h2>Preloading</h2>

<p>Published builds automatically preload all assets in a scene when the scene loads.  The exception to this rule is scene 0. This is because the first scene is usually a splashscreen, which you want to display as quickly as possible.
</p>

<p>To make sure all your content is preloaded, you can create an empty scene which calls Application.LoadLevel(1). In the build settings make this empty scene's index 0. All subsequent levels will be preloaded.
</p>

<h2>You're ready to build games</h2>

<p>By now, you have learned how to use Unity's interface, how to use assets, how to create scenes, and how to publish your builds.  There is nothing stopping you from creating the game of your dreams.  You'll probably learn lots more along the way, and we're here to help.
</p>

<p>To learn more details about using Unity itself, you can <a href="../Manual/Building Scenes.html">continue reading the manual</a> or follow the <a href="../Manual/Tutorials.html">Tutorials</a>.
</p>

<p>To learn more about Components, the nuts &amp; bolts of game behaviors, please read the <a class="wiki"  href="../Components/index.html">Component Reference</a>.
</p>

<p>To learn more about Scripting, please read the <a class="wiki"  href="../ScriptReference/index.html">Scripting Reference</a>.
</p>

<p>To learn more about creating Art assets, please read the <a href="../Manual/Working with Assets.html">Assets section</a> of the manual.
</p>

<p>To interact with the community of Unity users and developers, visit the <a class="wiki"  href="http://forum.unity3d.com">Unity Forums</a>.  You can ask questions, share projects, build a team, anything you want to do.  Definitely visit the forums at least once, because we want to see the amazing games that you make.
</p>



<p>These tutorials will let you work with Unity while you follow along.  They will give you hands-on experience with building real projects.  For new users, it is recommended that you follow the GUI Essentials and Scripting tutorials first.  After that, you can follow any of them.  They are all in PDF format, so you can print them out and follow along or read them alongside Unity.
</p>

<p><a class="wiki"  href="../../Tutorials/1%20-%20GUI%20Essentials.pdf"><img class='figure' src='images/Tutorials-0.jpg' /></a>
<a class="wiki"  href="../../Tutorials/2%20-%20Scripting%20Tutorial.pdf"><img class='figure' src='images/Tutorials-1.jpg' /></a>
<a class="wiki"  href="../../Tutorials/Marble%20Tutorial.pdf"><img class='figure' src='images/Tutorials-2.jpg' /></a>
<a class="wiki"  href="../../Tutorials/Racing%20Tutorial.pdf"><img class='figure' src='images/Tutorials-3.jpg' /></a>
<a class="wiki"  href="../../Tutorials/FPS%20Tutorial%20-%201.pdf"><img class='figure' src='images/Tutorials-4.jpg' /></a>
<a class="wiki"  href="../../Tutorials/FPS%20Tutorial%20-%202.pdf"></a>
<a class="wiki"  href="../../Tutorials/FPS%20Tutorial%20-%203.pdf"><img class='figure' src='images/Tutorials-6.jpg' /></a>
</p>



<p>This section will explain the core elements you will work with to build scenes for complete games.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/GameObjects.html">GameObjects</a></li><li class="toclevel"><a href="../Manual/Using Components.html">Using Components</a></li><li class="toclevel"><a href="../Manual/Prefabs.html">Prefabs</a></li><li class="toclevel"><a href="../Manual/Lights.html">Lights</a></li><li class="toclevel"><a href="../Manual/Cameras.html">Cameras</a></li><li class="toclevel"><a href="../Manual/Particle Systems.html">Particle Systems</a></li></ul>
</p>



<p>Game Objects are the most important concept in Unity.  Every object in your game will be a Game Object.  Game Objects can have different parts that make them up, called <b>Components</b>.  Game Objects can also be attached to each other using the <b>Parenting</b> concept. By using Components, Parenting, and scripting, you will create structures of Game Objects that contain your game mechanics.  They are the building blocks of your game.
</p>

<h2>Transform</h2>

<p>The one Component that every Game Object will always contain is the <b>Transform</b> Component.  Transforms give the Game Object a position, rotation, and scale within the scenes of your game.  It is impossible to create a Game Object without a Transform, and impossible to remove the Transform from any Game Object.  Whenever you move or rotate a Game Object in the Scene View, Inspector, or via scripting, you are altering its Transform Component, and not the Game Object itself.  Transform values are relative to the <b>World Coordinates</b> by default.  For more information about the Transform Component, please read the <a href="../Components/class-Transform.html">Transform Component page</a> in the Component Reference.
</p>

<h2>Parenting</h2>

<p>Unity makes use of a concept called <b>Parenting</b>.  The basic idea is that you can make one Game Object "contain" another.  You can create a Parent by dragging any Game Object in the Hierarchy View onto another.  This will create a Parent-Child relationship between the two Game Objects.  Think of the Game Object as a folder, and when you drop another onto it, the dropped Game Object becomes the Child that is contained within the Parent.  When you do this, the Child's Transform values in the Inspector are displayed as relative to the Parent's Transform values, or <b>Local Coordinates</b>.
</p>

<p>A Game Object can have any number of Children, but only one Parent.  Children can also be Parents of other Game Objects.  You can quickly tell if a Game Object is a Parent by looking at its name in the Inspector.  If it has an arrow to the left of its name, it is a Parent.
</p>

<p><img class='figure' src='images/GameObjects-0.jpg' /><br>
<i>A real-world example of a Parent-Child hierarchy</i>
</p>


<h2>Components</h2>

<p>Game Objects can be customized and made functional through the use of <b>Components</b>.  Think of a Game Object as an empty cooking pot, and Components as different ingredients that make up your recipe of gameplay.  Usually, multiple Components work together in a Game Object.  For example, a Particle System uses a Particle Emitter, a Particle Animator, and a Particle Renderer.  You can add Empty Game Objects to your scene, add Components one-by-one, then make your Game Object into a Prefab.  You can then use the Prefabs to make multiple copies of your Game Object, and adjust individual Component properties in each copy.  This gives you the most flexibility for creating Game Objects with a variety of attributes.
</p>

<p>It would be a good idea to learn how to add, edit, and removed Components individually.  The next page will discuss Components in-depth.
</p>

<p>For a detailed list of all Components in Unity, please view the complete <a class="wiki"  href="../Components/index.html">Component Reference</a>.
</p>



<p><b>Components</b> are the nuts &amp; bolts of objects and behaviors in a game.  A Game Object is a container for one or many Components.  To use Components, you select a Game Object and use the <i>Components</i> menu.  Any Component you select from this menu will be added to the selected Game Object.  You can add Components to Game Objects in Hierarchy View, or Prefabs in the Project View.
</p>

<p>By default, all Game Objects automatically have a <b>Transform Component</b>.  This is because the Transform dictates where the Game Object is located, and how it is rotated and scaled.  Without a Transform Component, the Game Object would essentially not exist in the world.  Therefore each must have one.
</p>

<p><img class='figure' src='images/Using Components-0.jpg' /><br>
<i>An empty Game Object</i>
</p>

<p>You can always see which Components are attached to the selected Game Object in the Inspector.  As you add, remove, and change Components, the Inspector will update to show you the current Components in the Game Object.  You can click on the Component header in the Inspector to expand or contract the properties of the Component.
</p>

<h2>Adding Components</h2>

<p>We will add a Rigidbody Component to an empty Game Object.  You can follow along if you like.  Use <b>GameObject -> Create Empty</b> to create a new Game Object.  With the empty Game Object selected, use <b>Component -> Physics -> Rigidbody</b> to add a Rigidbody Component.
</p>

<p><img class='figure' src='images/Using Components-1.jpg' /><br>
<i>The same Game Object with a Rigidbody attached</i>
</p>

<p>You can attach any number or combination of Components to a single Game Object.  Any script you write is also a Component.  You should be aware that some Components require others to work properly.  For example, any Joint Component requires a Rigidbody to be attached as well.  In this case, adding a Joint will automatically add a Rigidbody if one does not already exist.  Another example; Particle Systems use a Particle Emitter, Particle Animator, and Particle Renderer.  Adding one will not add all three.
</p>

<p>If you want to know more about using a particular Component, you can read about any of them in the <a class="wiki"  href="../Components/index.html">Component Reference</a>.  You can also access the reference page for a Component from Unity by clicking on the small <b>?</b> on the header of the Component in the Inspector.
</p>


<h2>Editing Components</h2>

<p>One of the great aspects of Components is flexibility.  When you attach a Component to a Game Object, there are different values or <b>Properties</b> in the Component that can be adjusted in the editor while building a game, or by scripts when running the game.  There are two main types of Properties: <b>Values</b> and <b>References</b>.
</p>

<p>Please take a look at the image below.  It is an empty Game Object with an Audio Source Component attached.  All the values of the Audio Source in the Inspector are the default values.
</p>

<p><img class='figure' src='images/Using Components-2.jpg' />
</p>

<p>This Component contains a single Reference property, and seven Value properties.  When this Audio Source begins playing, it will attempt to play the audio file that is referenced in the <b>Audio Clip</b> property.  If no reference is made, the Component will attempt to play a non-existent file, and an error will occur.  Before the Audio Source can play, you must reference the correct type of file within the Inspector.  This is as easy as dragging an audio file from the Project View onto the Reference Property.
</p>

<p><img class='figure' src='images/Using Components-3.jpg' /><br>
<i>Now a sound effect file is referenced in the <b>Audio Clip</b> property</i>
</p>

<p>Components can include references to any other type of Component, file, or Game Object.  For any of these, you just need to drag &amp; drop the appropriate reference to the property.  This type of referencing is very quick and powerful, especially when using scripting.  To learn more about using scripts and properties, please view the Scripting Tutorial on the <a href="../Manual/Tutorials.html">Tutorials</a> page.
</p>

<p>The seven remaining properties on the Audio Clip are all Value properties.  These can all be adjusted simply by clicking on them and pressing the Enter key.  You can then enter any value you like using the keyboard, and press Enter to save the value.
</p>

<ul><li>You can also option- or right-click and drag on numeric properties to scroll values quickly
</li></ul>

<p>The Value properties on the Audio Clip are all numeric, but some properties can be strings as well.  For example, the GUI Text Component contains a <b>Text</b> property, which accepts alphanumeric characters.
</p>

<p><img class='figure' src='images/Using Components-4.jpg' /><br>
<i>Some values can contain text, like the <b>Text</b> property in the GUI Text Component</i>
</p>

<h3>Testing out Properties</h3>

<p>While your game is in Play Mode, you are free to change properties in any Game Object's Inspector.  For example, you might want to experiment with different heights of jumping.  If you set a Jump Height property in a script, you can enter Play Mode, change the value, and press the jump button to see what happens.  Then without exiting Play Mode you can change it again and see the results within seconds.  When you exit Play Mode, your properties will revert to their pre-Play Mode values, so you don't lose any work.  This workflow gives you incredible power to experiment, adjust, and refine your gameplay without investing a lot of time in iteration cycles.  Try it out with any property in Play Mode.  We think you'll be impressed.
</p>

<h2>Removing Components</h2>

<p>If you want to remove a Component, option- or right-click on its header in the Inspector, and choose <b>Remove Component</b>.  All the property values will be lost and this cannot be undone, so be completely sure you want to remove the Component before you do.
</p>


<p>A Prefab is a reusable Game Object that is stored in the Project View. Prefabs can be inserted into any number of scenes, multiple times per scene.  When you add a Prefab to a scene, you create an <b>instance</b> of it.  All Prefab instances are linked to the original Prefab and are essentially clones of it.
</p>

<p>No matter how many instances exist in your project, when you make any changes to the Prefab you will see the change applied to all instances.  Whether your Prefab is a single Game Object or a group of Game Objects, a change made anywhere in the Prefab's Hierarchy will always be applied to its instances.
</p>

<h2>Creating Prefabs</h2>
<p>In order to create a Prefab, you must make a new, blank Prefab using the menu.  This blank Prefab contains no Game Objects, and you cannot create an instance of it.  Think of a new Prefab as an empty container, waiting to be filled with Game Object data.
</p>

<p><img class='figure' src='images/Prefabs-0.jpg' /><br>
<i>A new, empty Prefab.  It cannot be instanced until you fill it with a Game Object.</i>
</p>

<p>It's easy to fill the Prefab with an existing Game Object.  You use a Game Object that you've built in Hierarchy View.  Here are the precise steps for creating a new Prefab:
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> In Project View, select the folder you want to contain the Prefab.
</li><li> Choose <b>Assets -> Create -> Prefab</b> from the main menu, or <i>Create --> Prefab</i> from the Project View context menu.
</li><li> Name your Prefab using the keyboard.
</li><li> In Hierarchy View, select the Game Object you wish to make into a Prefab.
</li><li> Drag &amp; Drop the Game Object onto the Prefab in Project View.
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>After you have performed these steps, the Game Object and any children it contains have become the first instance of the Prefab.  From here, creating multiple instances of the Prefab is simple.
</p>

<h2>Instantiating Prefabs</h2>
<p>To create a Prefab instance in the current scene, Drag the Prefab from the Project View into the Scene or Hierarchy View. This will copy the top-level Game Object and any child Game Objects from the Prefab to the scene. These Game Objects are <b>linked</b> to the Prefab, as displayed by the blue text used for their name in the Project View.
</p>

<p><img class='figure' src='images/Prefabs-1.jpg' /><br>
<i>Three of these Game Objects are linked to Prefabs.  One of them is not.</i>
</p>

<p>More information about instantiating prefabs from your game scripts is in <a href="../Manual/Instantiating Prefabs.html">Instantiating Prefabs</a> page.
</p>

<h2>Inheritance</h2>
<p>Inheritance means that whenever the Prefab changes, those changes are applied to all linked Game Objects.  For example, if you add a new script to a Prefab, all of the linked Game Objects will now contain the script as well.  However, it is possible to change the properties of a Prefab instance while keeping the link intact.  All public properties in the Inspector of a linked Game Object will have a checkbox.  This checkbox is the <b>Override Flag</b>. If the override flag of any property is enabled, that property will not be affected by changes in the Prefab.
</p>

<p>Stated simply, this allows you to modify linked Game Objects to make them unique from their Prefabs, without breaking the Prefab link.
</p>

<p><img class='figure' src='images/Prefabs-2.jpg' /><br>
<i>A linked Game Object with no overrides enabled.</i>
</p>

<p><img class='figure' src='images/Prefabs-3.jpg' /><br>
<i>A linked Game Object with one override enabled.</i>
</p>

<p>A property's override flag is automatically enabled when you change it in the Inspector.
</p>

<p>There are certain types of changes that will break the link between a Game Object and its Prefab. These are the basic rules for keeping a Prefab link:
</p>

<ul><li> You cannot add a new Component to a linked Game Object
</li><li> You cannot remove a Component from a linked Game Object
</li><li> You cannot attach other Game Objects as children to a linked Game Object
</li></ul>

<p>If you perform any of these actions, you will see a warning message telling you that the Prefab link will be broken if you continue.  When a Game Object's link to a Prefab has been broken, changes to the Prefab will no longer affect that particular Game Object.
</p>

<p>If you want to make a change to all Prefab instances that requires an action which will break the link, you can reconnect the changed Game Object to its original Prefab.  This will cause the Prefab to adopt the changes and all linked Game Objects to that Prefab will also be changed.
</p>


<h2>Uploading Changes</h2>
<p>When creating or editing complex Prefabs, it is easier to instantiate them in the scene, edit the instance, and upload the changes to the Prefab itself.  This workflow will allow you to view and tweak the Prefab in Scene View. Once you're done with your edits, select the root of the linked instance Game Object and choose <b>Game Object -> Upload changes to Prefab</b> from the main menu. All of the changes are then copied back to the Prefab, and applied to all other inheriting objects in the scenes.
</p>

<p>Alternatively, you can use drag &amp; drop to upload your changes. Drag the instanced Game Object back to the Prefab it came from.  It is important that you change and upload a linked instance and not a random Game Object that is unrelated to the Prefab. If you do, all other linked instances will have their Components and properties overriden.
</p>

<p>Uploading changes using drag &amp; drop can cause unwanted data loss if you drop a different Game Object onto the Prefab.  Using the <b>Upload Changes to Prefab</b> menu option is safer, as it will only work when the selected Game Object is a linked instance. If you drag &amp; drop a different Game Object onto the Prefab, a confirmation pop-up will appear, verifying that you want to change a Prefab.  If you click yes, the data that existed in your Prefab and its linked instances will be replaced.  This operation cannot be undone so please be sure that you want to make a replacement, or always use <b>Upload Changes to Prefab</b> to play it safe.
</p>


<h2>Connecting Game Objects to Prefabs</h2>
<p>It is possible to apply a Prefab to an existing, unlinked Game Object.  This will add any of the Prefab's components that aren't contained in the Game Object and link it to the Prefab.  This is most useful in specialized cases.  To connect an existing Game Object to a Prefab, hold <b>Alt</b> and drag the Prefab from the Project View onto the Game Object in the Hierarchy View.  The Game Object will now be a linked instance of the Prefab.  This action will not change the Prefab itself, but will add or remove Components &amp; child Game Objects to or from the Game Object you've linked.
</p>


<h2>Importing Prefabs</h2>
<p>When you place a mesh asset into your Assets folder, Unity automatically imports the file and generates a prefab out of the mesh.  This Prefab is a little bit different from regular Prefabs, because it is built from the asset file itself.  Because the Prefab is dependent on the asset file itself, whenever you make changes to the asset in your 3d art package, all changes will be reflected in all instantiated prefabs.
</p>

<p>You are free to instantiate an asset Prefab and alter the instance, but you will not be able to upload changes to the Prefab.  This is because uploading the data would alter the asset file itself.  When you have altered an asset instance to your liking, create a new empty Prefab and drag the Game Object to it.  Now you have a standard Prefab linked to the Game Object and can upload changes normally.
</p>

<p>Here are some clear steps:
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Drag the asset Prefab generated from the Project View into the Scene or Hierarchy View.
</li><li> Modify it to your liking.  E.g. add scripts, child objects, components etc.
</li><li> Create a new empty prefab. Choose <b>Assets -> Create -> Prefab</b> from the main menu, or <b>Create -> Prefab</b> from the Project View context menu.
</li><li> Drag the Game Object from the Hierarchy View to the Prefab.
</li></ol>

<p></div></div></td></tr></table>
</p>



<p>Lights are an essential part of every scene.  While meshes and textures define the shape and look of a scene, lights define the mood and color themes.  You'll likely work with more than one light in each scene.  Making them work together requires a little practice but the results can be quite amazing.
</p>

<p><img class='figure' src='images/Lights-0.jpg' /><br>
<i>A simple, two-light setup</i>
</p>

<p>Lights can be added to your scene from the <b>GameObject -> Create Other</b> menu.  There are three types of lights which we'll discuss in a moment.  One a light has been added, you can manipulate it like any other Game Object.  Additionally, you can add a Light Component to the selected Game Object by using <i>Component->Rendering->Light</i>.
</p>

<p>There are many different options within the Light Component in the Inspector.
</p>

<p><img class='figure' src='images/Lights-1.jpg' /><br>
<i>Light Component properties in the Inspector</i>
</p>

<p>Simply by changing the <b>Color</b> of a light, you can give a whole different mood to the scene.
</p>

<p><img class='figure' src='images/Lights-2.jpg' /><br>
<i>Bright, sunny lights</i>
</p>

<p><img class='figure' src='images/Lights-3.jpg' /><br>
<i>Dark, medieval lights</i>
</p>

<p><img class='figure' src='images/Lights-4.jpg' /><br>
<i>Spooky night lights</i>
</p>


<h2>Using Lights</h2>

<h1>Light</h1>

<p>Lights will bring personality and flavor to your game. You use lights to illuminate the scenes and objects to create the perfect visual mood. Lights can be used to simulate the sun, match light, flashlights, gun-fire, or explosions, just to name a few.
</p>

<p><img class='figure' src='images/Lights-5.jpg' />
</p>

<p><i>The Light Component</i>
</p>

<p>There are three types of lights in Unity:
</p>
<ul><li> <i>Point lights</i> shine from a location equally in all directions, like a light bulb.
</li><li> <i>Directional lights</i> are placed infinitely far away and affect everything in the scene, like the sun.
</li><li> <i>Spot lights</i> shine from a point in a direction and only illuminate objects within a cone - like the headlights of a car.
</li></ul>

<p><img class='figure' src='images/Lights-6.jpg' />
</p>

<p><i>The three different light types in Unity</i>
</p>

<h2>Properties</h2>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>Type</nobr></b></td><td> The current type of light object
<dl><dt>Directional</dt><dd> A light placed infinitely far away. It affects everything in the scene and can not attenuate.</dd><dt>Point</dt><dd> A light that shines equally in all directions from its location, affecting all objects within its <b>Range</b>.</dd><dt>Spot</dt><dd> A light that shines everywhere within a cone (<b>Spot Angle</b>), and a <b>Range</b>. Only objects within this region are affected by the light.</dd></dl>
</td></tr><tr><td><b><nobr>Color</nobr></b></td><td> The color of the light emitted
</td></tr><tr><td><b><nobr>Attenuate</nobr></b></td><td> Does the light diminish with increasing distance? If disabled, objects' brightness will &quot;pop&quot; as they enter and exit the light's region of influence. It can be useful to turn off when you want to do some special effects. If the light is directional, this property is ignored.
</td></tr><tr><td><b><nobr>Range</nobr></b></td><td> How far light is emitted from the center of the object.
</td></tr><tr><td><b><nobr>Spot Angle</nobr></b></td><td> If the light is a Spot light, this determines the angle of the cone in degrees.
</td></tr><tr><td><b><nobr>Cookie</nobr></b></td><td> You can assign a texture to a light. The alpha channel of this texture is used as a mask that determines how bright the light is at different places. If the light is a <b>Spot</b> or a <b>Directional</b> light, this must be a 2D texture. If the light is a <b>Point</b> light, it must be a cubemap.
</td></tr><tr><td><b><nobr>Draw Halo</nobr></b></td><td> If checked, a spherical halo of light will be drawn with a radius equal to <b>Range</b>.
</td></tr><tr><td><b><nobr>Flare</nobr></b></td><td> Optional reference to the <a href="../Components/class-Flare.html">Flare</a> that will be rendered at the light's position.
</td></tr><tr><td><b><nobr>Render Mode</nobr></b></td><td> Choose whether this light is rendered as a vertex light, pixel light, or determined automatically. For a detailed description of this tradoff, see <i>Performance Considerations</i> below. Options include
<dl><dt>Auto</dt><dd> The rendering method is determined at runtime depending on the brightness of nearby lights and current <a href="../Components/class-QualitySettings.html">QualitySettings</a>.</dd><dt>Force Pixel</dt><dd> This light is always rendered at per-pixel quality. Use this for very important effects only (e.g. headlights of a player's car).</dd><dt>Force Vertex</dt><dd> This light is always rendered as a vertex-lit light.</dd></dl>
</td></tr><tr><td><b><nobr> Culling Mask</nobr></b></td><td> Use to selectively exclude groups of objects from being affected by the light; see <a href="../ScriptingConcepts/Layers.html">Layers</a>.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>There are three basic light types in Unity. Each type can be customized to fit your needs.
</p>

<p>You can use a texture that contains an alpha channel and assign it to be projected from any of the light types. This texture then becomes the cookie. The cookie's alpha mask modulates the light amount, creating light and dark spots on surfaces. They are a great way af adding lots of complexity to a scene, and hence providing a lot of atmosphere.
</p>

<p>All builtin shaders in Unity seamlessly work with any type of light (<i>VertexLit</i> type shaders ignore light cookies though).
</p>

<h3>Point Lights</h3>

<p><img class='figure' src='images/Lights-7.jpg' />
</p>

<p>Point lights shine out from a point in all directions. They are the most common lights in computer games - typically used for explosions, light bulbs, etc.  They have an average cost on the graphics processor.
</p>

<p>Point light cookies must be cubemaps with an alpha channel. This cubemap gets projected out in all directions.
</p>


<p><img class='figure' src='images/Lights-8.jpg' />
</p>


<h3>Spot Lights</h3>

<p><img class='figure' src='images/Lights-9.jpg' />
</p>

<p>Spot lights only shine in one direction, in a cone.  They are Perfect for flashlights or car headlights.  They cost the most expensive on the graphics processor.
</p>

<p>The cookie is projected down the cone of the spot light. This is good for creating an effect of light shining through a window. It is very important that the texture is black at the edges and its wrapping mode is set to <i>clamp</i>. For more info on this, see Texture
		print STDERR "WARN: nonexistent page href="tiki-editpage.php?page=class-FileTexture" , removing link
";
	
</p>


<h3>Directional Lights</h3>
<p>Directional lights are used mainly in outdoor scenes for sun &amp; moonlight.  The light affect all surfaces of objects in your scene.  They are the least expensive on the graphics processor.
</p>

<p><img class='figure' src='images/Lights-10.jpg' />
</p>

<p>With a directional light, the cookie is projected down the center of the light's Z axis. If you want to stretch it out over a large area, set the texture's wrapping mode to 'repeat' (select the texture in the project window, and in the Inspector for the texture instead of 'Clamp' select 'Repeat').
</p>

<p><img class='figure' src='images/Lights-11.jpg' />
</p>

<p>The above is a great way to add some quick detail to large outdoor scenes. You can even slide the light slowly over the scene to give the impression of moving clouds.
</p>


<h2>Performance considerations</h2>
<p>Lights can be rendered in one of two methods: vertex lighting and per-pixel lighting. Vertex lighting only calculates the lighting at the vertices of the game models, and interpolates the lighting over the surfaces of the models. Per-pixel lights are calculated at every screen pixel, and hence are much more expensive.  Some older graphics cards only support vertex lighting.
</p>

<p><img class='figure' src='images/Lights-12.jpg' />
</p>

<p>Lights have a big impact on rendering speed - therefore a tradeoff has to be made betwen lighting quality and game speed. Since per-pixel lights are much more expensive than per-vertex lights, Unity will only render the brightest lights at per-pixel quality. The actual number of pixel lights can be set as in the <a href="../Components/class-QualitySettings.html">Quality Settings</a>.
</p>

<p>You can explicitly control if a light should be rendered as a vertex or pixel light using the <b>Render Mode</b> setting of the light. By default Unity will classify the light automatically based on how much the object is affected by the light.
</p>

<p>The actual lights that are rendered as pixel lights are determined on an object-by-object case. This means:
</p>
<ul><li> Huge objects with bright lights could use all the pixel lights (depending on the quality settings). If the player is far from these, nearby lights will be rendered as vertex lights.  Therefore, it is better to split huge objects up in a couple of small ones.
</li></ul>

<p>See <a href="../Manual/Optimizing Graphics Performance.html">here</a> for more information about optimizing rendering performance.
</p>

<h2>Creating Cookies</h2>

<p>For more information on creating cookies, please see the tutorial on how to create a Spot Light cookie <a href="../Manual/HOWTO-LightCookie.html">here</a>.
</p>

<h2>Hints</h2>
<p><ul><li>
Spotlights with textures can be extremely effective for making light coming in from windows. In this case, disable attenuation, and set the range to just reach the floor.
</li><li>Low-intensity point lights are good for providing depth to a scene.
</li><li>Put a light near a particle system and assign a 'lighted' shader from the Particles group to its material. This works really well with projection textures.
</li><li>For high performance, use the <i>Vertex Lit</i> shader. This shader only does per-vertex lighting, giving a much higher throughput on low-end cards.
</li></ul>
</p>




<p>Just as cameras are used in films to display the story to the audience, cameras in Unity are used to display the game world to the player.  You will always have at least one camera in each scene, but you can have more than one.  Multiple cameras can give you a two-player splitscreen or create advanced custom effects.  You can animate cameras, or control them with physics.  Practically anything you can imagine is possible with Cameras, and you can use typical or unique cameras to fit your game's style.
</p>

<p>The remaining text is from the <a href="../Components/class-Camera.html">Camera Component reference</a> page.
</p>

<h1>Camera</h1>

<p>Cameras are the devices that capture and display the world to the player.  By customizing and manipulating cameras, you can make the presentation of your game truly unique.  You can have an unlimited number of cameras in a scene. They can be set to render in any order, at any place on the screen, or only certain parts of the screen.
</p>

<p><img class='figure' src='images/Cameras-0.jpg' />
</p>

<p><i>Unity's flexible Camera object</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Clear Flags</nobr></b></td><td> Determines which parts of the screen will be cleared.  This is handy when using multiple Cameras to draw different game elements.
</td></tr><tr><td><b><nobr>Background color</nobr></b></td><td> Color applied to the remaining screen after all elements in view have been drawn and there is no skybox.
</td></tr><tr><td><b><nobr>Normalized View Port Rect</nobr></b></td><td> Four values that indicate where on the screen this camera view will be drawn, in Screen Coordinates.
</td></tr><tr><td><b><nobr>    Xmin</nobr></b></td><td>The beginning horizontal position that the camera view will be drawn.
</td></tr><tr><td><b><nobr>    Ymin</nobr></b></td><td>The beginning vertical position that the camera view will be drawn.
</td></tr><tr><td><b><nobr>    Xmax</nobr></b></td><td>The ending horizontal position that the camera view will be drawn.
</td></tr><tr><td><b><nobr>    Ymax</nobr></b></td><td>The ending vertical position that the camera view will be drawn.
</td></tr><tr><td><b><nobr>Near Clip Plane</nobr></b></td><td> The closest point relative to the camera that drawing will occur.
</td></tr><tr><td><b><nobr>Far Clip Plane</nobr></b></td><td> The furthest point relative to the camera that drawing will occur.
</td></tr><tr><td><b><nobr>Field of view</nobr></b></td><td> Width of the Camera's view angle, measured in degrees along the local Y axis.
</td></tr><tr><td><b><nobr>Is ortho graphic</nobr></b></td><td> Toggles the camera's capability to simulate perspective.
</td></tr><tr><td><b><nobr>Orthographic size</nobr></b></td><td> The viewport size of the Camera when it is Orthographic.
</td></tr><tr><td><b><nobr>Depth</nobr></b></td><td> The camera's position in the draw order. Cameras with a higher depth will be drawn on top of cameras with a lower depth value.
</td></tr><tr><td><b><nobr>Culling Mask</nobr></b></td><td> Include or omit layers of objects to be rendered by the Camera.  Assign layers to your objects in the Inspector.
</td></tr><tr><td><b><nobr>Render Target (Pro)</nobr></b></td><td> Reference to a Render Texture that will contain the output of the Camera view
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>Cameras are essential for displaying your game to the player.  They can be customized, scripted, or parented to achieve just about any kind of effect imaginable.  For a puzzle game, you might keep the Camera static for a full view of the puzzle.  For a first-person shooter, you would parent the Camera to the player character, and place it at the character's eye level.  For a racing game, you'd likely want to have the Camera follow your player's vehicle.
</p>

<p>You can create multiple Cameras and assign each one to a different depth.  Cameras are drawn from low depth to high depth.  In other words, a Camera with a depth of 2 will be drawn on top of a Camera with a depth of 1.  You can adjust the values of the <b>Normalized View Port Rectangle</b> property to resize and position the Camera's view onscreen.  This can create multiple mini-views like missile cams, map views, rear-view mirrors, etc.
</p>

<p><img class='figure' src='images/Cameras-1.jpg' />
</p>

<p><i>Multiple Cameras making use of <b>Normalized View Port Rectangle</b></i>
</p>

<h3>Clear Flags</h3>

<p>Each Camera stores a color and depth information when it renders its view.  The portions of the screen that are not filled with a game object are empty, and will display the skybox by default.  When you are using multiple Cameras, each one stores its own color and depth information in buffers, accumulating more data as each Camera renders.  As any particular Camera in your scene renders its view, you can set the <b>Clear Flags</b> to clear different collections of the buffer information. This is done by choosing one of the four options:
</p>

<h4><span style="text-decoration:underline;">Skybox</span></h4>
<p>This is the default setting.  Any empty portions of the screen will display the current Camera's skybox.  If the current Camera has no skybox set, it will default to the skybox chosen in the <a href="../Components/class-RenderSettings.html">Render Settings</a> (found in <b>Edit -&gt; Render Settings</b>).  It will then fall back to the <b>Background Color</b>.
</p>

<h4><span style="text-decoration:underline;">Solid Color</span></h4>
<p>Any empty portions of the screen will display the current Camera's <b>Background Color</b>.
</p>

<h4><span style="text-decoration:underline;">Depth Only</span></h4>
<p>For example, if you wanted to draw a player's gun without letting it get clipped inside the environment, you would set one Camera at Depth 0 to draw the environment, and another Camera at Depth 1 to draw the weapon alone.  The weapon Camera's <b>Clear Flags</b> should be set to to &quot;depth only&quot;.  This will keep the graphical display of the environment on the screen, but discard all information about where each object exists in 3-D space.  When the gun is drawn, the opaque parts will completely cover anything drawn, regardless of how close the gun is to the wall.
</p>

<p><img class='figure' src='images/Cameras-2.jpg' />
</p>

<p><i>The gun is drawn last, after clearing the depth buffer of the cameras before it</i>
</p>

<h4><span style="text-decoration:underline;">Don't Clear</span></h4>
<p>This mode does not clear either the color or the depth buffer.  The result is that each frame is drawn over the next, resulting in a smear-looking effect.  This isn't typically used in games, and would likely be best used with a custom shader.
</p>

<h3>Clip Planes</h3>

<p>The <b>Near</b> and <b>Far Clip Plane</b> properties determine where the Camera's view begins and ends.  The planes are laid out perpendicular to the Camera's direction and are measured from the its position.  The <b>Near plane</b> is the closest location that will be rendered, and the <b>Far plane</b> is the furthest.
</p>

<p><img class='figure' src='images/Cameras-3.jpg' />
</p>

<p><i>Far Clip Plane set to small versus large distance</i>
</p>

<p>The clipping planes also determine how depth buffer precision is distributed over the scene. In general, to get better precision you should move the <b>Near plane</b> as far as possible.
</p>

<h3>Culling Mask</h3>

<p>The Culling Mask is used for selectively rendering groups of objects using Layers.  More information on using layers can be found <a href="../ScriptingConcepts/Layers.html">here</a>.
</p>

<p>Commonly, it is good practice to put your User Interface on a different layer, then render it by itself with a separate camera set to render the UI layer by itself.
</p>

<p>In order for the UI to display on top of the other Camera views, you'll also need to set the <b>Clear Flags</b> to &quot;Depth only&quot; and make sure that the UI Camera's <b>Depth</b> is higher than the other Cameras.
</p>

<h3>Normalized Viewport Rectangle</h3>

<p><b>Normalized Viewport Rectangles</b> are specifically for defining a certain portion of the screen that the current camera view will be drawn upon.  You can put a map view in the lower-right hand corner of the screen, or a missile-tip view in the upper-left corner.  With a bit of design work, you can use Viewport Rectangle to create some unique behaviors.
</p>

<p>It's easy to create a two-player split screen effect using Normalized Viewport Rectangle.  After you have created your two cameras, change player one's Ymin value to 0.5, and player two's Ymax: value to 0.5.  This will make player one's camera display from halfway up the screen to the top, and player two's camera will start at the bottom and stop halfway up the screen.
</p>

<p><img class='figure' src='images/Cameras-4.jpg' />
</p>

<p><i>Two-player display created with Normalized Viewport Rectangle</i>
</p>

<h3>Orthographic</h3>

<p>Marking a Camera as orthographic removes all perspective from the Camera's view.
</p>

<p><img class='figure' src='images/Cameras-5.jpg' />
</p>

<p><i>A non-orthographic and orthographic camera viewports</i>
</p>


<h3>Render Texture</h3>

<p>This feature is only available for Unity Pro licenses.  It will place the camera's view onto a <a href="../Components/class-RenderTexture.html"> Texture</a> that can then be applied to another object.  This makes it easy to create sports arena video monitors, surveillance cameras, reflections etc.
</p>

<p><img class='figure' src='images/Cameras-6.jpg' />
</p>

<p><i>Render Texture used to create a live Arena-Cam</i>
</p>

<h2>Hints</h2>
<p><ul><li>
Cameras can be instantiated, parented, and scripted just like any other Game Object.
</li><li>To increase the sense of speed in a racing game, use a high field of view.
</li><li>Cameras can be used in physics simulation if you add a Rigidbody component.
</li><li>There is no limit to the number of Cameras you can have in your scenes.
</li><li>Orthographic cameras are great for making 3-D user interfaces
</li><li>Pro license holders have the option of rendering a Camera's view to a texture, called Render-to-Texture, for even more unique effects.
</li><li>Unity comes with pre-installed Camera scripts, found in <b>Components -&gt; Camera Control</b>.  Experiment with them to get a taste of what's possible.
</li><li>If you are experiencing depth artifacts (close surfaces flickering), try setting <b>Near Plane</b> to as large value as possible in your scene.
</li></ul>
</p>



<p>Particles are essentially 2D images rendered in 3D space.  They are primarily used for effects such as smoke, fire, water droplets, or leaves.  A particle system is made up of three separate Components: Particle Emitter, Particle Animator, Particle Renderer.  You can use a Particle Emitter and Renderer together if you want static particles.  The Particle Animator will move particles in different directions and change colors.  You also have access to each individual particle in a particle system via scripting, so you can create your own unique behaviors that way if you choose.
</p>

<p>Please view the Particle Scripting Reference <a class="wiki"  href="../ScriptReference/ParticleEmitter.html">here</a>.
</p>

<p>The remainder of this page's text is from the <a href="../Components/comp-ParticlesGroup.html">Particle Component Reference</a> pages.
</p>

<h1>Particle systems</h1>

<p>Particle systems in Unity are used to make clouds of smoke, steam, fire and other atmospheric effects. Particle systems work by using one or two textures &amp; drawing them many times, creating a chaotic effect.
</p>

<p><img class='figure' src='images/Particle Systems-0.jpg' />
</p>

<p>One of the default explosions included in unity and the two textures it is made of. The orange texture is used for the flames in the bottom of the explosion, and the grayscale one is used to make the smoke near the top.
</p>

<p>A typical particle system in Unity is an object that contains a Particle Emitter, a Particle Animator and a Particle Renderer component. The <a href="../Components/class-EllipsoidParticleEmitter.html">emitter</a> generates the particles, the <a href="../Components/class-ParticleAnimator.html">animator</a> moves them over time, and the <a href="../Components/class-ParticleRenderer.html">renderer</a> gets them on the screen.
</p>

<p>If you want your particles to interact with the world, add a <a href="../Components/class-WorldParticleCollider.html">particle collider</a> component to the object.
</p>

<h2>See also</h2>



<h1>Ellipsoid Particle Emitter</h1>
<p>The Ellipsoid Particle Emitter spawns particles inside a sphere. Use the <b>Ellipsoid</b> property below to scale &amp; stretch the sphere.
</p>

<p><img class='figure' src='images/Particle Systems-1.jpg' />
</p>

<p><i>The Ellipsoid Particle Emitter</i>
</p>


<h2>Properties</h2>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
 Emit</nobr></b></td><td> If enabled, the emitter will emit particles.
</td></tr><tr><td><b><nobr>Min Size</nobr></b></td><td> The minimum size each particle can be at the time when it is spawned.
</td></tr><tr><td><b><nobr>Max Size</nobr></b></td><td> The maximum size each particle can be at the time when it is spawned.
</td></tr><tr><td><b><nobr>Min Energy</nobr></b></td><td> The minimum lifetime of each particle, measured in seconds.
</td></tr><tr><td><b><nobr>Max Energy</nobr></b></td><td> The maximum lifetime of each particle, measured in seconds.
</td></tr><tr><td><b><nobr>Min Emission</nobr></b></td><td> The minimum number of particles that will be spawned every second.
</td></tr><tr><td><b><nobr>Max Emission</nobr></b></td><td> The maximum number of particles that will be spawned every second.
</td></tr><tr><td><b><nobr>World Velocity</nobr></b></td><td> The starting speed of particles in world space, along X, Y, and Z.
</td></tr><tr><td><b><nobr>Local Velocity</nobr></b></td><td> The starting speed of particles along X, Y, and Z, measured in the object's orientation.
</td></tr><tr><td><b><nobr>Rnd Velocity</nobr></b></td><td> A random speed along X, Y, and Z that is added to the velocity.
</td></tr><tr><td><b><nobr>Emitter Velocity Scale</nobr></b></td><td> The amount of the emitter's speed that the particles inherit.
</td></tr><tr><td><b><nobr>Simulate In World Space</nobr></b></td><td> If enabled, the particles don't move when the emitter moves. If false, when you move the emitter, the particles follow it around.
</td></tr><tr><td><b><nobr>One Shot</nobr></b></td><td> If enabled, the particle numbers specified by min &amp; max emission is spawned all at once. If disabled, the particles are generated in a long stream.
</td></tr><tr><td><b><nobr>Ellipsoid</nobr></b></td><td> Scale of the sphere along X, Y, and Z that the particles are spawned inside.
</td></tr><tr><td><b><nobr>MinEmitterRange</nobr></b></td><td> Determines an empty area in the center of the sphere - use this to make particles appear on the edge of the sphere.
<p></td></tr></tr></table>
</p>


<h2>Details</h2>
<p>Ellipsoid Particle Emitters (EPEs) are the basic emitter, and are included when you choose to add a Particle System to your scene from Components -&gt; Particles -&gt; Particle System.  You can define the boundaries for the particles to be spawned, and give the particles an initial velocity.  From here, use the <a href="../Components/class-ParticleAnimator.html">Particle Animator</a> to manipulate how your particles will change over time to achieve interesting effects.
</p>

<p><img class='figure' src='images/Particle Systems-2.jpg' />
</p>

<p><i>An EPE applied to a sphere</i>
</p>

<p>Particle Emitters work in conjunction with <a href="../Components/class-ParticleAnimator.html">Particle Animators</a> and <a href="../Components/class-ParticleRenderer.html">Particle Renderers</a> to create, manipulate, and display Particle Systems.  All three components must be present on an object before the particles will behave correctly.  When particles are being emitted, all different velocities are added together to create the final velocity.
</p>


<h3>Spawning Properties</h3>

<p>Spawning properties like <b>Size</b>, <b>Energy</b>, <b>Emission</b>, and <b>Velocity</b> will give your particle system distinct personality when trying to achieve different effects.  Having a small <b>Size</b> could simulate fireflies or stars in the sky.  A large <b>Size</b> could simulate dust clouds in a musky old building.
</p>

<p><b>Energy</b> and <b>Emission</b> will control how long your particles remain onscreen and how many particles can appear at any one time.  For example, a rocket might have high <b>Emission</b> to simulate density of smoke, and high <b>Energy</b> to simulate the slow dispersion of smoke into the air.
</p>

<p><b>Velocity</b> will control how your particles move.  You might want to change your <b>Velocity</b> in scripting to achieve interesting effects, or if you want to simulate a constant effect like wind, set your X and Z <b>Velocity</b> to make your particles blow away.
</p>

<h3>Simulate in World Space</h3>

<p>If this is disabled, the position of each individual particle will always translate relative to the <b>Position</b> of the emitter.  When the emitter moves, the particles will move along with it.  If you have <b>Simulate in World Space</b> enabled, particles will not be affected by the translation of the emitter.  For example, if you have a fireball that is spurting flames that rise, the flames will be spawned and float up in space as the fireball gets further away.  If <b>Simulate in World Space</b> is disabled, those same flames will move across the screen along with the fireball.
</p>

<h3>Emitter Velocity Scale</h3>

<p>This property will only apply if <b>Simulate in World Space</b> is enabled.
</p>

<p>If this property is set to 1, the particles will inherit the exact translation of the emitter at the time they are spawned.  If it is set to 2, the particles will inherit double the emitter's translation when they are spawned.  3 is triple the translation, etc.
</p>

<h3>One Shot</h3>

<p><b>One Shot</b> emitters will create all particles within the <b>Emission</b> property all at once, and cease to emit particles over time.  Here are some examples of different particle system uses with <b>One Shot</b> enabled or disabled:
</p>

<p>Enabled
</p>
<ul><li>Explosion
</li><li>Water splash
</li><li>Magic spell
</li></ul>

<p>Disabled
</p>
<ul><li>Gun barrel smoke
</li><li>Wind effect
</li><li>Waterfall
</li></ul>



<h3>Min Emitter Range</h3>

<p>The <b>Min Emitter Range</b> determines the depth within the ellipsoid that particles can be spawned.  Setting the range to 0 will allow particles to spawn anywhere from the center core of the ellipsoid to the outer-most range.  Setting the range to 1 will restrict spawn locations to the outer-most range of the ellipsoid.
</p>

<p><img class='figure' src='images/Particle Systems-3.jpg' />
</p>

<p><i><b>Min Emitter Range</b> of 0</i>
</p>

<p><img class='figure' src='images/Particle Systems-4.jpg' />
</p>

<p><i><b>Min Emitter Range</b> of 1</i>
</p>

<h2>Hints</h2>
<p><ul><li>
Be careful of using many large particles. This can seriously hinder performance on low-level machines. Always try to use the minimum number of particles to attain an effect.
</li><li>The <b>Emit</b> property works in conjunction with the <b>AutoDestruct</b> property of the ParticleAnimator.  Through scripting, you can cease the emitter from emitting, and then <b>AutoDestruct</b> will automatically destroy the Particle System and the GameObject it is attached to.
</li></ul>
</p>
<h1> Mesh Particle Emitter</h1>
<p>The Mesh Particle Emitter emits particles around a mesh. Particles are spawned from the surface of the mesh, which can be necessary when you want to make your particles interact in a complex way with objects.
</p>

<p><img class='figure' src='images/Particle Systems-5.jpg' />
</p>

<p><i>The Mesh Particle Emitter</i>
</p>

<p>Here is how to create a <a href="../Manual/HOWTO-MeshParticleEmitter.html">Mesh Particle Emitter</a>.
</p>

<h2> Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
 Emit</nobr></b></td><td> If enabled, the emitter will emit particles.
</td></tr><tr><td><b><nobr>Min Size</nobr></b></td><td> The minimum size each particle can be at the time when it is spawned.
</td></tr><tr><td><b><nobr>Max Size</nobr></b></td><td> The maximum size each particle can be at the time when it is spawned.
</td></tr><tr><td><b><nobr>Min Energy</nobr></b></td><td> The minimum lifetime of each particle, measured in seconds.
</td></tr><tr><td><b><nobr>Max Energy</nobr></b></td><td> The maximum lifetime of each particle, measured in seconds.
</td></tr><tr><td><b><nobr>Min Emission</nobr></b></td><td> The minimum number of particles that will be spawned every second.
</td></tr><tr><td><b><nobr>Max Emission</nobr></b></td><td> The maximum number of particles that will be spawned every second.
</td></tr><tr><td><b><nobr>World Velocity</nobr></b></td><td> The starting speed of particles in world space, along X, Y, and Z.
</td></tr><tr><td><b><nobr>Local Velocity</nobr></b></td><td> The starting speed of particles along X, Y, and Z, measured in the object's orientation.
</td></tr><tr><td><b><nobr>Rnd Velocity</nobr></b></td><td> A random speed along X, Y, and Z that is added to the velocity.
</td></tr><tr><td><b><nobr>Emitter Velocity Scale</nobr></b></td><td> The amount of the emitter's speed that the particles inherit.
</td></tr><tr><td><b><nobr>Simulate In World Space</nobr></b></td><td> If enabled, the particles don't move when the emitter moves. If false, when you move the emitter, the particles follow it around.
</td></tr><tr><td><b><nobr>One Shot</nobr></b></td><td> If enabled, the particle numbers specified by min &amp; max emission is spawned all at once. If disabled, the particles are generated in a long stream.
</td></tr><tr><td><b><nobr>Interpolate Triangles</nobr></b></td><td> If enabled, particles are spawned all over the mesh's surface. If disabled, particles are only spawned from the mesh's vertrices.
</td></tr><tr><td><b><nobr>Systematic</nobr></b></td><td> If enabled, particles are spawned in the order of the vertices defined in the mesh. Although you seldom have direct control over vertex order in meshes, most 3D modelling applications have a very systematic setup when using primitives. It is important that the mesh contains no faces in order for this to work.
</td></tr><tr><td><b><nobr>Min Normal Velocity</nobr></b></td><td> Minimum amount that particles are thrown away from the mesh.
</td></tr><tr><td><b><nobr>Max Normal Velocity</nobr></b></td><td> Maximum amount that particles are thrown away from the mesh.
<p></td></tr></tr></table>
</p>

<h2> Details</h2>
<p>Mesh Particle Emitters (MPEs) are used when you want more precise control over the spawn position &amp; directions than the simpler Ellipsoid Particle Emitter gives you.  They can be used for making advanced effects like flaming swords.
</p>

<p><img class='figure' src='images/Particle Systems-6.jpg' />
</p>

<p><i>A flaming sword created with a Mesh Particle Emitter</i>
</p>

<p>MPEs work emitting particles at the vertices of the attached mesh. Therefore, the areas of your mesh that are more dense with polygons will be more dense with particle emission.
</p>

<p>Particle Emitters work in conjunction with <a href="../Components/class-ParticleAnimator.html">Particle Animators</a> and <a href="../Components/class-ParticleRenderer.html">Particle Renderers</a> to create, manipulate, and display Particle Systems.  All three components must be present on an object before the particles will behave correctly.  When particles are being emitted, all different velocities are added together to create the final velocity.
</p>


<h3>Spawning Properties</h3>

<p>Spawning properties like <b>Size</b>, <b>Energy</b>, <b>Emission</b>, and <b>Velocity</b> will give your particle system distinct personality when trying to achieve different effects.  Having a small <b>Size</b> could simulate fireflies or stars in the sky.  A large <b>Size</b> could simulate dust clouds in a musky old building.
</p>

<p><b>Energy</b> and <b>Emission</b> will control how long your particles remain onscreen and how many particles can appear at any one time.  For example, a rocket might have high <b>Emission</b> to simulate density of smoke, and high <b>Energy</b> to simulate the slow dispersion of smoke into the air.
</p>

<p><b>Velocity</b> will control how your particles move.  You might want to change your <b>Velocity</b> in scripting to achieve interesting effects, or if you want to simulate a constant effect like wind, set your X and Z <b>Velocity</b> to make your particles blow away.
</p>

<h3>Simulate in World Space</h3>

<p>If this is disabled, the position of each individual particle will always translate relative to the <b>Position</b> of the emitter.  When the emitter moves, the particles will move along with it.  If you have <b>Simulate in World Space</b> enabled, particles will not be affected by the translation of the emitter.  For example, if you have a fireball that is spurting flames that rise, the flames will be spawned and float up in space as the fireball gets further away.  If <b>Simulate in World Space</b> is disabled, those same flames will move across the screen along with the fireball.
</p>

<h3>Emitter Velocity Scale</h3>

<p>This property will only apply if <b>Simulate in World Space</b> is enabled.
</p>

<p>If this property is set to 1, the particles will inherit the exact translation of the emitter at the time they are spawned.  If it is set to 2, the particles will inherit double the emitter's translation when they are spawned.  3 is triple the translation, etc.
</p>

<h3>One Shot</h3>

<p><b>One Shot</b> emitters will create all particles within the <b>Emission</b> property all at once, and cease to emit particles over time.  Here are some examples of different particle system uses with <b>One Shot</b> enabled or disabled:
</p>

<p>Enabled
</p>
<ul><li>Explosion
</li><li>Water splash
</li><li>Magic spell
</li></ul>

<p>Disabled
</p>
<ul><li>Gun barrel smoke
</li><li>Wind effect
</li><li>Waterfall
</li></ul>


<h2>Interpolate Triangles</h2>

<p>Enabling your emitter to interpolate triangles will allow particles to be spawned outside of the mesh's vertices.  This option is off by default, so particles will only be spawned at vertex locations.
</p>

<p><img class='figure' src='images/Particle Systems-7.jpg' />
</p>

<p><i>A flaming sword with <b>Interpolate Triangles</b> off (by default)</i>
</p>

<p>Enabling this option will spawn particles on and in-between vertices, essentially all over the mesh's surface (seen below).
</p>

<p><img class='figure' src='images/Particle Systems-8.jpg' />
</p>

<p><i>A flaming sword with <b>Interpolate Triangles</b> on</i>
</p>

<p>It bears repeating that even with <b>Interpolate Triangles</b> enabled, particles will still be denser in areas of your mesh that are more dense with polygons.
</p>

<h2>Systematic</h2>

<p>Enabling <b>Systematic</b> will cause your particles to be spawned in your mesh's vertex order.  The vertex order is set by your 3D modeling application.
</p>

<p><img class='figure' src='images/Particle Systems-9.jpg' />
</p>

<p><i>An MPE attached to a sphere with Systematic enabled</i>
</p>

<h2>Normal Velocity</h2>

<p><b>Normal Velocity</b> controls the speed at which particles are emitted along the normal from where they are spawned.
</p>

<p>For example, create a Mesh Particle system, use a cube mesh as the emitter, enable <b>Interpolate Triangles</b>, and set <b>Normal Velocity Min</b> and <b>Max</b> to 1. You will now see the particles emit from the faces of the cube in a straight line.
</p>

<h2>See Also</h2>
<ul><li> <a href="../Manual/HOWTO-MeshParticleEmitter.html">How to make a Mesh Particle Emitter</a>
</li></ul>

<h2> Hints</h2>
<p><ul><li>
</p>

<p>MPEs can also be used to make glow from a lot of lamps placed in a scene. Simply make a mesh with one vertex in the center of each lamp, and build an MPE from that with a halo material. Great for evil sci-fi worlds.
</li></ul>
</p>
<h1> Particle Animator</h1>
<p>Particle Animators move your particles over time, you use them to apply wind, drag &amp; color cycling to your particle systems.
</p>

<p><img class='figure' src='images/Particle Systems-10.jpg' />
</p>

<p><i>The Particle Animator</i>
</p>

<h2> Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Does Animate Color</nobr></b></td><td> If enabled, particles cycle their color over their lifetime.
</td></tr><tr><td><b><nobr>Color Animation</nobr></b></td><td> The 5 colors particles go through. All particles cycle over this - if some have a shorter life span than others, they will animate faster.
</td></tr><tr><td><b><nobr>World Rotation Axis</nobr></b></td><td> An optional world-space axis the particles rotate around. Use this to make advanced spell effects or give caustic bubbles some life.
</td></tr><tr><td><b><nobr>Local Rotation Axis</nobr></b></td><td> An optional local-space axis the particles rotate around. Use this to make advanced spell effects or give caustic bubbles some life.
</td></tr><tr><td><b><nobr>Size Grow</nobr></b></td><td> Use this to make particles grow in size over their lifetime. As randomized forces will spread your particles out, it is often nice to make them grow in size so they don't fall apart.
Use this to make smoke rise upwards, to simulate wind, etc.
</td></tr><tr><td><b><nobr>Rnd Force</nobr></b></td><td> A random force added to particles every frame. Use this to make smoke become more alive.
</td></tr><tr><td><b><nobr>Force</nobr></b></td><td> The force being applied every frame to the particles, measure relative to the world.
</td></tr><tr><td><b><nobr>Damping</nobr></b></td><td> How much particles are slowed every frame. A value of 1 gives no damping, while less makes them slow down.
</td></tr><tr><td><b><nobr>Autodestruct</nobr></b></td><td> If enabled, the GameObject attached to the Particle Animator will be destroyed when all particles disappear.
<p></td></tr></tr></table>
</p>

<h2> Details</h2>

<p>Particle Animators allow your particle systems to be dynamic.  They allow you to change the color of your particles, apply forces and rotation, and choose to destroy them when they are finished emitting.  For more information about Particle Systems, reference <a href="../Components/class-MeshParticleEmitter.html">Mesh Particle Emitters</a>, <a href="../Components/class-EllipsoidParticleEmitter.html">Ellipsoid Particle Emitters</a>, and <a href="../Components/class-ParticleRenderer.html">Particle Renderers</a>.
</p>

<h3>Animating Color</h3>

<p>If you would like your particles to change colors or fade in/out, enable them to <b>Animate Color</b> and specify the colors for the cycle.  Any particle system that animates color will cycle through the 5 colors you choose.  The speed at which they cycle will be determined by the Emitter's <b>Energy</b> value.
</p>

<p>If you want your particles to fade in rather than instantly appear, set your first or last color to have a low Alpha value.
</p>

<p><img class='figure' src='images/Particle Systems-11.jpg' />
</p>

<p><i>An <b>Animating Color</b> Particle System</i>
</p>

<h3>Rotation Axes</h3>

<p>Setting values in either the Local or World <b>Rotation Axes</b> will cause all spawned particles to rotate around the indicated axis (with the <b>Transform's</b> position as the center).  The greater the value is entered on one of these axes, the faster the rotation will be.
</p>

<p>Setting values in the Local Axes will cause the rotating particles to adjust their rotation as the <b>Transform's</b> rotation changes, to match its local axes.
</p>

<p>Setting values in the World Axes will cause the particles' rotation to be consistent, regardless of the <b>Transform's</b> rotation.
</p>

<h3>Forces &amp; Damping</h3>

<p>You use force to make particles accelerate in the direction specified by the force.
</p>

<p>Damping (Drag) can be used to decelerate or accelerate without changing their direction.<br />
A value of 1 means no damping is applied, the particles will not slow down or accelerate.<br />
A value of 0 means particles will stop immediately.<br />
A value of 2 means particles will double their speed every second.
</p>

<h3>Destroying Objects attached to Particles</h3>

<p>You can destroy the Particle System and any attached Game Object by enabling the <b>AutoDestruct</b> property.  For example, if you have an oil drum, you can attach a Particle System that has <b>Emit</b> disabled and <b>AutoDestruct</b> enabled.  On collision, you enable the Particle Emitter.  The explosion will occur and after it is over, the Particle System and the oil drum will be destroyed and removed from the scene.
</p>

<h2> Hints</h2>
<p><ul><li>
Use the color animation to make your particles fade in &amp; out over their lifetime - otherwise, you will get nasty-looking pops.
</li><li>Use the rotation axes to make whirlpool-like swirly motions.
</li></ul>
</p>
<h1>Particle Collider</h1>

<p>The Particle Collider is used to collide particles against other objects in the scene.
</p>

<p><img class='figure' src='images/Particle Systems-12.jpg' />
</p>

<p><i>A shot of a very simple particle system with particle collider colliding with a cube</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Bounce Factor</nobr></b></td><td> Particles can be accelerated or slowed down when they collide against other objects. This factor is similar to the Particle Animator's damping.
</td></tr><tr><td><b><nobr>Collision Energy Loss</nobr></b></td><td>Amount of energy (in seconds) a particle should lose when colliding. If the energy goes below 0, the particle is killed
</td></tr><tr><td><b><nobr>Min Kill Velocity</nobr></b></td><td> If a particle's velocity drops below Min Kill Velocity because of a Collision, it will be eliminated.
</td></tr><tr><td><b><nobr>Collides with</nobr></b></td><td> Which layers the particles collides against.
</td></tr><tr><td><b><nobr>Send Collision Message</nobr></b></td><td> When colliding every particle sends out a message that you can catch through scripting.
<p></td></tr></tr></table>
</p>
<h2>Details</h2>

<p>To create a particle system with particle collider:
</p>
<ol><li> Create a particle system using <b>GameObject -&gt; Create Other -&gt; Particle System</b>
</li><li> Add the particle collider using <b>Component -&gt; Particles -&gt; World Particle Collider</b>
</li></ol>


<h3>Messaging</h3>
<p>If Send Collision Message is enabled, any particles that are in a collision will send the message OnParticleCollision to  both the particle's GameObject and the GameObject the particle collided with.
</p>

<h2>Hints</h2>
<p><ul><li>
Send Collision message can be used to simulate bullets and apply damage on impact.
</li><li>Particle Collision Detection is slow when used with a lot of particles. Use Particle Collision Detection wisely.
</li><li>Message sending introduces a large overhead and shouldn't be used for normal particle systems.
</li></ul>
</p>
<h1>Particle Renderer</h1>
<p>The Particle Renderer renders the particle system on screen.
</p>

<p><img class='figure' src='images/Particle Systems-13.jpg' />
<i>The Particle Renderer</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Materials</nobr></b></td><td> Reference to a list of Materials that will be displayed in the position of each individual particle.
</td></tr><tr><td><b><nobr>Camera Velocity Scale</nobr></b></td><td> The amount of stretching that is applied to the particles based on Camera movement.
</td></tr><tr><td><b><nobr>Stretch Particles</nobr></b></td><td> Determines how the particles are rendered.
<dl><dt>Billboard</dt><dd> The particles are rendered as if facing the camera.</dd><dt>Stretched</dt><dd> The particles are facing the direction they are moving. </dd><dt>SortedBillboard</dt><dd> The particles are sorted by depth. Use this when using a blending material.</dd></dl>
</td></tr><tr><td><b><nobr>Length Scale</nobr></b></td><td> If <b>Stretch Particles</b> is set to Stretched, this value determines how long the particles are in their direction of motion.
</td></tr><tr><td><b><nobr>Velocity Scale</nobr></b></td><td> If <b>Stretch Particles</b> is set to Stretched, this value determines the rate at which particles will be stretched, based on their movement speed.
</td></tr><tr><td><b><nobr>UV Animation</nobr></b></td><td> If either of these are set, the UV coordinates of the particles will be generated for use with a tile animated texture. See the section on Animated Textures below.
</td></tr><tr><td><b><nobr>    X Tile</nobr></b></td><td> Number of frames located across the X axis
</td></tr><tr><td><b><nobr>    Y Tile</nobr></b></td><td> Number of frames located across the Y axis
</td></tr><tr><td><b><nobr>    Cycles</nobr></b></td><td> How many times to loop the animation sequence.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>Particle Renderers are required for any Particle Systems to be displayed on the screen.
</p>

<p><img class='figure' src='images/Particle Systems-14.jpg' />
</p>

<p><i>A Particle Renderer is what makes explosion appear on the screen</i>
</p>

<h3> Choosing a material</h3>
<p>When setting up a particle renderer it is very important to use an appropriate material and shader. Most of the time you want to use a material with one of the <b>builtin Particle shaders</b>. There are some premade materials in the Standard Assets/Particles/Sources folder.
</p>

<p>Creating a new material is easy:
</p>
<ol><li> <b>Assets -&gt; Create Other -&gt; Material</b>
</li><li> The {class-Material|material} has a shader popup, choose one of the shaders in the Particles group. Eg. Particles/Multiply
</li><li> Now assign a texture. The different shaders use the alpha channel of the textures slightly differently, but most of the time a value of black will make it invisible and white in the alpha channel will display it on screen.
</li></ol>

<h3>Distorting particles</h3>

<p>By default particles are rendered billboarded. That is simple square sprites. This is good for smoke and explosions and most other particle effects.
</p>

<p>Particles can be made to either stretch with the velocity. This is useful for sparks, lightning or laser beam.
Length Scale and Velocity Scale affects how long the stretched particle will be.
</p>

<p>Sorted Billboard can be used to make all particles sort by depth. Sometimes this is necessary, mostly when using Alpha Blended particle shaders. This can be expensive and should only be used if it really makes a quality difference when rendering.
</p>

<h3>Animated textures</h3>
<p>Particle systems can be rendered with an animated tile texture. To use this feature, make the texture out of a grid of images. As the particles go thorough their life cycle, they will cycle through the images. This is good for adding more life to your particles, or making small rotating debris pieces.
</p>

<h2>Hints</h2>
<p><ul><li>
Use particle materials with the Particle Renderer.
</li></ul>
</p>



<p>A large part of making a game is assigning all your source files to world objects. This goes for textures, models, sound effects and behaviour scripts. Inside Unity, you have quick access to all the files that makes up your game using the Project view:
</p>

<p><img class='figure' src='images/Working with Assets-0.jpg' />
</p>

<p>This view shows the organization of the files in your project folder. Whenever you change one of your asset files, changes are immediately reflected into your game!
</p>

<p>In order to import an asset file in your game, you simple move the file into the Assets folder in the Finder, and it will get imported into Unity. To assign it to objects in your game scenes, simply drag the files from the project window over your objects in the hierarchy or scene views.
</p>

<p>What exactly happens depends on the type of file:
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Importing Assets.html">Importing Assets</a></li><li class="toclevel"><a href="../Manual/Meshes.html">Meshes</a></li><li class="toclevel"><a href="../Manual/Textures.html">Textures</a></li><li class="toclevel"><a href="../Manual/Materials.html">Materials</a></li><li class="toclevel"><a href="../Manual/Audio Files.html">Audio Files</a></li><li class="toclevel"><a href="../Manual/Scripting.html">Scripting</a></li></ul>
</p>

<h2>Hints</h2>

<ul><li> Rename and move files to your heart's content inside Project View; nothing will break.
</li><li> <b>Never</b> rename or move anything from the Finder or another program; everything will break. In short, Unity stores lots of metadata for each asset (things like import settings, cached versions of compressed textures, etc.) and if you move a file externally, Unity can no longer associate metadata with the moved file.
</li></ul>




<p>Unity will automatically detect files as they are added to your project folder.  When you put any asset into your project's Assets folder, you will see the asset appear in your Project View within the editor.  The Project View is window into the Assets folder.  When you are building a game and you want to add a new asset of any type, all you have to do is create the asset and save it somewhere in your project's assets folder.  When you return to Unity or launch it, the added file(s) will be detected and imported.
</p>

<p>Additionally, as you update and save your assets, the changes will be detected and the asset will be re-imported in Unity.  This allows you to focus on refining your assets without struggling to make them compatible with Unity.
</p>

<h2>Maintaining Assets</h2>

<p>It is very important to remember to move, rename, and otherwise manipulate your assets from the Project View once they have been imported into Unity.  There are many dependencies that are established behind the scenes, and if you relocate a file or folder from the Finder, the dependencies will be broken and you will have to re-link your assets.  This is a huge headache and you probably don't want to do it.  So just remember to only Save to the Assets folder from the Finder, and never rename or move files from the Finder.  Always use Project View.
</p>

<h2>Asset Types</h2>

<p>There are a handful of basic asset types that will go into your game.  The types are:
</p>

<ul><li> Mesh Files &amp; Animations
</li><li> Texture Files
</li><li> Sound Files
</li></ul>

<p>We'll discuss the details of importing each of these file types and how they are used.
</p>

<h3>Meshes &amp; Animations</h3>

<p>Whichever 3-D package you are using, Unity will import the meshes and animations from each file.  For a list of applications that are supported by Unity, please see <a href="../Manual/HOWTO-importObject.html">this page</a>.
</p>

<p>Your mesh file does not need to have an animation to be imported.  If you do use animations, you have your choice of importing all animations from a single file, or importing separate files each with one animation.  For more information about importing animations, please see <a href="../Manual/Character-Animation.html">this page</a>.
</p>

<p>Once your mesh is imported into Unity, you can drag it to the Scene or Hierarchy to create an instance of it.  You can also add Components to the instance, which will not be attached to mesh file itself.
</p>

<p>Meshes will be imported with UVs and a number of default materials (one material per UV).  You can then assign the appropriate texture files to the materials and complete the look of your mesh in Unity's game engine.
</p>

<h3>Textures</h3>

<p>Unity supports all image formats.  Even when working with layered Photoshop files, they are imported without disturbing the Photoshop format.  This allows you to work with a single texture file for a very care-free and streamlined experience.
</p>

<p>You should make your textures in dimensions that are to the power of two.  E.g. 32x32, 64x64, 128x128, 256x256, etc.  Simply placing them in your project's Assets folder is sufficient, and they will appear in the Project View.
</p>

<p>Once your texture has been imported, you should assign it to a <a href="../Components/class-Material.html">Material</a>.  The material can then be applied to a mesh, particle system, or GUI Texture.  Using the Import Settings, it can also be converted to a Cubemap or Bumpmap for different types of applications in the game.  For more information about importing textures, please read the <a href="../Components/class-Texture2D.html">Texture Component page</a>.
</p>

<h3>Sounds</h3>

<p>Any sounds you want to use in your game should be converted to Ogg Vorbis format before they are imported into Unity.  Unity will support other sound file types like MP3, but they will not be compressed when a build of your game is published.  Using Ogg Vorbis files from the start will keep your player sizes low.
</p>

<p>You can also use WAV files for sounds that are very short, like a machine gun sound.  If your sound is longer than 5 - 10 seconds, you should convert it to Ogg Vorbis.
</p>

<p>Once sound files are imported, they can be attached to any Game Object.  The Game Object will require an <a href="../Components/class-AudioSource.html">Audio Source Component</a> to use the sound file.
</p>




<p>At the core of any 3D game are <b>Meshes</b> - objects consisting of triangles, with textures applied.
</p>

<p>Meshes in Unity are passed through <i>render pipeline</i>. Although there may be many variations, most often a pipeline consists of a <a href="../Components/class-MeshFilter.html"> Mesh Filter</a> and a <a href="../Components/class-MeshRenderer.html"> Mesh Renderer</a>:
</p>
<ul><li> The filter loads mesh from mesh asset. Regular meshes use a Mesh Filter, while skinned meshes use a <a href="../Components/class-SkinnedMeshFilter.html"> Skinned Mesh Filter</a>.
</li><li> The renderer displays it at the Game Object's position.
</li><li> The appearance of the mesh is controlled through renderer's <a href="../Manual/Materials.html">Materials</a>.
</li></ul>

<p><img class='figure' src='images/Meshes-0.jpg' />
</p>

<p><i>A <a href="../Components/class-MeshFilter.html"> Mesh Filter</a> together with <a href="../Components/class-MeshRenderer.html"> Mesh Renderer</a> makes the model appear on screen. Car model courtesy of ATI Technologies Inc.</i>
</p>

<h1> Importing 3D models</h1>

<p>Meshes make up a large part of your 3D worlds. You don't build your meshes in Unity, but in another application.
</p>

<p>In Unity, we have done everything in our power to make this process as simple as possible. There are a lot of details, but the following should hold:
</p>

<h1> How do I import objects from my 3D app?</h1>

<p>Unity supports importing from a lot of 3D applications. Choose the one you're working with below:
</p>
<ul><li> <a href="../Manual/HOWTO-ImportObjectMaya.html">Maya</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectCinema4D.html">Cinema 4D</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectMax.html">3D Studio MAX</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectCheetah3D.html">Cheetah3D</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectModo.html">Modo</a>
</li><li> <a href="../Manual/HOWTO-importObjectLightwave.html">Lightwave</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectBlender.html">Blender</a>
</li></ul>

<h2> Other applications</h2>
<p>Unity can read <b>.FBX</b>, <b>.3DS</b>, <b>.dxf</b> and <b>.obj</b> files, so if your program can export to this format you're home free. FBX exporters for popular 3D packages can be found <a class="wiki"  href="http://autodesk.com/fbx">here</a>.
</p>

<h2>Hints</h2>
<ul><li> Store textures in a folder called <b>Textures</b> next to the exported mesh. This will guarantee that Unity can always find the Texture and automatically connect the Texture to the Material. For more information, see the <a href="../Components/class-Texture2D.html">Textures</a> reference.
</li></ul>

<h2>See Also</h2>
<ul><li> <a href="../Manual/HOWTO-bumpmap.html">How do I use bump maps?</a>
</li><li> <a href="../Components/class-Mesh.html">Mesh Import Settings</a>
</li><li> <a href="../Manual/HOWTO-FixZAxisIsUp.html">Fixing a mesh that has the z-axis facing upwards</a>
</li></ul>

<h2> Textures</h2>
<p>Unity will attempt to hook up materials to your imported scenes - Basically, just place textures in a folder called 'Textures' next to the sccene file, or in any folder above it.
</p>

<p><img class='figure' src='images/Meshes-1.jpg' />
</p>

<h2> Import settings.</h2>
<p>To access the importing settings for a 3D scene file, click the <b>Settings</b> button in the project window, or control-click a scene file and select <b>Import Settings...</b>.
</p>

<p><img class='figure' src='images/Meshes-2.jpg' />
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Share Materials</nobr></b></td><td> Enable this to generate material files near the found texture files. When enabled,  different scenes will share the same material settings when they use the same textures. For the precise rules, see Material Generation below.
</td></tr><tr><td><b><nobr>One Material for...</nobr></b></td><td> This will generate materials per scene, so only this scene uses them.
</td></tr><tr><td><b><nobr>Don't generate materials</nobr></b></td><td> This will not generate materials at all.
</td></tr><tr><td><b><nobr>Mesh Scale Factor</nobr></b></td><td> Unity's physics system expects 1 meter in the game world to be 1 unit in the imported file. If you like to model at a different scale, this is the place to fix it.
</td></tr><tr><td><b><nobr>Meshes have colliders</nobr></b></td><td> If this is enabled, your meshes will be imported with Mesh Colliders automatically attached. This is recommended for background geometry, but never for geometry you move about. For more info see Colliders below.
</td></tr><tr><td><b><nobr>Automatically calculate normals</nobr></b></td><td> Enable this to automatically generate normals for the imported geometry. If enabled, the <b>Smoothing Angle</b> sets how sharp an edge has to be to be treated as a hard edge.
</td></tr><tr><td><b><nobr>Swap primary and secondary uv channel</nobr></b></td><td> Use this if Lightmapped shaders pick up wrong UV channels.
</td></tr><tr><td><b><nobr>Animation options</nobr></b></td><td> Controls how animations are imported.
<dl><dt>No Animation</dt><dd> No animation or skinning is imported.</dd><dt>Animation in root</dt><dd> Animations are stored in the scene's transform root objects. Use this when animating anything that has a hierarchy.</dd><dt>Animation in original roots</dt><dd> Animations are stored in root objects of your animation package (these might be different from root objects in Unity).</dd><dt>Animation stored in nodes</dt><dd> Animations are stored together with the objects they animate. Use this when you have a complex animation setup and want full scripting control.</dd></dl>
</td></tr><tr><td><b><nobr>Bake IK &amp; simulation</nobr></b></td><td> When using IK or simulation in your animation package, enable this. Unity will convert to FK on import.
</td></tr><tr><td><b><nobr>Keyframe reduction</nobr></b></td><td> Perform keyframe reduction on imported animations. You should always use this, as it takes less memory and is faster.
</td></tr><tr><td><b><nobr>Split animation into multiple clips</nobr></b></td><td> If you have multiple animations in a single file, here you can split it into multiple clips.
<p></td></tr></tr></table>
</p>

<h3> Material Generation</h3>

<p>Materials are found based on the following rules:
</p>

<ul><li> Unity gets the name of the main diffuse material bound to the objects in the scene.
</li><li> Unity looks for a material with this name in a Folder called 'Materials' next to the scene.
</li><li> Unity goes up the project folders, looking for the Material in each 'Materials' folder along the way.
</li></ul>

<p>If Unity can't find the Material, it tries to create one from the texture:
</p>

<ul><li> Unity checks for a texture with the correct name in the same folder as the scene.
</li><li> Unity checks for a texture with the correct name in a folder called 'Textures' next to the scene.
</li><li> Unity goes up the project folders, looking for the correct texture in each 'Textures' folder along the way.
</li><li> If Unity finds the texture, it creates a 'Materials' folder next to it and creates a material in there.
</li></ul>

<h3> Colliders</h3>

<p>Unity features two primary types of colliders: Mesh colliders and Primitive colliders. Mesh colliders are imported together with your geometry and are used for background objects. When you enable <b>Meshes Have Colliders</b> in the import settings, the mesh becomes solid as far as the physics system is concerned.
</p>

<p>If you are moving the object around (a car for example), you can not use mesh colliders. Instead, you will have to use primitive colliders. In this case you should disable the <b>Meshes Have Colliders</b> setting.
</p>

<h3> Animations</h3>

<p>Animations are automatically imported from the scene. For more details about animation import options see <a href="../Manual/Character-Animation.html">Character-Animation</a> chapter.
</p>

<h2>Hints</h2>

<p><ul><li>
Merge your meshes together. Make them share materials and textures. This has a huge performance benefit.
</li><li>If you need to set up your objects further in Unity (adding physics, scripts or other coolness), save yourself a world of pain and name your objects properly in your 3D application. Working with lots of <i>pCube17</i> or <i>Box42</i>-like objects is not fun.
</li><li>Make your meshes be centered on the world origin in your 3D app. This will make them easier to place in Unity.
</li></ul>
</p>



<p>Textures bring your meshes, particles, and interfaces to life! They are image or movie files that you lay over or wrap around your objects. As they are so important, they have a lot of properties. If reading this for the first time, jump down to <i>Details</i>, and return to the actual settings when you need a reference.
</p>

<p>Which shaders you use for your objects put specific requirements on your textures, but the basic principle is that you can put any image file inside your project. If it meets the size requirements (specified below), it will get imported and optimized for game use.
</p>

<p>This extends to multi-layer Photoshop or TIFF files - they are flattened on import, so there is no size penalty for your game.
</p>

<h2>Properties</h2>
<p>The texture inspector looks a bit different from most others:
</p>

<p><img class='figure' src='images/Textures-0.jpg' />
</p>

<p>The top section contains a few settings, and the bottom part contains a texture preview. The changes you make to the bottom part only affect the display, and not the texture itself.
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Filtering Mode</nobr></b></td><td> Selects how the texture is filtered when it gets stretched by 3D transformations.

<dl><dt>No Filtering</dt><dd> The texture becomes blocky up close</dd><dt>Bilinear</dt><dd> The texture becomes blurry up close</dd><dt>Trilinear</dt><dd> Like Bilinear, but the texture also blurs between the different mip levels...</dd></dl>

</td></tr><tr><td><b><nobr>Anisotropy</nobr></b></td><td>   Increases texture quality when viewing the texture at a steep angle. Good for floor textures
</td></tr><tr><td><b><nobr>Edge mode</nobr></b></td><td> Selects how the texture behaves when tiled
<dl><dt>Repeat</dt><dd> The texture repeats (tiles) itself.</dd><dt>Clamp</dt><dd>  The texture's edges get stretched. </dd></dl>

<p></td></tr></tr></table>
</p>

<h2>Import Settings</h2>

<p>Textures all come from image files in your project folder. How they are imported is specified by the texture's import settings. You change these by selecting the file texture in the project window and clicking the import settings button on the toolbar above:
</p>

<p><img class='figure' src='images/Textures-1.jpg' />
</p>

<p>This brings up the import settings dialog:
</p>

<p><img class='figure' src='images/Textures-2.jpg' />
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Max. Texture Size</nobr></b></td><td> The maximum imported texture size. A lot of artists prefer to work with huge textures - scale the texture down to a suitable size with this.
</td></tr><tr><td><b><nobr>Texture Format</nobr></b></td><td> What internal representation is used for the texture. This is a tradeoff between size and quality. In the examples below we show the final size of a in-game texture of 256 by 256 pixels.

<dl><dt>RGB Compressed DXT1</dt><dd> Compressed RGB texture. This is the most common format for diffuse textures. 4 bits per pixel (32 KB for a 256x256 texture).</dd><dt>RGBA Compressed DXT3</dt><dd> Compressed RGBA texture. Provides a different compression method for alpha. Usually DXT5 looks better. 1 byte/pixel (64 KB for a 256x256 texture).</dd><dt>RGBA Compressed DXT5</dt><dd> Compressed RGBA texture. This is the main format used for diffuse &amp; specular control textures. 1 byte/pixel (64 KB for a 256x256 texture).</dd><dt>RGB 16 bit</dt><dd> 65 thousand colors with no alpha. Compressed DXT formats use less memory and usually look better. 128 KB for a 256x256 texture.</dd><dt>RGB 24 bit</dt><dd> Truecolor but without alpha. 192 KB for a 256x256 texture.</dd><dt>Alpha 8 bit</dt><dd> High quality alpha channel but without any color. 64 KB for a 256x256 texture.</dd><dt>RGBA 16 bit</dt><dd> Low-quality truecolor. Has 16 levels of red, green, blue and alpha. Compressed DXT3/5 formats use less memory and usually look better. 128 KB for a 256x256 texture.</dd><dt>RGBA 32 bit</dt><dd> Truecolor with alpha - this is the highest quality. At 256 KB for a 256x256 texture, this one is expensive. Most of the time, <b>DXT5</b> offers sufficient quality at a much smaller size. The main place this is used is for bump maps, as DXT compression there often carries a visible quality loss.</dd></dl>
</td></tr><tr><td><b><nobr>Build Alpha From Grayscale</nobr></b></td><td> If enabled, an alpha transparency channel will be generated by the image's existing values of light &amp; dark.
</td></tr><tr><td><b><nobr>Scale NonPower2 Sizes Up</nobr></b></td><td> If enabled on textures that have non-power-of-two sizes, this will scale texture up to the nearest power-of-two size at import time. For more info see Texture Sizes section below.
</td></tr><tr><td><b><nobr>Generate Cube Map</nobr></b></td><td> Generates a cubemap from the texture using different generation methods.
</td></tr><tr><td><b><nobr>Generate Mip Maps</nobr></b></td><td> Select this to enable mip-map generation. Mip maps are smaller versions of the texture that gets used when the texture is very small on screen. For more info, see Mip Maps, below.
</td></tr><tr><td><b><nobr>Correct Gamma</nobr></b></td><td> Select this to enable per-mip-level gamma correction.
</td></tr><tr><td><b><nobr>Border Mip Maps</nobr></b></td><td> Select this to avoid colors seeping out to the edge of the lower Mip levels. Used for light cookies (see below).
</td></tr><tr><td><b><nobr>Mip Map Filtering</nobr></b></td><td> 3 ways of mip map filtering is available to optimize image quality
<dl><dt>Box</dt><dd> The simplest way to fade out the mipmaps - the mip levels become smoother and smoother as they go down in size.</dd><dt>Kaiser</dt><dd> A sharpening Kaiser algorithm is run on the mip maps as they go down in size.</dd></dl>
By default, Box mode is selected. If your textures are to blurry in the distance, try some of the other options and see if they work. This is not an exact science, so play around and see what works for different textures.

</td></tr><tr><td><b><nobr>Fade Out Mips</nobr></b></td><td> Enable this to make the mipmaps fade to gray the mip levels progress. This is used for detail maps.
</td></tr><tr><td><b><nobr>Fade Out start</nobr></b></td><td> The first mip level to begin fading out at.
</td></tr><tr><td><b><nobr>Fade Out End</nobr></b></td><td> The mip level where the texture is completely grayed out
</td></tr><tr><td><b><nobr>Generate  Bump Map</nobr></b></td><td> Enable this to turn the color channels into a format suitable for real-time bumpmapping. For more info, see Bump Maps, below...
</td></tr><tr><td><b><nobr>Bumpyness</nobr></b></td><td> Increase the amount of bumpyness.
</td></tr><tr><td><b><nobr>Filtering</nobr></b></td><td> Determine how the bumpyness is calculated
<dl><dt>Standard</dt><dd> This generates normal maps that are smoother than with a sobel filter</dd><dt>Sobel</dt><dd> The solber filter generates normal maps that are sharper than Standard. </dd></dl>

<p></td></tr></tr></table>
</p>

<h2> Details</h2>

<h3> Supported Formats</h3>
<p>Unity can read the following file formats: PSD, TIFF, JPG, TGA, GIF, PNG,  BMP, IFF, PICT. It should be noted that Unity can import multi-layer PSD &amp; TIFF files just fine. They are flattened automatically on import but the layers are maintained in the assets themselves, so you don't lose any of your work when using these file types natively. This is important as it allows you to just have one copy of your textures that you can use from Photoshop, through your 3D modelling app and into Unity.
</p>

<h3> Texture Sizes</h3>
<p>Ideally texture sizes should be powers of two on the sides. These sizes are as follows: 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024 or 2048 pixels. The textures do not have to be square, i.e. width can be different from height.
</p>

<p>It is possible to use other (non power of two) texture sizes with Unity. Non power of two texture sizes work best when used on <a href="../Components/class-GuiTexture.html">GUI Textures</a>, however if used on anything else they will be converted to an uncompressed RGBA 32 bit format. That means they will take up more video memory (compared to DXT compressed textures) and will be slightly slower to load. In general you'll use non power of two sizes only for making GUI.
</p>

<p>Non power of two texture assets can be scaled up at import time using a <i>Scale NonPower2 Sizes Up</i> option in the import settings. Then Unity will scale texture contents up to the next power of two, and in the game they will behave just like any other texture. So they can still be compressed and very fast to load.
</p>

<h3> UV Mapping</h3>
<p>When mapping a 2D texture on to a 3D model, some sort of wrapping is done. This is called UV mapping and is done in your 3D modelling app. Inside Unity, you can scale and move the texture using <a href="../Components/class-Material.html">Materials</a>. Scaling bump &amp; detail maps are especially useful
</p>

<h3> Mip Maps</h3>
<p>Mip Maps are a list of progressively smaller versions of an image, used optimise performance on real-time 3D engines. Object that are far away from the camera use the smaller textures. Using mip maps uses 33% more memory, but not using mipmaps can be a huge performance loss. You should always you mipmaps for in-game textures; the only exceptions are textures that will never be minified (e.g. GUI textures).
</p>

<h3> Bump Maps</h3>
<p>Bump maps are used by bump map shaders to make low-polygon models look as if they contain more detail. Unity uses normal maps encoded as RGB images. You also have the option to generate a normal map from a grayscale height map image.
</p>

<h3> Detail Maps</h3>
<p>If you want to do a terrain, you normally use your main texture to show where there are grass, rocks sand, etc... If your terrain has a decent size, you will end up with a very blurry terrain. <a href="../Manual/HOWTO-UseDetailTexture.html">Detail textures</a> hide this fact by fading in small details as your main texture get up close.
</p>

<p>When drawing detail textures, a neutral gray is invisible, white makes the main texture twice as bright and black makes the main texture completely black.
</p>

<h3> Cube Maps</h3>
<p>If you want to use texture for reflection maps (e.g. use <i>Reflective</i> builtin shaders), you need to use <a href="../Components/class-CubemapTexture.html">Cubemap Textures</a>.
</p>

<h3> Light Cookies</h3>
<p>An interesting way to add a lot of visual detail to your scenes is to use cookies - greyscale textures you use to control the precise look of in-game lighting. This is fantastic for making moving clouds and giving an impression of dense foilage. The <a href="../Components/class-Light.html">Light</a> page has more info on all this, but the main thing is that for textures to be usable for cookies, the following properties need to be set:
</p>

<p>For <i>spotlight</i> cookies, use the following settings:
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Texture Format</nobr></b></td><td> Any setting that has an alpha channel</td></tr><tr><td><b><nobr>Build Alpha from RGB Grayscale</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Generate Mip Maps</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Border Mip Maps</nobr></b></td><td> Enabled
</td></tr></tr></table>
You should keep the edges of you cookie texture solid black in order to get the proper effect. In the texture inspector, set the Edge Mode to <b>Clamp</b>.
</p>

<p>For <i>directional</i> lights, use the following settings:
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Texture Format</nobr></b></td><td> Any setting that has an alpha channel</td></tr><tr><td><b><nobr>Build Alpha from RGB Grayscale</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Generate Mip Maps</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Border Mip Maps</nobr></b></td><td> Disabled
</td></tr></tr></table>
This texture will tile, so in the texture inspector, you must set the Edge Mode to <b>Repeat</b>.
</p>

<p>For <i>point</i> lights, you need to use <b>Cube Maps</b>. To generate one, either make six textures and assign them as detailed in <a href="../Components/class-CubemapTexture.html">Cubemap Textures</a> or generate on with the following settings:
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Texture Format</nobr></b></td><td> Any setting that has an alpha channel</td></tr><tr><td><b><nobr>Generate Cube Map</nobr></b></td><td> Any other setting than <b>None</b>.
</td></tr><tr><td><b><nobr>Build Alpha from RGB Grayscale</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Generate Mip Maps</nobr></b></td><td> Enabled
</td></tr><tr><td><b><nobr>Border Mip Maps</nobr></b></td><td> Disabled
</td></tr></tr></table>
</p>



<p>Unity has an extensive Shader system, allowing you to tweak the look of all in-game graphics. It works like this:
</p>

<p>A Shader basically defines a formula for how the in-game shading should look. Within any given Shader is a number of properties (typically textures). Shaders are implemented through <b>Materials</b>, which are attached directly to individual Game Objects.  Within a Material, you will choose a Shader, then define the properties (usually textures and colors but properties can vary) that are used by the Shader.
</p>

<p>As this is rather complex, a graph is in order:
</p>

<p><img class='figure' src='images/Materials-0.jpg' />
</p>

<p>On the left side of the graph is the <i>Carbody Shader</i>. 2 different Materials are created from this: <i>Blue car Material</i> and <i>Red car Material</i>. Each of these Materials have 2 textures assigned; the <i>Car Texture</i> defines the main texture of the car, and a <i>Color FX texture</i>. These properties are used by the shader to make the car finish look like 2-tone paint. This can be seen on the front of the red car: it is yellow where it faces the camera and then fades towards purple as the angle increases. The car materials are attached to the 2 cars. The car wheels, lights and windows don't have the color change effect, and must hence use a different Material. At the bottom of the graph there is a <i>Simple Metal Shader</i>. The <i>Wheel Material</i> is using this Shader. Note that even though the same <i>Car Texture</i> is reused here, the end result is quite different from the car body, as Shader used in the Material is different .
</p>

<p><i>Note: Quite a few textures, Shaders &amp; Materials were left out from this diagram in order to avoid clutter.</i>
</p>

<p>To be more specific, a Shader defines:
</p>
<ul><li> The method to render an object. This includes using different methods depending on the graphics card of the end user.
</li><li> Any vertex and fragment programs used to render.
</li><li> Some texture properties that are assignable within Materials.
</li><li> Color and number settings that are assignable within Materials.
</li></ul>

<p>A Material defines:
</p>
<ul><li> Which textures to use for rendering.
</li><li> Which colors to use for rendering.
</li><li> Any other assets, such as a Cubemap that is required by the shader for rendering.
</li></ul>

<p>Shaders are meant to be written by graphics programmers. They are written using the ShaderLab language, which is quite simple. However, getting a shader to work well on a variety graphics cards is an involved job and requires a fairly comprehensive knowledge of how graphics cards work.
</p>

<p>A number of shaders are built into Unity directly, and some more come in the <a href="../Manual/HOWTO-InstallStandardAssets.html">Standard Assets</a> Library.
</p>


<h2>Making new Materials</h2>

<p>To make a new Material, either:
</p>
<ul><li> Right-click on a Shader in the Project view and select <b>Create-&gt; Material</b>
</li><li> Select an existing material and choose duplicate from the edit menu.
</li><li> Drag a texture onto a mesh. This automatically creates the material in the 'Materials' folder next to the texture.
</li></ul>

<h2>Setting Material Properties</h2>

<p>When you select an object in the scene, you can pick the Material from the object's <i>Renderer</i> component in the Inspector, or dragging a Material to the object from the library. After doing this, the Material inspector shows up. First it shows the shader used by this material, then all material properties are listed. Currently the properties can be colors, sliders, textures, numbers and vectors. As you change these, you can see the changes to the scene updated in real-time.
</p>

<p><img class='figure' src='images/Materials-1.jpg' />
</p>

<p>To assign a texture, drag one from the project view over one of the texture buttons, or click &quot;Select&quot; and choose from a list. To edit the mapping options for the texture, click the &quot;Placement&quot; button. Mapping optons will fold out:
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Offset</nobr></b></td><td> Slides the texture around
</td></tr><tr><td><b><nobr> Scale</nobr></b></td><td> Scales the texture along the different axes
<p></td></tr></tr></table>
</p>

<h2>Changing The Shader of a Material</h2>
<p>Sometimes, you wish to change the shader being used by a material. In order to do so, simply expand the <b>Shader</b> drop-down in the Material inspector, and choose your new shader.  Unity will carry across any properties that the shaders share. All shaders that ship with Unity have been constructed with this in mind, so most of the time you can just replace a shader and see the effect.
</p>

<h2>Builtin Shaders</h2>

<p><img class='figure' src='images/Materials-2.jpg' />
</p>

<p><i>The builtin Unity shaders matrix</i>
</p>

<p>Unity comes with 30+ ready to use shaders. They can be grouped by purpose:
<dl><dt>Normal</dt><dd> Use for opaque textured objects.</dd><dt>Transparent</dt><dd> Use for partly transparent objects. Texture's alpha channel defines the level of tranparency.</dd><dt>Self-Illuminated</dt><dd> Use for objects that have light emitting parts.</dd><dt>Reflective</dt><dd> Use for opaque textured objects that reflect an environment cubemap.</dd><dt>Lightmapped</dt><dd> Use for objects that have an additional <i>lightmap</i> texture and corresponding texture coordinate channel.</dd></dl>
In each group, builtin shaders range by complexity, from the simple <i>VertexLit</i> to the complex <i>Parallax Bumped with Specular</i>.
</p>



<p>Adding sound to a game is one of the final touches that make a game feel like a complete product. Be it nerve-wrecking sound effects or thumping background music, they are seen by Unity as Audio Clips.
</p>

<p>See the <a href="../Manual/Sound.html">Sound chapter</a> in the &quot;Creating Gameplay&quot; section of this manual for more information on how to use sound in Unity.
</p>

<h1>Audio Clip</h1>

<p>Audio Clips are used by <a href="../Components/class-AudioSource.html">Audio Sources</a> to represent the audio asset imported into Unity.
</p>

<p><img class='figure' src='images/Audio Files-0.jpg' />
</p>

<p><i>The Audio Clip</i>
</p>

<p>Audio Clips just work.  The only thing you should have to do with them is reference them from within <a href="../Components/class-AudioSource.html">Audio Sources</a>.
</p>

<h2>Properties</h2>
<p>Sound assets only have 3 read-only properties.
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Format </nobr></b></td><td> The format the sound is stored in. Unity supports 4 raw formats and one compressed.
<dl><dt>Mono 8 bit</dt><dd> 8 bit uncompressed mono PCM audio</dd><dt>Mono 16 bit</dt><dd> 16 bit uncompressed mono PCM audio</dd><dt>Stereo 8 bit</dt><dd> 8 bit uncompressed stereo PCM audio</dd><dt>Stereo 16 bit</dt><dd> 16 bit uncompressed stereo PCM audio</dd><dt>Ogg Vorbis</dt><dd> Ogg Vorbis encoded stereo or mono audio</dd></dl>
</td></tr><tr><td><b><nobr>Length</nobr></b></td><td> The duration of the sound file in seconds.
</td></tr><tr><td><b><nobr>Frequency</nobr></b></td><td> The sampling frequency of the file.
</td></tr></tr></table>
</p>

<h2>Supported sound formats</h2>
<p>Unity currently supports the following file formats:
</p>

<p><dl><dt><b>AIFF</b></dt><dd> Both mono and stereo. The sound will be stored as-is inside the player-data. No compression will be attempted.</dd><dt><b>WAV</b></dt><dd> Both mono and stereo. The sound will be stored as-is inside the player-data. No compression will be attempted.</dd><dt><b>MP3</b></dt><dd> Mono and stereo. Note that the audio will be uncompressed in the editor and stored uncompressed in the player. If you want to conserve space, use Ogg Vorbis files instead.</dd><dt><b>Ogg Vorbis</b></dt><dd> Both mono and stereo. The file will be stored compressed in the player-data and streamed on the fly. When using Ogg vorbis it is recommended to always use 44khz frequency.</dd></dl>
</p>

<h2> Stereo or Mono?</h2>
<p>Stereo sounds are always played as is. They are not faded out over distance and they do not have panning. This makes them optimal for music and ambient sources.
</p>

<p>Mono sounds always fade out over distance and do panning. This is good for all effects requiring 3D positional sound.
</p>

<h2> Choosing the right format</h2>

<p>For music you should always use the ogg vorbis format. The frequency should be 44khz and it should be stereo. (44 khz is recommended since playback will be faster than with 22khz)
</p>

<p>Short audio clips  (eg. foot steps, bullet explosion) you should use <b>AIFF</b> or <b>WAV</b> with mono and either 22khz or 11khz. Usually you should not use 44khz since that takes up too much disk space and the quality difference is not hearable.
</p>

<p>Long audio clips should use ogg vorbis and mono. A good rule of thumb is that if a sound file is more than 200k uncompressed, then it makes sense to use ogg vorbis and stream the sound instead (when using ogg vorbis, always choose 44khz).
</p>

<h2>Hints</h2>
<p><ul><li>
Stereo sounds are always played as-is. If you want to use attenuation and other 3D audio effects, use mono sounds.
</li><li>You can get a free Ogg Vorbis converter from <a class="wiki"  href="http://sbooth.org/Max">http://sbooth.org/Max</a> (Mac) or from <a class="wiki"  href="http://www.rarewares.org/ogg.html">http://www.rarewares.org/ogg.html</a> (Windows)
</li></ul>
</p>




<p>This is a short introduction on how to add and scripts in a project.  For detailed information including the scripting API, please view the <a class="wiki"  href="../ScriptReference/index.html">Scripting Reference</a>.
</p>

<p>Scripting inside Unity is done by writing simple behaviour scripts in JavaScript, C# or Boo. You can use one or all scripting languages in a single project, there is no penalty for using more than one. This manual addresses scripting with JavaScript unless specifically stated otherwise.
</p>


<h2>Creating new scripts</h2>
<p>To create a new script, open the <b>Assets -&gt; Create -&gt; JavaScript</b> (or C Sharp Script or Boo Script) from the main menu. This will create a new script called <b>NewBehaviourScript</b> and place it in the selected folder in Project View.  If no folder is selected in Project View, the script will be created at the root level.
</p>

<p><img class='figure' src='images/Scripting-0.jpg' />
</p>

<p>You can edit the script by double-clicking on it in the Project View.  This will launch <b>Unitron</b>, the script editor for Unity.
</p>

<p>These are the contents of a new, empty behaviour script:
<pre class='codelisting'>
function Update () {
}
</pre>
</p>

<p>A new, empty script does not do a lot on its own, so let's modify it a bit:
<pre class='codelisting'>
function Update () {
    print(&quot;Hello World&quot;);
}
</pre>
</p>

<h2>Attaching scripts to objects</h2>

<p>Save the above script and create a new object in a scene by opening <b>GameObject -&gt; Create Other -&gt; Cube</b>. This will create a cube Game Object in the scene.
</p>

<p><img class='figure' src='images/Scripting-1.jpg' />
</p>

<p>Now attach the script to the cube object either by dragging the script from the Project View onto the cube object (in the Scene or Hierarchy View) or by selecting the cube and then choosing the script from the <b>Component -&gt; Scripts -&gt; New Behaviour Script</b>.  If you have changed the name of your script, you will see the name you chose appear in the menu.
</p>

<p><img class='figure' src='images/Scripting-2.jpg' />
</p>

<p>Now, if you select the cube and look at the inspector, you will see that the script is now visible.
</p>

<p><img class='figure' src='images/Scripting-3.jpg' />
</p>

<p>Press Play to test your creation. You should see the text &quot;Hello World&quot; appear beside the Play/Pause/Step buttons. Exit play mode when you see it.
</p>

<p><img class='figure' src='images/Scripting-4.jpg' />
</p>

<h1>Manipulating the object</h1>

<p>A print statement like in above example, can be very handy when debugging your script, but this one is not doing anything to the cube it is attached to. Let's change the script to make the cube rotate slowly around its Y axis.
</p>

<p><pre class='codelisting'>
function Update () {
    transform.Rotate(0, 5*Time.deltaTime, 0);
}
</pre>
</p>

<p>So what's all this about? The line that has replaced the print statement first fetches the cube object's <b>Transform</b> and then tells it to rotate 0 degrees around its X axis, 5 around the Y axis and 0 around the Z axis every second. We multiply the number of degrees with <b>Time.deltaTime</b> in order to make the rotation speed consistent on different machines with different frame rates. Remember that the Update function is called on every frame and this variable contains the number of seconds since last time it got called.
</p>

<p>To find out which values you can modify, a good starting point is to look on the Inspector window of an object. There you'll see a list of <b>Components</b>, with each Component having a number of <b>Properties</b>. As a rule of thumb, you can modify these properties using the Component.property syntax. So if you add a <b>Rigidbody</b> to the cube (making it affected by physics object), you can change the mass of the cube's Rigidbody from scripting by assigning a value to rigidBody.mass.
</p>

<h2>Adding Variables</h2>

<p>When playing around with the above script, you might want to adjust the speed of rotation. This can be done by modifying the script directly, but requires Unity to recompile it every time. Also if you attach the script to multiple objects they will all rotate in the same way.
</p>

<p>To get around this, you can add variables to your script.
</p>

<p><pre class='codelisting'>
var speed = 5.0;

function Update () {
    transform.Rotate(0, speed*Time.deltaTime, 0);
}
</pre>
</p>

<p>Note that after recompiling, the speed variable shows up in the cube's Inspector.
</p>

<p><img class='figure' src='images/Scripting-5.jpg' />
</p>

<p>Hit Play and try modifying the value inside the Inspector while the game is running. The speed will change instantly.
</p>

<h2>Where to go from here</h2>

<p>This was just a short introduction on how to use scripts inside the Editor. For more examples, check out the Script Tutorial project that comes with Unity. You could also read through <a class="wiki"  href="../ScriptReference/index.html">Scripting Overview</a> inside the Script Reference, which contains a more thorough introduction into scripting with Unity plus pointers into the reference itself for in-depth information. Also take a look at the <a class="wiki"  href="http://forum.unity3d.com">Unity Forums</a>.
</p>





<p><i>&quot;The happiest man is he who best understands the art of finding happiness without letting it encroach upon his duties.&quot;</i>
</p>

<p><i>&ndash; Giacomo Casanova (1725-1798), voicing an early version of the game-design maxim of balancing frustration and reward.</i>
</p>

<p>Unity empowers game designers to make games.  What's really special about Unity is that you don't need years of experience with code or a degree in art to make fun games.  There are a handful of basic workflow concepts provided by Unity, and if you learn how to use them, you will find yourself making games in no time.  With the time you will save getting your games up and running, you will have that much more time to refine, balance, and tweak your game to perfection.
</p>

<p>This section will explain the core concepts you need to know for creating unique, amazing, and fun gameplay.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Instantiating Prefabs.html">Instantiating Prefabs</a></li><li class="toclevel"><a href="../Manual/Input.html">Input</a></li><li class="toclevel"><a href="../Manual/Transforms.html">Transforms</a></li><li class="toclevel"><a href="../Manual/Physics.html">Physics</a></li><li class="toclevel"><a href="../Manual/Animation.html">Animation</a></li><li class="toclevel"><a href="../Manual/Character-Animation.html">Character-Animation</a></li><li class="toclevel"><a href="../Manual/Sound.html">Sound</a></li><li class="toclevel"><a href="../Manual/Game Interface Elements.html">Game Interface Elements</a></li></ul>
</p>



<p>Hopefully by now you understand the concept of <a href="../Manual/Prefabs.html">Prefabs</a>.  They are a collection of pre-defined Game Objects &amp; Components that are re-usable throughout your game.  Prefabs come in very handy when you want to instantiate complicated Game Objects at runtime.  The alternative to instantiating Prefabs is to create Game Objects from scratch using code.  Instantiating Prefabs has many advantages over this.  Let's look at some examples.
</p>

<ol><li> Building a wall out of a single &quot;brick&quot; Prefab by instantiating it several times in different positions.
</li><li> A rocket launcher instantiates a rocket Prefab when the user presses fire. The Prefab contains the mesh, a rigidbody, collider, and a child Game Object that contains a trail particle system.
</li><li> A robot exploding to many pieces. The complete, operational robot is destroyed and replaced with a wrecked robot Prefab. This Prefab would consist of the robot split into many parts, all set up with rigidbodies and particle systems of their own. This technique allows you to blow up a robot into many pieces, with 1 line of code, replacing one object with a Prefab.
</li></ol>

<p>Instantiating Prefabs instead of building new Game Objects from code has huge advantages:
</p>
<ul><li> You can set up and modify the Prefab quickly &amp; easily in the Scene &amp; Inspector.
</li><li> You can change the Prefab being instanced without changing the code that instantiates it. A simple rocket might become a super-charged rocket, and you don't have to change the existing code.
</li></ul>

<h2>Building a wall</h2>

<p>Let's compare creating objects from code and using prefabs by building a brick wall.
</p>

<p>First lets build a brick wall from code:
<pre class='codelisting'>
function Start ()
{
   for (var y=0;y&lt;5;y++)
   {
        for (var x=0;x&lt;5;x++)
        {
            var cube = GameObject.CreatePrimitive(PrimitiveType.Cube);
            cube.transform.position = Vector3 (x, y, 0);
            cube.AddComponent(Rigidbody);
        }
   }
}
</pre>
</p>

<p>Now lets say you want to start tweaking values. For example you might want to assign a different texture, a different color, change friction and change the mass of the rigidbody. You can do all those things in one line of code but when you want to tweak a lot of things you will still end up with 6 lines of code. Plus tweaking a value takes longer if you have to type it, instead of edit a value in the inspector.
</p>

<p>The point is once you go beyond the basics, creating everything completely from code becomes unmanagable very quickly.
</p>

<p>So why not just create one of those cubes in the Editor, adjust all the values until they are right, add any Components we like, and instantiate a bunch of them?
</p>

<p>This is the script necessary to create our stack.
<pre class='codelisting'>
var cube : Transform;
function Start ()
{
   for (var y=0;y&lt;5;y++)
   {
        for (var x=0;x&lt;5;x++)
        {
            var cube = Insantiate(cube, Vector3 (x, y, 0), Quaternion.identity);
        }
   }
}
</pre>
</p>

<p>Now this is not only very clean but also very reusable. There is nothing saying we are instantiating a cube or that it must contain a rigidbody. All of this is defined in the Prefab and can be quickly created in the Editor.
</p>

<p>Now we only need to create the Prefab, which we do in the Editor
</p>
<ol><li> Choose <b>Game Object -&gt; Create Other -&gt; Cube</b>
</li><li> Choose <b>Component -&gt; Physics -&gt; Rigidbody</b>
</li><li> Choose <b>Assets -&gt; Create Prefab</b>
</li><li> Drag the cube you created in the Hierarchy View onto the empty Prefab that was created in the Project View.
</li></ol>

<ul><li> To use the above script we simply drag the script onto an empty Game Object.
</li><li> Then we select the Game Object that contains the script and drag the Prefab onto the cube variable in the Inspector.
</li></ul>

<p>This is a workflow pattern that can be used over and over again in Unity. In the beginning you might wonder why this is so much better, because the script creating the cube from code is only 2 lines longer.
</p>

<p>But because you are using a Prefab now, you can adjust the Prefab in seconds. Want to change the mass of all those instances? Adjust the Rigidbody in the Prefab only once. Want to use a different Material for all the instances?  Drag the Material onto the Prefab only once. Want to change friction?  Use a different Physic Material in the Prefab's collider. Want to add a particle system to all those boxes?  Add a child to the Prefab only once.
</p>


<h2> Instantiating rockets &amp; explosions:</h2>

<ol><li> A rocket launcher instantiates a rocket Prefab when the user presses fire. The Prefab contains the mesh, a rigidbody, collider, and a child Game Object that contains a trail particle system.
</li><li> The rocket impacts and instantiates an explosion Prefab. The explosion Prefab contains a Particle System, a light that fades out over time, and a script that applies damage to surrounding Game Objects.
</li></ol>

<p>While it would be possible to build a rocket Game Object completely from code, adding Components manually and setting properties, it is far easier to instantiate a Prefab. You can instantiate the rocket in just one line of code, no matter how complex the rocket's Prefab is.  After instantiating the Prefab you can also modify any properties of the instantiated object. E.g. you can set the velocity of the rocket's Rigidbody.
</p>

<p>Aside from being easier to use. You can update the prefab later on. So if you are building a rocket you don't immediately have to add a particle trail to it. You can do that later. As soon as you add the trail as a child Game Object to the Prefab, all your instantiated rockets will have particle trails. And lastly, you can quickly tweak property of the rocket game object in the Inspector, making it far easier to fine tune your game.
</p>

<p>This script shows how to launch a rocket using the <b>Instantiate</b> function.
<pre class='codelisting'>
// Require the rocket to be a rigidbody.
// This way we the user can not assign a prefab without rigidbody
var rocket : Rigidbody;
var speed : 10.0;

function FireRocket () {
    var rocketClone : Rigidbody = Insantiate(rocket, transform.position, transform.rotation);
    rocketClone.velocity = transform.forward * speed;
    // You can also acccess other components / scripts of the clone
    rocketClone.GetComponent(MyRocketScript).DoSomething();
}

// Calls the fire method when holding down ctrl or mouse
function Update () {
    if (Input.GetButtonDown(&quot;Fire1&quot;))
       FireRocket();
}
</pre>
</p>


<h2> Replacing a character with a ragdoll or wreck:</h2>
<p>Let's say you have a fully rigged enemy character and he dies.  You could simply play a death animation on the character and disable all scripts that usually handle the enemy logic. You probably have to take care of removing several scripts, adding some custom logic to make sure that no one will continue attacking the dead enemy anymore, for example.
</p>

<p>A far better approach is to immediately delete the entire character and instantiate a wreck prefab instead of it. This gives you a lot of flexibility. You could use a different material for the dead character, attach completely different scripts, spawn a Prefab containing the object broken into many pieces to simulate a shattered enemy, or simply instantiate a Prefab containing a version of the character.
</p>

<p>Any of these options can be achieved with a single call to instantiate, you just have to hook it up to the right prefab and you are set.
</p>

<p>The important part to remember is that the wreck which you Instantiate can be made of completely different objects that the original. For example, if you have an airplane, you would model two versions. One where the plane consists of a single game object with mesh renderer and scripts for airplane physics. By keeping the model in just one game object your game will run faster since you will be able to make the model with less triangles and since it consists of fewer objects it will render faster than using many small parts. Also while your plane is happily flying around there is no reason to have it in seperate parts.
</p>

<p>To build an airplane wreck prefab the typical steps are:
</p>
<ol><li> Model your air plane with lots of different parts in your favorite modeller
</li><li> Create an empty scene
</li><li> Drag the model into an empty scene
</li><li> Add rigidbodies to all parts, by selecting all the parts and choosing <b>Component -&gt; Physics -&gt; Rigidbody</b>
</li><li> Add box colliders to all parts by selecting all the parts and choosing <b>Component -&gt; Physics -&gt; Box Collider</b>
</li><li> For extra Special FX add a Smoke like Particle system as a child game object to each of the parts
</li><li> Now you have an airplane with multiple exploded parts, they fall to the ground by physics and will create a particle trail due to the attached particle system. Hit Play to preview how your model reacts and do any necessary tweaks.
</li><li> Choose <b>Assets -&gt; Create Prefab</b>
</li><li> Drag the root game object containing all the air plane parts into the prefab
</li></ol>

<p><pre class='codelisting'>
var wreck : GameObject;

// As an example, we turn the game object into a wreck after 3 seconds automatically
function Start ()
{
    yield WaitForSeconds(3);
    KillSelf();
}

// Calls the fire method when holding down ctrl or mouse
function KillSelf () {
    // Instantiate the wreck game object at the same position we are at
    var wreckClone = Instantiate(wreck, transform.position, transform.rotation);

    // Sometimes we need to carry over some variables from this object
    // to the wreck
    wreckClone.GetComponent(MyScript).someVariable = GetComponent(MyScript).someVariable;

    // Kill ourselves
    Destroy(gameObject);
}
</pre>
</p>

<p>The First person shooter tutorial explains how to replace a character with a ragdoll version and also synchronize limbs with the last state of the animation.
</p>


<h2>Placing a bunch of objects in a specific pattern eg. a grid or a circle.</h2>

<p>Lets say you want to place a bunch of objects on a grid or a circle.
</p>

<p>Traditionally this would be done by either:
</p>
<ol><li>Building an object completely from code. Eg. creating an empty game object and adding a component, then setting up all it's properties. This is tedious, entering values from a script is both slow, unintuitive and not worth the hassle.
</li><li>Make the fully rigged object, duplicate it and place it multiple times in the scene. This is tedious, and placing objects accurately in a grid is hard.
</li></ol>

<p>Solution: Use Instantiate. Create one Prefab, the prototype of what you want to create. Call instantiate several times in a loop and place those objects. You can also modify the Prefab components or Game Objects after you have instantiated them
</p>


<p><pre class='codelisting'>
// Instantiates a prefab in a circle
var prefab : GameObject;
var numberOfObjects = 20;
var radius = 5;

function Start ()
{
	for (var i=0;i&lt;numberOfObjects;i++)
	{
		var angle = i * Mathf.PI * 2 / numberOfObjects;
		var pos = Vector3 (Mathf.Cos(angle), 0, Mathf.Sin(angle)) * radius;
		Instantiate(prefab, pos, Quaternion.identity);
	}
}
</pre>
</p>


<p><pre class='codelisting'>
// Instantiates a prefab in a grid
var prefab : GameObject;
var gridX = 5;
var gridY = 5;
var spacing = 2.0;

function Start ()
{
	for (var y=0;y&lt;gridY;y++)
	{
		for (var x=0;x&lt;gridX;x++)
		{
			var pos = Vector3 (x, 0, y) * spacing;
			Instantiate(prefab, pos, Quaternion.identity);
		}
	}
}
</pre>
</p>





<p>Unity supports keyboard, joystick and gamepad input.
</p>

<p>Virtual axes and buttons can be created in the Input inspector and end users can configure keyboard input in a nice screen configuration dialog.
</p>

<p><img class='figure' src='images/Input-0.jpg' />
</p>

<p>You can setup joysticks, joypads, keyboard and mouse buttons and access them all through one simple scripting interface.
</p>

<p>From scripts all virtual axes are accessed by their name.
</p>

<p>Every project has the following default input axes.
&quot;Horizontal&quot; and &quot;Vertical&quot; are mapped to w, a, s, d and the arrow keys.
&quot;Fire1&quot;, &quot;Fire2&quot;, &quot;Fire3&quot; are mapped to control, alt and cmd.
&quot;Mouse X&quot;, &quot;Mouse Y&quot;is mapped to the mouse delta.
&quot;Window Shake X&quot; and &quot;Window Shake Y&quot; is mapped to the movement of the window.
</p>

<h3>Adding new Input Axes</h3>
<p>If you want to add new virtual axes go to the Edit-&gt;Project Settings -&gt; Input menu.
Here you can also change the settings of each axis.
</p>

<p><img class='figure' src='images/Input-1.jpg' />
</p>

<p>You map each Axis either to a Joystick, Mouse or two keyboard buttons.
</p>

<p>There are various parameters like gravity and sensitivity which can be used to fine tune the look and feel of input. They are all documented with tooltips.
</p>

<h3>Using Input Axes from Scripts</h3>
<p>You can query the current state from a script like this:
<pre class='codelisting'>
value = Input.GetAxis (&quot;Horizontal&quot;);
</pre>
An axis has a value between -1 and 1. The neutral position is 0.
This is the case for joystick input and keyboard input.
</p>

<p>However mouse delta and window shake delta is how much the mouse or window moved during the last frame. This means it can be larger than 1 or smaller than -1 when the user moves the mouse quickly.
</p>

<p>It is possible to create multiple Axes with the same name. When getting the input axis, the axis with the largest absolute value will be returned. This makes it possible to assign more than one input device to one Axis name. Eg. Create one axis for keyboard input and one axis for joystick input with the same name. If the user is using the joystick, input will come from the joystick otherwise the keyboard. This way you don't have to think at all about from where the input comes when writing scripts.
</p>

<h3>Button names</h3>

<p>To map a key to an axis you have to enter the key's name in the &quot;Positive Button&quot; or &quot;Negative Button&quot; property in the inspector.
</p>

<p>The names of keys follow this convention:
</p>
<ul><li> Normal keys: &quot;a&quot;, &quot;b&quot;, &quot;c&quot; ...
</li><li> Number keys: &quot;1&quot;, &quot;2&quot;, &quot;3&quot;,  ...
</li><li> Arrow keys: &quot;up&quot;, &quot;down&quot;, &quot;left&quot;, &quot;right&quot;
</li><li> Keypad keys: &quot;[1]&quot;, &quot;[2]&quot;, &quot;[3]&quot;, &quot;[+]&quot;, &quot;[equals]&quot;
</li><li> Modifier keys: &quot;right shift&quot;, &quot;left shift&quot;, &quot;right ctrl&quot;, &quot;left ctrl&quot;, &quot;right alt&quot;, &quot;left alt&quot;, &quot;right cmd&quot;, &quot;left cmd&quot;
</li><li> Mouse Buttons: &quot;mouse 0&quot;, &quot;mouse 1&quot;, &quot;mouse 2&quot;, ...
</li><li> Joystick Buttons (from any joystick): &quot;joystick button 0&quot;, &quot;joystick button 1&quot;, &quot;joystick button 2&quot;,  ...
</li><li> Joystick Buttons (from a specific joystick): &quot;joystick 0 button 0&quot;, &quot;joystick 0 button 1&quot;, &quot;joystick 1 button 0&quot;, ...
</li><li> Special keys: &quot;backspace&quot;, &quot;tab&quot;, &quot;return&quot;, &quot;escape&quot;, &quot;space&quot;, &quot;delete&quot;, &quot;enter&quot;, &quot;insert&quot;, &quot;home&quot;, &quot;end&quot;, &quot;page up&quot;, &quot;page down&quot;
</li><li> Function keys: &quot;f1&quot;, &quot;f2&quot;, &quot;f3&quot;, ...
</li></ul>

<p>The names used to identify the keys are the same in the scripting interface and the inspector.
<pre class='codelisting'>
value = Input.GetKey (&quot;a&quot;);
</pre>
</p>



<p><b>Transforms</b> are a key Component in every Game Object.  They dictate where the Game Object is positioned, how it is rotated, and its scale.  It is impossible to have a Game Object without a Transform.  You can adjust the Transform of any Game Object from the Scene View, the Inspector, or through Scripting.
</p>

<p>The remainder of this page's text is from the <a href="../Components/class-Transform.html">Transform Component Reference</a> page.
</p>

<h1>Transform</h1>
<p>The Transform component determines the physical location, rotation, and scale of all objects in the scene. Every object has a Transform.
</p>

<p><img class='figure' src='images/Transforms-0.jpg' />
</p>

<p><i>The Transform component of the Game Object is viewable and editable in the Inspector</i>
</p>



<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Position</nobr></b></td><td>Position of the Transform in X, Y, and Z coordinates

</td></tr><tr><td><b><nobr>Rotation</nobr></b></td><td>Rotation of the Transform around the X, Y, and Z axes, measured in degrees
</td></tr><tr><td><b><nobr>Scale</nobr></b></td><td>Scale of the Transform along X, Y, and Z axes.  Value &quot;1&quot; is the size at which the object was imported.
<p></td></tr></tr></table>
All properties of a Transform are measured relative to the Transform's parent.  If the Transform has no parent, the properties are measured relative to the World.
</p>



<h2>Using Transforms</h2>
<p>Transforms are always manipulated in 3-D space using X, Y, and Z axes.  In Unity, these axes are represented by the colors red, green, and blue respectively.
</p>

<p><img class='figure' src='images/Transforms-1.jpg' />
</p>

<p><i>Color-coded relationship between 3 axes and Transform properties</i>
</p>

<p>Transform components can be directly manpulated using the Scene view or the Inspector.  The Inspector will list the properties stated above for easy editing.
</p>

<p><img class='figure' src='images/Transforms-2.jpg' />
</p>

<p><i>Translation along the X axis (Left/Right)</i>
</p>

<p><img class='figure' src='images/Transforms-3.jpg' />
</p>

<p><i>Translation along the Y axis (Up/Down)</i>
</p>

<p><img class='figure' src='images/Transforms-4.jpg' />
</p>

<p><i>Translation along the Z axis (Forward/Backward)</i>
</p>

<p>You can also modify Transforms in your Scene by interacting with them, using the Move, Rotate, and Scale tools.  These tools are located in the upper left-hand corner of the Unity UI.
</p>

<p><img class='figure' src='images/Transforms-5.jpg' />
</p>

<p><i>The View, Translate, Rotate, and Scale tools</i>
</p>

<p>The tools will be usable on any object in your scene.  Click on the object, and you will see the tool gizmo appear around it.  Depending on the current tool, the gizmo will look slightly different.  Clicking the object will also cause the Transform component to become visible in the Inspector.  If the Inspector does not display the Transform component or its properties, then you do not have an object highlighted in the scene view.
</p>

<p><img class='figure' src='images/Transforms-6.jpg' />
</p>

<p><i>Different Gizmos for the 3 tools can be directly edited in Scene view</i>
</p>


<p>To manipulate the Transform, click and drag on one of the 3 gizmo axes, you'll notice its color changes to yellow.  As you drag the mouse, you will see the object translate, rotate, or scale along the axis.  When you release the mouse button, you'll notice that the axis remains yellow.  You can click the middle mouse button and drag the mouse to manipulate the Transform around the yellow axis.  To access all 3 axes at once click and drag the center point of all 3 gizmos.
</p>

<p><img class='figure' src='images/Transforms-7.jpg' />
</p>

<p><i>Any individual axis will change yellow when you click on it</i>
</p>



<h3>Parenting</h3>
<p>Parenting is one of the most important concepts to understand when using Unity. It is a method of attaching two or more objects together, creating a &quot;Parent&quot; and a &quot;Child&quot; or &quot;Children&quot;  Each object can have multiple children, but only one parent.
</p>

<p>The principle behind parenting is simple; you can attach objects to each other - just like your arms are attached to your body. When you turn your body, your arms move. An object can only have one parent (just like each of your arms can only be attached to one body), but each object can have many children (your body does have two arms, after all).
</p>

<p><img class='figure' src='images/Transforms-8.jpg' />
</p>

<p><i>Example of the Parenting concept</i>
</p>

<p>In the above example, we say that the arms are parented to the body, and the hands are parented to the arms. The scenes you make in Unity will contain collections of these <i>Transform hierarchies</i>. The topmost parent object is called the <i>Root object</i>. When you move, scale, or rotate a parent, all the changes in its Transform are applied to its children as well.
</p>

<p>You can build compound objects by parenting multiple separate objects together, like the skeletal structure of a human ragdoll. You can also create small yet effective objects with single parents.  For example, if you have a horror game that takes place at night, you can create an effective atmosphere with a flashlight.  To create this object, you would parent a  spotlight Transform to the flashlight Transform.  Then, any alteration of the flashlight Transform will affect the spotlight, creating a convincing flashlight effect.
</p>

<p>Creating and removing parents is performed in the <i>Hierarchy</i> window.  The hierarchy window will display all the objects currently in your scene.  To create a parent, drag the desired child object over the desired parent object in your Hierarchy, and release.  You have then <i>parented</i> your child to its new parent.  To remove the child from its parent, click and drag the child object outside of the parent object.
</p>


<h2>Importance of scale</h2>
<p>The scale of the Transform determines the difference between the size of your mesh in your modeling application, and the size of your mesh in Unity. The mesh's size in Unity (and therefore the Transform's scale) is <span style="text-decoration:underline;">very</span> important, especially  during physics simulation.   There are 3 factors that can determine the scale of your object:
</p>
<ul><li>The size of your mesh in your 3D modeling application
</li><li>The Global scale setting in your <i>Import Settings</i> menu
</li><li>The scale values of your Transform component
</li></ul>

<p>Ideally, you should not adjust the scale of your object in the Transform component.  The best option is to create your models at real-life scale, so you won't have to change your Transform's scale.  The second-best option is to adjust the scale at which your mesh is imported in the <i>Import Settings</i> for your individual mesh.  Certain optimizations occur based on the import size, and instantiating an object that has an adjusted scale value can decrease performance.  For more information, read through the <a href="../Components/class-Rigidbody.html">Rigidbody</a> component's section on optimizing scale.
</p>


<h2>Hints</h2>
<p><ul><li>
When parenting Transforms, make sure the new parent is located at 0,0,0 before applying the child.  This will save you many headaches later.
</li><li>Particle systems are the only type of Transform that are not affected by Scale. In order to scale a particle system, you need to modify the particle emitter, animator and renderer properties.
</li><li>If you are using Rigidbodies for physics simulation, there is some important information about the Scale property to be read on the  <a href="../Components/class-Rigidbody.html">Rigidbody</a> page.
</li><li>You can change the colors of the axes (and other UI elements) from the Unity Menu -&gt; Preferences -&gt; Colors &amp; keys.
</li><li>If you can avoid scaling, avoid scaling.  Try to have the scales of your object finalized in your 3D modeling application, or in the <i>Import Settings</i> of your mesh.
</li></ul>
</p>



<p>Unity has the next-generation Ageia PhysX physics engine built-in. This allows for unique emergent behaviour and is generally very cool.
</p>

<h2>Basics</h2>
<p>To put an object under physics control, simply add a Rigidbody to it. When you do this, the object will be affected by gravity, and can collide with other objects in the world.
</p>

<h3> Rigidbodies</h3>
<p>You use <a href="../Components/class-Rigidbody.html">rigidbodies</a> for things that the player can push around. Eg. crates or loose objects. You can also add <a href="../Components/class-HingeJoint.html">joints</a> to rigidbodies to make the behaviour more complex. For example to make a physical door or a crane with a swinging chain.
</p>

<p>You also use rigidbodies to make vehicles, for example you can make cars using a rigidbody, 4 wheel colliders and a script applying wheel forces based on the user's input.
</p>

<p>You can make airplanes by applying forces to the rigidbody from a script. Or you can create special vehicles or robots by adding various joints and applying forces from scripts.
</p>

<p>Rigidbodies are usually used in combination with <a href="../Components/class-BoxCollider.html">primitive colliders</a>.
</p>

<h3> Kinematic Rigidbodies</h3>
<p>Kinematic rigidbodies are not affected by forces, gravity or collisions. They are driven explicitly by setting the position and rotation of the transform or animating them. They are used to interact with other non-kinematic rigidbodies.
</p>

<p>They are used for three purposes:
</p>
<ol><li>Sometimes you want an object to be under physics control but in another situation to be controlled explicitly from a script or animation. For example you could make an animated character whose bones have rigidbodies attached that are connected with joints for use as a Ragdoll. Most of the time the Ragdoll is under animation control, thus you make the rigidbody kinematic. But when he gets hit you want him to turn into a ragdoll and be affected by physics. Thus you disable the isKinematic property.
</li><li> Kinematic rigidbodies play better with other rigidbodies. For example if you have an animated platform and you want to place some rigidbody boxes on top, you should make the platform a kinematic rigidbody instead of just a collider without rigidbody.
</li><li> You might want to have a rigidbody that is animated and have a real rigidbody follow it using one of the different joints.
</li></ol>

<h3> Static Colliders</h3>
<p>Static colliders are used for level geometry which does not move around much. You add a mesh collider to your already existing graphical meshes. (Even better use the <b>Import Settings</b> Meshes Have Colliders check box)
You can of course move around static colliders but if you move them around a lot you might want to add a kinematic rigidbody.
There are two reasons why you want to make a static collider into a kinematic rigidbody instead:
</p>
<ol><li> Kinematic rigidbodies <a href="../ScriptingConcepts/RigidbodySleeping.html">wake up</a> other rigidbodies when they collide with them.
</li><li> Kinematic rigidbodies apply friction to rigidbodies placed on top of them
</li></ol>

<h3> Character Controllers</h3>
<p>You use <a href="../Components/class-CharacterController.html">character controllers</a> if you want to make a humanoid character. This could be the main character in a third person platformer, FPS shooter or any enemy characters.
</p>

<p>These controllers don't follow the rules of physics since it will not feel right. (In Doom you run 90 miles per hour, come to halt in one frame and turn on a dime). Instead a character controller performs collision detection to make sure your characters can slide along wall, walk stairs.
</p>

<p>Character Controllers are not be affected by forces but they can push rigidbodies by applying forces to them from a script. Usually all humanoid characters are implemented using Character Controllers.
</p>

<p>Character controllers are inherently unphysical, thus if you want to apply real physics - Swing on ropes, get pushed by big rocks - to your character you have to use a rigidbody, this will let you use joints and forces on your character. But be aware that tuning a rigidbody to feel right for a character is hard due to the unphysical way in which game characters are expected to move.
</p>

<h1>Rigidbody</h1>
<p>Rigidbodies are the gateway for applying physics to your objects. The Rigidbody can receive forces and torque to make your objects move in a realistic way.  Any GameObject must contain a Rigidbody to be influenced by gravity, act under added forces via scripting, or interact with other objects through the Ageia physX physics engine.
</p>

<p><img class='figure' src='images/Physics-0.jpg' />
</p>

<p><i>A GameObject with a Rigidbody component attached</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Mass</nobr></b></td><td> The weight of the object in kilogram. For stable simulation it is recommended to make masses not more or less than 100 times that of other rigid bodies.
</td></tr><tr><td><b><nobr>Drag</nobr></b></td><td> How much air resistance affects the object when moving from forces. 0 means no air resistance, and infinity makes the object stop moving immediately.
</td></tr><tr><td><b><nobr>Angular Drag</nobr></b></td><td> How much air resistance affects the object when rotating from torque. 0 means no air resistance, and infinity makes the object stop rotating immediately.
</td></tr><tr><td><b><nobr>Use Gravity</nobr></b></td><td> If checked, the object is affected by gravity.
</td></tr><tr><td><b><nobr>Is Kinematic</nobr></b></td><td> If checked, the object will not be driven by the physics engine, but can only be manipulated by its Transform. This is useful for moving platforms or if you want to animate a Rigidbody that has a Hinge Joint attached.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>Rigidbodies allow your GameObjects to act under control of the physics engine.  This opens the gateway to realistic collisions, varied types of joints, and other very cool behaviors.  Manipulating your objects by adding forces to a Rigidbody creates a very different feel and look than adjusting the Transform property directly.  Generally, you shouldn't manipulate the Rigidbody and the Transform of the same object &mdash; just one or the other.
</p>

<p>The biggest difference between manipulating the Transform or the Rigidbody is the use of forces.  Rigidbodies can receive forces and torque, but Transforms cannot.  Transforms can be translated and rotated, but this is not the same as using physics. You'll notice the distinct difference when adding you try it for yourself.  Adding forces/torque to the Rigidbody will actually change the object's position and rotation of the Transform component.  This is why you should only be using one or the other.  Changing the Transform while using physics could cause problems with collisions and other calculations.
</p>

<p>Rigidbodies must be explicitly added to your game object before they will be affected by the physics engine.  You can add a Rigidbody to your selected object from <i>Components-&gt;Dynamics-&gt;Rigidbody</i>. Now your object is physics-ready; it will fall under gravity and can receive forces via scripting, but you may want to add a Collider or a Joint to get it to behave exactly how you want.
</p>

<h3> Parenting</h3>
<p>When an object is under physics control, it moves semi-independently of the way its transform parents move. If you move any parents, they will pull the Rigidbody child along with them. However, the Rigidbodies will still fall down due to gravity and react to collision detection.
</p>

<h3> Scripting</h3>
<p>To control your Rigidbodies, you will primarily use scripts to add forces or torque. You do this by calling <a class="wiki"  href="../ScriptReference/Rigidbody.AddForce.html">AddForce</a> and <a class="wiki"  href="../ScriptReference/Rigidbody.html#AddTorque">AddTorque</a> on the object's Rigidbody.  Remember that you shouldn't be directly altering the object's Transform when you are using physics.
</p>

<h3>Animation</h3>
<p>For some situations, mainly creating ragdoll effects, it is neccessary to switch control of the object between animations and physics. For this purpose Rigidbodies can be marked <a class="wiki"  href="../ScriptReference/Rigidbody-isKinematic.html">Kinematic</a>. While the Rigidbody is marked Kinematic, it will not be affected by collisions, forces, or any other part of the physics engine. This means that you will have to control the object by manipulating the <a href="../Components/class-Transform.html">Transform</a> component directly.  Kinematic Rigidbodies will affect other objects, but they themselves will not be affected by physics. For example, Joints which are attached to Kinematic objects will constrain any other Rigidbodies attached to them and Kinematic Rigidbodies will affect other Rigidbodies through collisions.
</p>

<h3>Colliders</h3>
<p>Colliders are another kind of component that must be added alongside the Rigidbody in order to allow collisions to occur.  If two Rigidbodies bump into each other, the physics engine will not calculate a collision unless both objects also have a Collider attached.  Collider-less Rigidbodies will simply pass through each other during physics simulation.
</p>

<p><img class='figure' src='images/Physics-1.jpg' />
</p>

<p><i>A Rigidbody with a Collider component attached</i>
</p>

<p>Add a collider with the Component -&gt; Dynamics menu.  View the Component page of any individual Collider for more specific information:
</p>
<ul><li><a href="../Components/class-BoxCollider.html">Box Collider</a> - primitive shape of a cube
</li><li><a href="../Components/class-SphereCollider.html">Sphere Collider</a> - primitive shape of a sphere
</li><li><a href="../Components/class-CapsuleCollider.html">Capsule Collider</a> - primitive shape of a capsule
</li><li><a href="../Components/class-MeshCollider.html">Mesh Collider</a> - creates a collider from the object's mesh, cannot collide with another Mesh Collider
</li><li><a href="../Components/class-WheelCollider.html">Wheel Collider</a> - specifically for creating cars or other moving vehicles
</li></ul>



<h3>Compound colliders</h3>

<p>Compound Colliders are combinations of primitive Colliders, all together acting as a single Collider.  They come in handy when you have a complex mesh to use in collisions, but cannot use a Mesh Collider.  To create a Compound Collider, create child objects of your colliding object, then add a primitive Collider to each child object.  This allows you to position, rotate, and scale each Collider easily and independently of each other.
</p>

<p><img alt="" src=""img/wiki_up/RigidBody" border="0"  />
</p>

<p><i>A GameObject with a Rigidbody and multiple colliders attached</i>
</p>

<p>In the above picture, the terrain has a Mesh Collider attached.  Mesh Colliders work the best for terrain or environments made from irregular shapes. The Rigidbody has 3 child Colliders attached: capsule, cube and sphere. When Play mode begins, the Rigidbody falls due to gravity, and the 3 child Colliders fall with it. The 3 Collision primitives collide with the Mesh Collider, and the Rigidbody eventually balances and comes to rest on the 3 Colliders.
</p>

<p>Keep in mind, Mesh Colliders can't collide with each other, so the typical solution is to use primitive Colliders for any objects that move, and Mesh Colliders for static background objects.
</p>




<h2>Use the right size</h2>
<p>The size value of the your object's mesh is much more important than the mass of the Rigidbody.  If you find that your Rigidbody is not behaving exactly how you expect; it moves slowly, 'floats', or doesn't collide correctly; consider adjusting the scale of your mesh and/or the Rigidbody's <a href="../Components/class-Transform.html">Transform</a>.  Unity's default unit scale is 1 unit = 1 meter, so the scale of your imported mesh is maintained, and applied to physics calculations.  For example, a crumbling skyscraper is going to fall apart very differently than a tower made of toy blocks, so objects of different sizes should be modeled to accurate scale.
</p>

<p>If you are modelling a human make sure he is around 2 meters big in Unity. To check if your object has the right size compare it to the default cube. You can create a cube using <i>GameObject-&gt;Create Other-&gt;Cube</i>. The cube will be exactly 1 meter large. So your human should be twice as tall.
</p>

<p>If you aren't able to adjust the mesh itself, you can change the global scale of each particular mesh by control-clicking on your imported mesh and selecting 'Import Settings' from the context menu.  Here, you can change the scale and re-import your mesh.
</p>

<p>If your game requires that your GameObject needs to be instantiated at different scales, it is perfectly okay to directly adjust the values of your Transform's scale.  The down-side is that the physics simulation must do more work at the time the object is instantiated, and could cause a performance drop in your game.  This isn't a terrible loss, but it is not as efficient as finalizing your scale with the other two options.
</p>


<h2>Hints</h2>
<p><ul><li>
The relative masses of two objects determines how they react when they collide.
</li><li>Making one object have higher mass than another does not make it fall faster in free fall. Use drag for that.
</li><li>A low drag value makes an object seem heavy. A high one makes it seem light. Typical values for drag are between .001 (solid block of metal) and 10 (feather)
</li><li>If you are directly manipulating the Transform component of your object but still want physics, attach a Rigidbody and make it Kinematic.
</li></ul>
</p>
<h1>Constant Force</h1>
<p>The Constant Force component is a quick utility for adding constant forces to a rigidbody.
This works great for one shot objects like rockets, if you don't want it to start with a large velocity but instead accelerate.
</p>

<p><img class='figure' src='images/Physics-2.jpg' />
</p>

<p><i>A rocket propelled forward by the constant force component</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Force</nobr></b></td><td> The vector of a force to be applied in world space.
</td></tr><tr><td><b><nobr>Relative Force</nobr></b></td><td> The vector of a force to be applied in the objects local space.
</td></tr><tr><td><b><nobr>Torque</nobr></b></td><td> The vector of a torque, applied in world space. The object will begin spinning <i>around</i> this vector. The longer the vector is, the faster the rotation.
</td></tr><tr><td><b><nobr>Relative Torque</nobr></b></td><td> The vector of a torque, applied in local space. The object will begin spinning <i>around</i> this vector. The longer the vector is, the faster the rotation.
<p></td></tr></tr></table>
</p>

<h3> Details</h3>

<p>To make a rocket that accelerates forward set the relative force to be along the positive z-axis. Then use the rigidbody's drag property to make it not exceed a some maximum velocity. (The higher the drag the lower the maximum velocity will be.)
In the rigidbody also make sure to turn off gravity so that the rocket will always stay on it's path.
</p>

<h2>Hints</h2>
<p><ul><li>
To make an object flow upwards, add a constant force with the Force property having a positive Y value.
</li><li>To make an object fly forwards,  add a constant force with the Relative Force property having a positive Z value.
</li></ul>
</p>

<h1>Sphere Collider</h1>
<p>The Sphere Collider is a basic sphere-shaped collision primitive.
</p>

<p><img class='figure' src='images/Physics-3.jpg' />
</p>

<p><i>(Image of a Sphere Collider in Inspector)</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Material</nobr></b></td><td> Reference to the <a href="../Components/class-PhysicMaterial.html">PhysicMaterial</a> that determines how this Collider interacts with others.
</td></tr><tr><td><b><nobr>Is Trigger</nobr></b></td><td> If enabled, this Collider is used for triggering events, and is ignored by the physics engine.

</td></tr><tr><td><b><nobr>Radius</nobr></b></td><td> The size of the collider.
</td></tr><tr><td><b><nobr>Center</nobr></b></td><td> The position of the collider in the object's local space.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>The Sphere Collider can be resized to uniform scale, but not along individual axes. It works great for falling boulders, ping pong balls, marbles, etc.
</p>

<p><img class='figure' src='images/Physics-4.jpg' />
</p>

<p><i>A standard Sphere Collider</i>
</p>


<p>Colliders work with Rigidbodies to bring physics in Unity to life.  Whereas Rigidbodies allow objects to be controlled by physics, Colliders allow objects to collide with each other.  Colliders must be added to objects independently of Rigidbodies.  A Collider does not necessarily need a Rigidbody attached, but a Rigidbody <span style="text-decoration:underline;">must</span> be attached in order for the object to react to collisions.
</p>

<p>When a collision between two Colliders occurs and if at least one of them has a Rigidbody attached, <a class="wiki"  href="../ScriptReference/Collider.html#OnCollisionEnter">three</a> <a class="wiki"  href="../ScriptReference/Collider.html#OnCollisionExit">collision</a> <a class="wiki"  href="../ScriptReference/Collider.html#OnCollisionStay">messages</a> are sent out to the objects attached to them. These events can be handled in scripting, and allow you to create unique behaviors with or without making use of the built-in Ageia physX engine.
</p>

<h3>Triggers</h3>
<p>An alternative way of using Colliders is to mark them as a Trigger, just check the IsTrigger property checkbox in the Inspector.  Triggers are effectively ignored by the physics engine, and have a unique set of <a class="wiki"  href="../ScriptReference/Collider.html#OnTriggerEnter">three</a> <a class="wiki"  href="../ScriptReference/Collider.html#OnTriggerExit">trigger</a> <a class="wiki"  href="../ScriptReference/Collider.html#OnTriggerStay">messages</a> that are sent out when a collision with a Trigger occurs.  Triggers are useful for triggering other events in your game, like cutscenes, automatic door opening, displaying tutorial messages, etc.  Use your imagination!
</p>

<p>Be aware that in order for two Triggers to send out trigger events when they collide, one of them must be attached to a Rigidbody. For a Trigger to collide with a normal Collider, one of them must have a Rigidbody attached.  For a detailed chart of different types of collisions, see the collision action matrix in the Advanced section below.
</p>

<h3>Friction and bouncyness</h3>

<p>Friction, bouncyness and softness is defined in the <a href="../Components/class-PhysicMaterial.html">physic material</a>. The <a href="../Manual/HOWTO-InstallStandardAssets.html">Standard Assets</a> contain the most common physic materials. To use one of them click on the material popup and select eg. Ice. You can also <a href="../Components/class-PhysicMaterial.html">create</a> your own physic materials and tweak all friction values.
</p>


<h2>Compound Colliders</h2>

<p>Compound Colliders are combinations of primitive Colliders, all together acting as a single Collider.  They come in handy when you have a complex mesh to use in collisions, but cannot use a Mesh Collider.  To create a Compound Collider, create child objects of your colliding object, then add a primitive Collider to each child object.  This allows you to position, rotate, and scale each Collider easily and independently of each other.
</p>

<p><img alt="" src=""img/wiki_up/RigidBody" border="0"  />
</p>

<p><i>A GameObject with a Rigidbody and multiple colliders attached</i>
</p>

<p>In the above picture, the terrain has a Mesh Collider attached.  Mesh Colliders work the best for terrain or environments made from irregular shapes. The Rigidbody has 3 child Colliders attached: capsule, cube and sphere. When Play mode begins, the Rigidbody falls due to gravity, and the 3 child Colliders fall with it. The 3 Collision primitives collide with the Mesh Collider, and the Rigidbody eventually balances and comes to rest on the 3 Colliders.
</p>

<p>Keep in mind, Mesh Colliders can't collide with each other, so the typical solution is to use primitive Colliders for any objects that move, and Mesh Colliders for static background objects.
</p>


<h2>Hints</h2>
<p><ul><li>
To add multiple Colliders for an object, create child objects and attach a Collider to each one.  This allows each Collider to be manipulated independently.
</li><li>You can look at the gizmos in the Scene view to see how the Collider is being calculated on your object.
</li><li>Colliders do their best to match the scale of an object. If you have a non-uniform scale (a scale which is different in each direction), only the Mesh Collider can match completely.
</li><li>If you make an explosion, it can be very effective to add a rigidbody with lots of drag and a sphere collider to it in order to push it out a bit from the wall it hits.
</li></ul>
</p>


<h1>Box Collider</h1>
<p>The Box Collider is a basic cube-shaped collision primitive.
</p>

<p><img class='figure' src='images/Physics-5.jpg' />
</p>

<p><i>Box collider here is used to approximate car's hull</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>Size</nobr></b></td><td> The size of the collider in the X, Y, Z directions.
</td></tr><tr><td><b><nobr>Center</nobr></b></td><td> The position of the collider in the object's local space.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>The Box Collider can be resized into different shapes of rectangular prisms.  It works great for doors, walls, platforms, etc. It is also effective as a human torso in a ragdoll or car hull in a vehicle. Of course, it works perfectly for just boxes and crates as well!
</p>

<p><img class='figure' src='images/Physics-6.jpg' />
</p>

<p><i>A standard Box Collider</i>
</p>




<h2>Compound Colliders</h2>




<h2>Hints</h2>
<p><ul><li>
</p>

<p></li></ul>
</p>


<h1>Mesh Collider</h1>

<p>The Mesh Collider takes a <a href="../Components/class-Mesh.html">Mesh Asset</a> and builds its Collider based on that mesh.  It is far more accurate for collision detection than using primitives for complicated meshes, but it cannot collide with other Mesh Colliders.
</p>

<p><img class='figure' src='images/Physics-7.jpg' />
</p>

<p><i>A Mesh Collider used on the flag tower object</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>Mesh</nobr></b></td><td> Reference to the Mesh to use for collisions.
</td></tr><tr><td><b><nobr>Smooth Sphere Collisions</nobr></b></td><td> When this is enabled, collision mesh normals are smoothed. You should enable this on smooth surfaces eg. rolling terrain without hard edges to make sphere rolling smoother.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>
<p>The Mesh Collider builds its collision representation from the <a href="../Components/class-Mesh.html">Mesh</a> attached to the GameObject, and reads the properties of the attached <a href="../Components/class-Transform.html">Transform</a> to set its position and scale correctly.
</p>

<p>Collision meshes use backface culling. If an object collides with a mesh that will be back face culled graphically it will also not collide with it physically.
</p>



<h2>Hints</h2>
<p><ul><li>
Mesh Colliders <span style="text-decoration:underline;">cannot</span> collide with each other.  Therefore, they are most useful for background objects like environment geometry.
</li><li>It is usually better to use primitive Colliders for objects under physics control.
</li><li>When you attach a Mesh Collider to a Game Object, its Mesh property will default to the mesh being rendered. You can change that by assigning a different Mesh.
</p>

<p></li></ul>
</p>


<h1>Physic Material</h1>
<p>The physic material is used to adjust friction and bouncing effects of colliding objects.
</p>

<p>To create a physic material select the menu <b>Assets -&gt; Create -&gt; Physic Material</b>.  Then drag the physic material from the project pane on a collider in the scene.
</p>

<p><img class='figure' src='images/Physics-8.jpg' />
</p>

<p><i>The Physic Material</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Static Friction</nobr></b></td><td> The friction used when an object is lying on a surface. Usually a value from 0 to 1. A value of zero feels like ice, a value of 1 will make it very hard to get the object moving.
</td></tr><tr><td><b><nobr>Dynamic Friction</nobr></b></td><td> The friction used when already moving. Usually a value from 0 to 1. A value of zero feels like ice, a value of 1 will make it come to rest very quickly unless a lot of force / gravity pushes the object.
</td></tr><tr><td><b><nobr>Bouncyness</nobr></b></td><td> How bouncy is the surface? A value of 0 will not bounce. A value of 1 will bounce without any loss of energy.
</td></tr><tr><td><b><nobr>Friction Combine Mode</nobr></b></td><td> How the friction of two colliding objects is combined.
</td></tr><tr><td><b><nobr>    Average</nobr></b></td><td> The two friction values are averaged.
</td></tr><tr><td><b><nobr>    Min</nobr></b></td><td> The smallest of the two values is used.
</td></tr><tr><td><b><nobr>    Max</nobr></b></td><td> The largest of the two values is used.
</td></tr><tr><td><b><nobr>    Multiply</nobr></b></td><td> The friction values are multiplied with each other.
</td></tr><tr><td><b><nobr>Bounce Combine Mode</nobr></b></td><td> How the bouncyness of two colliding objects is combined.
</td></tr><tr><td><b><nobr>    Average</nobr></b></td><td> The two values are averaged.
</td></tr><tr><td><b><nobr>    Min</nobr></b></td><td> The smallest of the two values is used.
</td></tr><tr><td><b><nobr>    Max</nobr></b></td><td> The largest of the two values is used.
</td></tr><tr><td><b><nobr>    Multiply</nobr></b></td><td> The values are multiplied with each other.
</td></tr><tr><td><b><nobr>Friction Direction 2</nobr></b></td><td> The direction of anisotropy. Anisotropic friction is enabled if the vector3 is not zero. Dynamic Friction 2 and Static Friction 2 will be applied along Friction Direction 2.
</td></tr><tr><td><b><nobr>Dynamic Friction 2</nobr></b></td><td> If anisotropic friction is enabled, dynamicFriction2 will be applied along Friction Direction 2.
</td></tr><tr><td><b><nobr>Static Friction 2</nobr></b></td><td> If anisotropic friction is enabled, staticFriction2 will be applied along Friction Direction 2.
</td></tr><tr><td><b><nobr>Static Friction 2</nobr></b></td><td> If anisotropic friction is enabled, staticFriction2 will be applied along Friction Direction 2.
</td></tr><tr><td><b><nobr>Use Spring</nobr></b></td><td> If use Spring is checked, surface will be springy.
</td></tr><tr><td><b><nobr>Spring</nobr></b></td><td> The spring of the surface
</td></tr><tr><td><b><nobr>    Spring</nobr></b></td><td> The spring coefficient. A high value will pull the surfaces towards the rest position faster.
</td></tr><tr><td><b><nobr>    Damper</nobr></b></td><td> The damper coefficient. A high value will dampen the relative movement of the two surfaces.
</td></tr><tr><td><b><nobr>    Target Position</nobr></b></td><td> The rest position of the spring.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>Friction is the quantity which prevents surfaces from sliding off each other. This value is critical when trying to stack objects.
Friction comes in two forms, dynamic and static. Static friction is used when the object is lying still. It will prevent the object from starting to move. If a large enough force is applied to the object it will start moving. At this point dynamic friction will come into play. Dynamic friction will now attempt to slow down the object while in contact with another.
</p>

<h2>Hints</h2>
<p><ul><li>
Don't try to use a standard physic material for the main character. Make a customized one and get it perfect.
</li></ul>
</p>
<h1>Hinge Joint</h1>

<p>The Hinge Joint groups together 2 <a href="../Components/class-Rigidbody.html">Rigidbodies</a>, constraining them to move like they are connected by a hinge. It is perfect for doors, but can also be used to model chains, pendulums, etc.
</p>

<p><img class='figure' src='images/Physics-9.jpg' />
</p>

<p><i>The Hinge Joint</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Connected Body</nobr></b></td><td> Optional reference to the Rigidbody that the joint is dependent upon. If not set, the joint connects to the world.
</td></tr><tr><td><b><nobr>Anchor</nobr></b></td><td> The Position of the anchor around which the body swings. The Position is defined in local space.
</td></tr><tr><td><b><nobr>Axis</nobr></b></td><td> The Direction of the axis around which the body swings. The Axis is defined in local space.
</td></tr><tr><td><b><nobr>Use Spring</nobr></b></td><td> Spring makes the rigid body reach for a specific angle compared to its connected body.
</td></tr><tr><td><b><nobr>    Spring</nobr></b></td><td> The force the object asserts to move into the position.
</td></tr><tr><td><b><nobr>    Damper</nobr></b></td><td> the higher this value, the more the object will slow down.
</td></tr><tr><td><b><nobr>    Target Position</nobr></b></td><td> Target angle of the spring. The spring pulls towards this angle measured in degrees.
</td></tr><tr><td><b><nobr>Use Motor</nobr></b></td><td> The motor makes the object spin around.
</td></tr><tr><td><b><nobr>    Target Velocity</nobr></b></td><td> The speed the object tries to attain.
</td></tr><tr><td><b><nobr>    Force</nobr></b></td><td> The force applied in order to attain the speed.
</td></tr><tr><td><b><nobr>    Free Spin</nobr></b></td><td> If enabled, the motor is never used to brake the spinning, only accelerate it.
</td></tr><tr><td><b><nobr>Use Limits</nobr></b></td><td> If enabled, the angle of the hinge will be restricted within the <b>Min</b> &amp; <b>Max</b> values.
</td></tr><tr><td><b><nobr>    Min</nobr></b></td><td> The lowest angle the rotation can go.
</td></tr><tr><td><b><nobr>    Max</nobr></b></td><td> The highest angle the rotation can go.
</td></tr><tr><td><b><nobr>    Min Bounce</nobr></b></td><td> How much the object bounces when it hits the minimum stop.
</td></tr><tr><td><b><nobr>    Max Bounce</nobr></b></td><td> How much the object bounces when it hits the maximum stop.
</td></tr><tr><td><b><nobr>Break Force</nobr></b></td><td> The force that needs to be applied for this joint to break.
</td></tr><tr><td><b><nobr>Break Torque</nobr></b></td><td> The torque that needs to be applied for this joint to break.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>A single Hinge Joint should be applied to an object per desired hinge.  The hinge will rotate at the point specified by the <b>Anchor</b> property, moving around the specified <b>Axis</b> property.  You DO NOT need to assign a Game Object to the joint's <b>Connected Body</b> property.  You should only assign a Game Object to the <b>Connected Body</b> property if you want the joint's Transform to be dependent on the attached object's Transform.
</p>

<p>Think about how the hinge of a door works. The <b>Axis</b> in this case is up, positive along the Y axis. The <b>Anchor</b> is placed somewhere at the intersection between door and wall.  You would not need to assign the wall to the <b>Connected Body</b>, because the joint will be connected to the world by default.
</p>

<p><img class='figure' src='images/Physics-10.jpg' />
</p>

<p><i>A practical Hinge Joint with no <b>Connected Body</b></i>
</p>

<p>Now think about a doggy door hinge. The doggy door's <b>Axis</b> would be sideways, positive along the relative X axis.  The main door should be assigned as the <b>Connected Body</b>, so the doggy door's hinge is dependent on the main door's Transform.
</p>

<p><img class='figure' src='images/Physics-11.jpg' />
</p>

<p><i>A practical Hinge Joint with a proper <b>Connected Body</b></i>
</p>


<h3>Chains</h3>

<p>Multiple Hinge Joints can also be strung together to create a chain.  Add a joint to each link in the chain, and attach the next link as a <b>Connected Body</b>.  The result should be similar to the following picture.
</p>

<p><img class='figure' src='images/Physics-12.jpg' />
</p>

<p><i>A Nunchaku made exclusively with primitives and Hinge Joints</i>
</p>

<h3>Vehicles</h3>

<p>Hinge Joints can be implemented as axles on vehicles, as seen here in Forest Johnson's racing game. However, it's often better just to use a <a href="../Components/class-WheelCollider.html">Wheel Collider</a> for vehicles.
</p>

<p><img class='figure' src='images/Physics-13.jpg' />
</p>

<h2>Hints</h2>
<p><ul><li>
You do not need to assign a <b>Connected Body</b> to your joint for it to work.
</li><li>Use <b>Break Force</b> in order to make dynamic damage systems. This is really cool as it allows the player to break a door off its hinge by blasting it with a rocket launcher or running into it with a car.
</li><li>The <b>Spring</b>, <b>Motor</b>, and <b>Limits</b> properties allow you to fine-tune your joint's behaviors.
</li></ul>
</p>






<p>Animations are best imported from art programs but can also be created inside Unity.
</p>

<p>To import an animation from your art package just <a href="../Manual/HOWTO-importObject.html">drop in your model files</a>.
</p>

<p>When you place your model file in unity's project folder it will automatically appear in the project view and you can drag it to the scene. The animation on all objects in the scene is imported automatically and you wil see the animation playing when you hit play.
</p>

<p>For more information about animating characters or importing animations see the <a href="../Manual/Character-Animation.html"> Character Animation section</a>.
</p>

<h2>Creating animations inside Unity</h2>

<p>1. Switch to the animation layout. This will display the <b>Timeline View</b>. In the Timeline you will create and modify animations.
</p>

<p><img class='figure' src='images/Animation-0.jpg' />
</p>

<p>2. Select the object you want to animate in the scene view.
</p>

<p>3. Click on the record button in the animation Timeline
</p>

<p><img class='figure' src='images/Animation-1.jpg' />
</p>

<p>4. Select another time in the Timeline by clicking on it. Then move the object some where else and hit record again.
</p>

<p>If you hit Play now, your object will follow the animation you just created.
</p>

<h2>Hints</h2>
<p><ul><li>
By default only the transform's position, rotation and scale is included in the animation.
Right-click on the Timeline and use the <b>Add Key With Attribute</b> menu to add other animatable properties of the selected object to the animation.
</p>

<p><img class='figure' src='images/Animation-2.jpg' />
</p>

<p></li><li>You can scrub on the timeline by dragging a keyframe with the center mouse button
</p>

<p></li><li>Post Infinity is used to define behaviour of the animation after the last keyframe. Right-click on the timeline and select <b>Post Infinity -&gt; Repeat</b> from the context menu.
</p>

<p><img class='figure' src='images/Animation-3.jpg' />
</p>

<p></li><li>Sometimes it is useful to create animations which are shared among all objects.
To do this, create an animation clip in the assets menu.
</p>

<p><img class='figure' src='images/Animation-4.jpg' />
</p>

<p>Then drag the animation clip on an object. Then you animate the object. Then you can drag the animation clip on other objects.
</li></ul>
</p>



<p>Unity's Animation System allows you to create beautifully animated skinned characters. The Animation System supports animation blending, mixing, additive animations, walk cycle time synchronization, animation layers, control over all aspects of the animation playback (time, speed, blend-weights), mesh skinning with 1, 2 or 4 bones per vertex and finally physically based ragdolls.
</p>

<p>Making an animated character involves two things; <i>moving</i> them through the world and <i>animating</i> them accordingly.
</p>

<p>This page focuses on the animation. If you want to learn more about moving characters around (for a Super Mario Bros style game or a first-person shooter), go <a href="../Components/class-CharacterController.html">here</a>.
</p>

<ul><li><A HREF="#ImportAnim">Importing Character Animations</A>
<ul><li><A HREF="#ImportSplit">Animation Splitting</A>
</li><li><A HREF="#ImportFile">Multipe Files</A>
</li><li><A HREF="#ImportIK">Inverse Kinematics</A>
</li></ul></li><li><A HREF="#IntoScene">Inserting Into a Unity Scene</A>
</li><li><A HREF="#Animate">Animating the Character</A>
<ul><li><A HREF="#AnimBlend">Animation Blending</A>
</li><li><A HREF="#AnimLayers">Animation Layers</A>
</li><li><A HREF="#LayerExample">Additive Animation</A>
</li></ul></li></ul>

<p>You can download an <b><a class="wiki"  href="http://www.unity3d.com/examples/index.html">example project</a></b> showing pre-setup animated characters <a class="wiki"  href="http://www.unity3d.com/examples/index.html">here</a>.
</p>



<p><A NAME="ImportAnim"></A>
</p>
<h2> Importing The Animations</h2>
<p>First of all we have to import the character.  Unity natively imports Maya (.mb/.ma) files, Cinema 4D (.c4d) files, and fbx files which can be exported from most animation packages. Click here to learn how to <a href="../Manual/HOWTO-importObject.html">export from your modelling/animation package</a>.
</p>

<p><A NAME="ImportSplit"></A>
</p>
<h3>Importing Animations using Animation Splitting</h3>
<p>The most convenient way for animators to work is to have a single model containing all animations. When importing the animated model, you can define which frames make up each part of the animation. Unity will automatically split the animation into the individual parts, called <b>Animation Clips</b>.
</p>

<p>For example:
</p>
<ul><li>idle animation during frames 0 - 40
</li><li>run animation during frames 41 - 65
</li><li>walk animation during frames 66 - 83
</li></ul>

<p>To import the animations you simply place the model in your project folder. Unity will now automatically import it. Now highlight it in the project view and choose <b>Assets -&gt; Import Settings...</b> from the main menu.
</p>

<p><img class='figure' src='images/Character-Animation-0.jpg' />
</p>

<p><i>The Import Settings Dialog for a mesh</i>
</p>

<p>In the Import Settings' <b>Split Animations</b> table you tell Unity which frames in your 3D file make up which <b>Animation Clip</b>. The names you specify here are used to activate them in your game.
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
name</nobr></b></td><td> Defines the Animation Clip's name within Unity.
</td></tr><tr><td><b><nobr>first frame</nobr></b></td><td> the first frame of the animation. The frame number refers to the same frame as in the 3D program used to create the animation.
</td></tr><tr><td><b><nobr>last frame</nobr></b></td><td> The last frame of the animation.
</td></tr><tr><td><b><nobr>loop frame</nobr></b></td><td> If enabled, an extra <i>loop frame</i> is inserted at the end of the animation. This frame matches the first frame in the clip. Use this if you want to make a looping animation and your artwork has not been created in such a way that the first and last frame of the animation match up exactly.
<p></td></tr></tr></table>
</p>

<p><A NAME="ImportFile"></A>
</p>
<h3>Importing Animations using multiple model files</h3>
<p>The other way to import animations is to follow the @ animation naming scheme. You create seperate model files and name them like: 'model name'@'animation name'.fbx
</p>

<p><img class='figure' src='images/Character-Animation-1.jpg' />
</p>

<p><i>An example of 4 animation files for an animated character</i>
</p>

<p>Unity automatically imports all 4 files and collects all animations to the file without the @ sign in. In the example above, the goober.mb file will be setup to reference idle, jump, and walk automatically.
</p>

<p><A NAME="ImportIK"></A>
</p>
<h3> Importing Inverse Kinematics</h3>
<p>When importing animated Characters from Maya that are created using IK, you have to check the Bake IK &amp; simulation box in the import settings. Otherwise, your Character will not animate correctly.
</p>

<p><A NAME="IntoScene"></A>
</p>
<h2> Bringing the Character into the Scene</h2>

<p>When you have imported your model you drag the object from the Project view into the Scene view or Hierarchy.
</p>

<p><img class='figure' src='images/Character-Animation-2.jpg' />
</p>

<p><i>The animated character is added by dragging it into the scene</i>
</p>

<p>The character above has 3 animations in the animation list and no default animation. You can add more animations to the character by dragging animation clips from the <b>Project View</b> on to the character (in either the <b>Hierarchy View</b> or a <b>Scene View</b>). This will also set the default animation. When you hit play the default animation will be played.
</p>

<p>TIP: you can use this to quickly test if your animation plays back correctly. Also use the Wrap Mode to view different behaviors of the animation- especially looping.
</p>

<p><A NAME="Animate"></A>
</p>
<h2> Animating the Character</h2>

<p>The actual animation of characters is done through Unity's scripting interface.
</p>

<p><A NAME="AnimBlend"></A>
</p>
<h3> Animation Blending</h3>

<p>In today's games, animation blending is an essential feature to ensure that characters have smooth animations. Animators create separate animations, e.g. a walk cycle, run cycle, idle animation or shoot animation. At any point in time in your game you need to be able to transition from the idle animation into the walk cycle and vice versa. Of course you don't want any sudden jumps in the motion. You want the animation to smoothly transition.
</p>

<p>This is where animation blending comes in. In Unity you can have an arbitrary amount of animations playing on the same character. All animations are blended or added together to generate the final animation.
</p>


<p>Our first step will be to make a character smoothly blend between the idle and walk animations.  In order to make our job simpler when scripting, we will first set the <b>Wrap Mode</b> of the animation to <b>Loop</b>. Then we will turn off <b>Play Automatically</b> to make sure our script is the only one playing animations.
</p>

<p>Our first script for animating the character is quite simple; we only need some way to detect how fast our character is moving, and then fade between walk and idle animation. For this simple test we use the pre-setup input axes.
</p>

<p><pre class='codelisting'>
function Update ()
{
   if (Input.GetAxis(&quot;Vertical&quot;) &gt; 0.2)
       animation.CrossFade (&quot;walk&quot;);
   else
      animation.CrossFade (&quot;idle&quot;);
}
</pre>
</p>

<p>To get this script running:
</p>
<ol><li> Create a javascript using Assets -&gt; Create Other -&gt; Javascript.
</li><li> Copy &amp; Paste the code into it
</li><li> Drag the script onto the character (It needs to be the same game object as the animation)
</li></ol>

<p>When you hit the play button, The character will start walking in place when you hold the up arrow key and return to the idle pose when you release  it.
</p>

<p><A NAME="AnimLayers"></A>
</p>
<h3> Animation Layers</h3>

<p>Layers are an incredibly useful concept that allow you to group animations and prioritize weighting.
</p>

<p>in Unity's animation system, you can blend between as many animation clips as you want. You can assign blend weights manually or simply use animation.CrossFade, which will animate the weight automatically.
</p>

<h4>Blend weights are always normalized before being applied</h4>

<p>Let's say you have a walk cycle and a run cycle, both have a weight of 1 (100%). When Unity generates the final animation it will normalize the weights, which means walk will contribute 50% to the animation, the run cycle will also contribute 50%.
</p>

<p>This is all very nice, but often you want to prioritize which animation receives most weight when there are two animations playing. Surely you could just make sure that the weight sums up to 100% manually, but it is a lot easier to use layers for this purpose.
</p>


<p><A NAME="LayerExample"></A>
</p>
<h4> Layering Example</h4>
<p>For example you might have a shoot animation, an idle and a walk cycle. You will want to continously fade between the walk and idle animation based on the player's speed. But when the player shoots you want to only show the shoot animation. Thus the shoot animation essentially has a higher priority.
</p>

<p>The easiest way to do this is to simply keep playing the walk and idle animations while shooting. Then we need to make sure that the shoot animation is in a higher layer than idle and walk. This means the shoot animation will receive blend weights first. The walk and idle animation will receive weights only if the shoot animation doesn't use all of the 100% blend weights. So when CrossFading the shoot animation in, the weight will start out at zero and over a short period become 100%. In the beginning the walk and idle layer will still receive blend weights but when the shoot animation is completely faded in, they will receive no weights at all.  This is exactly what we need!
</p>

<p><pre class='codelisting'>
function Start ()
{
   // Set all animations to loop
   animation.wrapMode = WrapMode.Loop;
   // except shooting
   animation[&quot;shoot&quot;].wrapMode = WrapMode.Once;

   // Put idle and walk into lower layers (The default layer is always 0)
   // This will do two things
   // - Since shoot and idle/walk are in different layers they will not affect
   //   each other's playback when calling CrossFade.
   // - Since shoot is in a higher layer, the animation will replace idle/walk 
   //   animations when faded in.
   animation[&quot;shoot&quot;].layer = 1;
  
   // Stop animations that are already playing
   //(In case user forgot to disable play automatically)
   animation.Stop();
}

function Update () {
   // Based on the key that is pressed,
   // play the walk animation or the idle animation
   if (Mathf.Abs(Input.GetAxis(&quot;Vertical&quot;)) &gt; 0.1)
      animation.CrossFade(&quot;walk&quot;);
   else
      animation.CrossFade(&quot;idle&quot;);

   // Shoot
   if (Input.GetButtonDown (&quot;Fire1&quot;))
      animation.CrossFade(&quot;shoot&quot;);
}
</pre>
</p>

<p>By default the animation.Play or animation.CrossFade function will stop or fade out animations that are in the same layer. This is exactly what we want in mose cases. In our shoot, idle, run example. Playing idle and run will not affect the shoot animation and vice versa. (You can change this behaviour with an optional parameter to animation.CrossFade if you like)
</p>

<p><A NAME="Additive"></A>
</p>
<h3> Additive Animations and Animation Mixing</h3>

<p>Additive Animations and Animation mixing allow you to cut down on the number of animations you have to create for your game, and are important to creating facial animation.
</p>

<p>Let's say you want to create a character that leans to the sides when running and turning.
</p>

<p>You already made a walk and run cycle, now you could make a walk-lean-left, walk-lean-right, run-lean-left, run-lean-right animation.
</p>

<p>But that means you just doubled the amount of animation work! Creating a huge amount of animations is not feasiable. Additive animations and Mixing to the rescue!
</p>

<h4>Additive Animation Example</h4>
<p>Additive animations allow you to overlay the effects of animation on top of any others that may be playing. When making additive animations, Unity will calculate the difference between the first frame in the animation clip and the current frame. Then it will apply this difference on top of all other playing animations.
</p>

<p>Now you only have to make a lean-left and lean-right animation. Unity will then layer this animation on top of the walk, idle or run cycle.
</p>

<p>Here is the code to make that happen:
<pre class='codelisting'>
private var leanLeft : AnimationState;
private var leanRight : AnimationState;

function Start ()
{
   leanLeft = animation[&quot;leanLeft&quot;];
   leanRight = animation[&quot;leanRight&quot;];
	
   // Put the leaning animation in a seperate layer
   // So that other calls to CrossFade won't affect it.
   leanLeft.layer = 10;
   leanRight.layer = 10;

   // Set the lean animation to be additive
   leanLeft.blendMode = AnimationBlendMode.Additive;
   leanRight.blendMode = AnimationBlendMode.Additive;

   // Set the lean animation ClampForever
   // With ClampForever animation's will not automatically
   // stop when reaching the end of the clip
   leanLeft.wrapMode = WrapMode.ClampForever;
   leanRight.wrapMode = WrapMode.ClampForever;

   // Enable the animation and fade it in completely
   // We don't use animation.Play here because we manually adjust the time
   // in the Update function.
   // Instead we just enable the animation and set it to full weight
   leanRight.enabled = true;
   leanLeft.enabled = true;
   leanRight.weight = 1.0;
   leanLeft.weight = 1.0;

   // For testing just play run animation and loop it
   animation[&quot;walk&quot;].wrapMode = WrapMode.Loop;
   animation.Play(&quot;walk&quot;);
}

// Every frame just set the normalized time 
// based on how much lean we want to apply
function Update ()
{
   var lean = Input.GetAxis(&quot;Horizontal&quot;);
   // normalizedTime is 0 at the first frame and 1 at the last frame in the clip
   leanLeft.normalizedTime = -lean;
   leanRight.normalizedTime = lean;
}
</pre>
</p>

<p>Tip:
When using Additive animations it critical that you are also playing some other non-additive animation on every transform that is also used int eh additive animation, otherwise the animations will add on top of the last frame's result. This is most certainly not what you want.
</p>

<p>You have learned how to make a basic character animation please see the <a class="wiki"  href="http://www.unity3d.com/examples">projects</a> for in-depth examples of character animation and the <a class="wiki"  href="../ScriptReference/Animation.html">animation script interface</a>.
</p>



<p>Unity uses OpenAL to implement immersive 3D audio. Adding sound to a game is one of the final touches that make a game feel like a complete product. Using 3D positioned audio effects and well chosen music creatively can even add to the game play and greatly affect the mood of the final product.
</p>

<p>In short, adding sounds to a game consists of adding sound assets to the project, attaching an Audio Listener to the main camera object and attaching Audio Sources to game objects.
</p>

<h2>Scripting</h2>

<p>Audio is triggered from scripting. See the documentation on the <a class="wiki"  href="../ScriptReference/AudioListener.html">AudioListener</a>, <a class="wiki"  href="../ScriptReference/AudioSource.html">AudioSource</a> and the <a class="wiki"  href="../ScriptReference/AudioClip.html">AudioClip</a> classes in the <a class="wiki"  href="../ScriptReference/index.html">Script Reference</a> for more information on scripting audio.
</p>

<h1>Audio Listener</h1>
<p>The Audio Listener acts as a microphone-like device. It receives input from any given <a href="../Components/class-AudioSource.html">Audio Source</a> in the scene and plays sounds through the computer speakers.  It is traditionally attached to the main <a href="../Components/class-Camera.html">Camera</a>.
</p>

<p><img class='figure' src='images/Sound-0.jpg' />
</p>

<p><i>The Audio Listener, attached to the Main Camera</i>
</p>

<h2>Properties</h2>
<p>The Audio Listener has no properties.  It simply must be added to work.
</p>

<h2>Details</h2>
<p>The Audio Listener works in conjunction with <a href="../Components/class-AudioSource.html">Audio Sources</a>, allowing you to create the aural experience of your games.  When the Audio Listener is attached to an object in your scene, any Sources that are close enough to the Listener will be picked up and played through the player's computer speakers.  Each scene can only have 1 Audio Listener to work properly.
</p>

<p>As long as the Sources are in mono format, the Listener will automatically position the sound in the correct speaker, at the correct volume.  Stereo Sources will automatically play in both speakers.  For example, if your character walks off a street into a night club, the night club's music should probably be stereo, while the individual voices of characters in the club should be mono.
</p>

<p>You should attach the Audio Listener to either the main camera or to the game object that represents the player. Try both to find what suits your game best.
</p>

<h2>Hints</h2>
<p><ul><li>
Each scene can only have one Audio Listener.
</li><li>You access the project-wide audio settings using the <a href="../Components/class-AudioManager.html">AudioManager</a>, found in the Edit-&gt;Project Settings-&gt;Audio menu.
</li></ul>
</p>


<h1>Audio Source</h1>
<p>The Audio Source takes an <a href="../Components/class-AudioClip.html">Audio Clip</a> and plays it from a position in the world.
</p>

<p><img class='figure' src='images/Sound-1.jpg' />
</p>

<p><i>The Audio Source in the scene view and Inspector</i>
</p>

<h2> Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Audio Clip</nobr></b></td><td> Reference to the sound clip file that will be played
</td></tr><tr><td><b><nobr>Play On Awake</nobr></b></td><td> If enabled, the sound will start playing the moment the scene launches. If disabled, you need to start it using the Play() command from scripting.
</td></tr><tr><td><b><nobr>Volume</nobr></b></td><td> How loud the sound is at 1 world unit's (1 meter) distance from Audio Listener.
</td></tr><tr><td><b><nobr>Min Volume</nobr></b></td><td> The minimum value of the sound. No matter how far away you get, the sound will get softer.
</td></tr><tr><td><b><nobr>Max Volume</nobr></b></td><td> How loud the sound gets at the loudest. No matter how close you get, the sound will never get louder.
</td></tr><tr><td><b><nobr>Rolloff Factor</nobr></b></td><td> How fast the sound fades. the higher the value, the shorter the range the Listener can hear the sound.
</td></tr><tr><td><b><nobr>Loop</nobr></b></td><td> Enable this to make the <b>Audio Clip</b> loop when it finishes playing.
<p></td></tr></tr></table>
</p>

<h2> Hints</h2>
<p><ul><li>
The key to a nice sound environment is tweaking the <b>Rolloff Factor</b>.
</li><li>The 3D audio effects will only work for mono audio clips. Stereo audio clips will be mixed as-is into the sound output.
</li></ul>
</p>

<h1>Audio Clip</h1>

<p>Audio Clips are used by <a href="../Components/class-AudioSource.html">Audio Sources</a> to represent the audio asset imported into Unity.
</p>

<p><img class='figure' src='images/Sound-2.jpg' />
</p>

<p><i>The Audio Clip</i>
</p>

<p>Audio Clips just work.  The only thing you should have to do with them is reference them from within <a href="../Components/class-AudioSource.html">Audio Sources</a>.
</p>

<h2>Properties</h2>
<p>Sound assets only have 3 read-only properties.
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Format </nobr></b></td><td> The format the sound is stored in. Unity supports 4 raw formats and one compressed.
<dl><dt>Mono 8 bit</dt><dd> 8 bit uncompressed mono PCM audio</dd><dt>Mono 16 bit</dt><dd> 16 bit uncompressed mono PCM audio</dd><dt>Stereo 8 bit</dt><dd> 8 bit uncompressed stereo PCM audio</dd><dt>Stereo 16 bit</dt><dd> 16 bit uncompressed stereo PCM audio</dd><dt>Ogg Vorbis</dt><dd> Ogg Vorbis encoded stereo or mono audio</dd></dl>
</td></tr><tr><td><b><nobr>Length</nobr></b></td><td> The duration of the sound file in seconds.
</td></tr><tr><td><b><nobr>Frequency</nobr></b></td><td> The sampling frequency of the file.
</td></tr></tr></table>
</p>

<h2>Supported sound formats</h2>
<p>Unity currently supports the following file formats:
</p>

<p><dl><dt><b>AIFF</b></dt><dd> Both mono and stereo. The sound will be stored as-is inside the player-data. No compression will be attempted.</dd><dt><b>WAV</b></dt><dd> Both mono and stereo. The sound will be stored as-is inside the player-data. No compression will be attempted.</dd><dt><b>MP3</b></dt><dd> Mono and stereo. Note that the audio will be uncompressed in the editor and stored uncompressed in the player. If you want to conserve space, use Ogg Vorbis files instead.</dd><dt><b>Ogg Vorbis</b></dt><dd> Both mono and stereo. The file will be stored compressed in the player-data and streamed on the fly. When using Ogg vorbis it is recommended to always use 44khz frequency.</dd></dl>
</p>

<h2> Stereo or Mono?</h2>
<p>Stereo sounds are always played as is. They are not faded out over distance and they do not have panning. This makes them optimal for music and ambient sources.
</p>

<p>Mono sounds always fade out over distance and do panning. This is good for all effects requiring 3D positional sound.
</p>

<h2> Choosing the right format</h2>

<p>For music you should always use the ogg vorbis format. The frequency should be 44khz and it should be stereo. (44 khz is recommended since playback will be faster than with 22khz)
</p>

<p>Short audio clips  (eg. foot steps, bullet explosion) you should use <b>AIFF</b> or <b>WAV</b> with mono and either 22khz or 11khz. Usually you should not use 44khz since that takes up too much disk space and the quality difference is not hearable.
</p>

<p>Long audio clips should use ogg vorbis and mono. A good rule of thumb is that if a sound file is more than 200k uncompressed, then it makes sense to use ogg vorbis and stream the sound instead (when using ogg vorbis, always choose 44khz).
</p>

<h2>Hints</h2>
<p><ul><li>
Stereo sounds are always played as-is. If you want to use attenuation and other 3D audio effects, use mono sounds.
</li><li>You can get a free Ogg Vorbis converter from <a class="wiki"  href="http://sbooth.org/Max">http://sbooth.org/Max</a> (Mac) or from <a class="wiki"  href="http://www.rarewares.org/ogg.html">http://www.rarewares.org/ogg.html</a> (Windows)
</li></ul>
</p>





<p>Unity has functionality for making in-game Head-Up-Displays and 2D menus, using the GUI Texture and GUI Text components. A complete GUI is made up from several GUI components.
</p>

<p>To create a GUI, you must first attach a GUI Layer component to the main camera. Then add GUI Texture and GUI Text objects to the scene. The x and y components of the GUI objects' position determine the position on the screen with (0,0) being the bottom left and (1,1) the top right corner of the screen.
</p>

<h1>GUI Texture</h1>

<p>GUI Textures are displayed as flat images in 2D. They are made especially for User Interface elements, buttons, or decorations.  Their positioning and scaling is performed along the x and y axes only, and they are measured in Screen Coordinates, rather than World Coordinates.
</p>

<p><img class='figure' src='images/Game Interface Elements-0.jpg' />
</p>

<p><i>The GUI Texture</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Texture</nobr></b></td><td> Reference to the <a href="../Components/class-Texture2D.html">Texture2D</a> that will be used as the texture's display.
</td></tr><tr><td><b><nobr>Color</nobr></b></td><td> Value that will tint the <b>Texture</b> drawn on screen.
</td></tr><tr><td><b><nobr>Pixel Inset</nobr></b></td><td> Used for pixel-level control of the scaling and positioning of the GUI Texture. All values are measured relative to the position of the GUI Texture's <b>Transform</b>.
</td></tr><tr><td><b><nobr>    Xmin</nobr></b></td><td> Left-most pixel position of the texture.
</td></tr><tr><td><b><nobr>    Ymin</nobr></b></td><td> Bottom-most pixel position of the texture.
</td></tr><tr><td><b><nobr>    Xmax</nobr></b></td><td> Right-most pixel position of the texture.
</td></tr><tr><td><b><nobr>    Ymax</nobr></b></td><td> Top-most pixel position of the texture.
</td></tr><tr><td><b><nobr>Left Border</nobr></b></td><td> Number of pixels from the left that are not affected by scale.
</td></tr><tr><td><b><nobr>Right Border</nobr></b></td><td> Number of pixels from the right that are not affected by scale.
</td></tr><tr><td><b><nobr>Top Border</nobr></b></td><td> Number of pixels from the top that are not affected by scale.
</td></tr><tr><td><b><nobr>Bottom Border</nobr></b></td><td> Number of pixels from the bottom that are not affected by scale.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>To create a gui texture
</p>
<ol><li> Select a texture in the project view
</li><li> Choose <b>Game Object -&gt; Create Other -&gt; GUI Texture</b>
</li></ol>


<p>GUI Textures are perfect for presenting game interface backgrounds, buttons, or other elements to the player.  Through scripting, you can easily provide visual feedback for different &quot;states&quot; of the texture &mdash; when the mouse is hovering over the texture, or is actively clicking it for example.  Here is the basic breakdown of how the GUI Texture is calculated:
</p>

<p><img class='figure' src='images/Game Interface Elements-1.jpg' />
</p>

<p>Here's a real-world example of GUI Texture at work from Unity forum member Bampf's game <span style="text-decoration:underline;">Pawns</span>.
</p>

<p><img class='figure' src='images/Game Interface Elements-2.jpg' />
</p>

<h3>Borders</h3>

<p>The number of pixels that will not scale with the texture at each edge of the image.  As you rarely know the resolution your game runs in, chances are your GUI will get scaled. Some GUI textures have a border at the edge that is meant to be an exact number of pixels. In order for this to work, set the border sizes to match those from the texture.
</p>

<h3>Pixel Inset</h3>

<p>The purpose of the <b>Pixel Inset</b> is to prevent textures from scaling with screen resolution, and keeping thim in a fixed pixel size. This allows you to render a texture without any scaling.  This means that players who run your game in higher resolutions will see your textures in smaller areas of the screen, allowing them to have more screen real-estate for your gameplay graphics.
</p>

<p>To use it effectively, you need to set the scale of the GUI Texture's <b>Transform</b> to 0, 0, 0. Now, the <b>Pixel Inset</b> is in full control of the texture's size and you can set the <b>Pixel Inset</b> values to be the exact pixel size of your texture.
</p>

<h2>Hints</h2>
<p><ul><li>
The depth of each layered GUI Texture is determined by its individual Z Transform position, not the global Z position.
</li><li><b>GUI Textures</b> are great for making menu screens, or pause/escape menu screens.
</li><li>You should use <b>Pixel Inset</b> on any GUI Textures that you want to be a specific number of pixels for the width and height.
</li></ul>
</p>


<h1>GUI Text</h1>

<p>GUI Text displays text of any font you import in screen coordinates.
</p>

<p><img class='figure' src='images/Game Interface Elements-3.jpg' />
</p>

<p><i>The GUI Text</i>
</p>

<h2>Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Text</nobr></b></td><td> The string of text to display.
</td></tr><tr><td><b><nobr>Anchor</nobr></b></td><td> Which point of the text shares the position of the Transform.
</td></tr><tr><td><b><nobr>Alignment</nobr></b></td><td> How multiple lines are aligned within the GUIText.
</td></tr><tr><td><b><nobr>Line Spacing</nobr></b></td><td> How much space will be in-between lines of text.
</td></tr><tr><td><b><nobr>Tab Size</nobr></b></td><td> How much space will be inserted for a tab '\t' character. As a multiplum of the space character offset.
</td></tr><tr><td><b><nobr>Font</nobr></b></td><td> The <a href="../Components/class-Font.html">font</a> to use when rendering the text.
</td></tr><tr><td><b><nobr>Material</nobr></b></td><td> Reference to the Material containing the characters to be drawn. If set, this property overrides the one in the <a href="../Components/class-Font.html">Font</a> asset.
</td></tr><tr><td><b><nobr>Pixel Correct</nobr></b></td><td> If enabled, all text characters will be drawn in the size of the imported font texture. If disabled, the characters will be resized based on the transform's scale.
<p></td></tr></tr></table>
</p>

<h2>Details</h2>

<p>GUI Texts are used to print text onto the screen in 2D. The camera has to have a <a href="../Components/class-GUILayer.html">GUI Layer</a> attached in order to render the text.  Cameras include a GUI Layer by default, so don't remove it if you want to display a GUI Text.  GUI Texts are positioned using only the X and Y axes.  Rather than being positioned in World Coordinates, GUI Texts are positioned in Screen Coordinates, where (0,0) is the bottom-left and (1,1) is the top-right corner of the screen
</p>

<p>To import a font see the <a href="../Components/class-Font.html">Font class</a>.
</p>

<h3>Pixel Correct</h3>

<p>By default Fonts are rendered pixel correct. This makes them look crisp and they will stay the same size in pixels independent of the screen resolution.
</p>

<h2>Hints</h2>
<p><ul><li>
When entering text into the <b>Text</b> property, you can create a line break by holding <i>Alt</i> and pressing <i>Return</i>.
</li><li>You can download free true type fonts from <a class="wiki"  href="http://www.1001freefonts.com/fonts/afonts.htm">http://www.1001freefonts.com/fonts/afonts.htm</a> (download the windows fonts since they contain true type fonts).
</li><li>If you are scripting the <b>Text</b> property, you can add line breaks by inserting the escape character &quot;\n&quot; in your strings.
</li></ul>
</p>


<p>The following is a list of common tasks in Unity and how to accomplish them.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Graphics how-tos.html">Graphics how-tos</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-bumpmap.html">HOWTO-bumpmap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseDetailTexture.html">HOWTO-UseDetailTexture</a></li><li class="toclevel"><a href="../Manual/HOWTO-MakeCubemap.html">HOWTO-MakeCubemap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseSkybox.html">HOWTO-UseSkybox</a></li><li class="toclevel"><a href="../Manual/HOWTO-MeshParticleEmitter.html">HOWTO-MeshParticleEmitter</a></li><li class="toclevel"><a href="../Manual/HOWTO-SplashScreen.html">HOWTO-SplashScreen</a></li><li class="toclevel"><a href="../Manual/HOWTO-LightCookie.html">HOWTO-LightCookie</a></li><li class="toclevel"><a href="../Manual/HOWTO-FixZAxisIsUp.html">HOWTO-FixZAxisIsUp</a></li><li class="toclevel"><a href="../Manual/HOWTO-Water.html">HOWTO-Water</a></li><li class="toclevel"><a href="../Manual/HOWTO-Lightmap.html">HOWTO-Lightmap</a></li></ul><li class="toclevel"><a href="../Manual/HOWTO-importObject.html">HOWTO-importObject</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectMax.html">HOWTO-ImportObjectMax</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectBlender.html">HOWTO-ImportObjectBlender</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectCinema4D.html">HOWTO-ImportObjectCinema4D</a></li><li class="toclevel"><a href="../Manual/HOWTO-importObjectLightwave.html">HOWTO-importObjectLightwave</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectMaya.html">HOWTO-ImportObjectMaya</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectModo.html">HOWTO-ImportObjectModo</a></li><li class="toclevel"><a href="../Manual/HOWTO-ImportObjectCheetah3D.html">HOWTO-ImportObjectCheetah3D</a></li></ul><li class="toclevel"><a href="../Manual/Workflow.html">Workflow</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-exportpackage.html">HOWTO-exportpackage</a></li><li class="toclevel"><a href="../Manual/HOWTO-InstallStandardAssets.html">HOWTO-InstallStandardAssets</a></li></ul><li class="toclevel"><a href="../Manual/Game Code How-to.html">Game Code How-to</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-First Person Walkthrough.html">HOWTO-First Person Walkthrough</a></li></ul></ul>
</p>

<p>The following is a list of graphics tasks in Unity and how to accomplish them.
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-bumpmap.html">HOWTO-bumpmap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseDetailTexture.html">HOWTO-UseDetailTexture</a></li><li class="toclevel"><a href="../Manual/HOWTO-MakeCubemap.html">HOWTO-MakeCubemap</a></li><li class="toclevel"><a href="../Manual/HOWTO-UseSkybox.html">HOWTO-UseSkybox</a></li><li class="toclevel"><a href="../Manual/HOWTO-MeshParticleEmitter.html">HOWTO-MeshParticleEmitter</a></li><li class="toclevel"><a href="../Manual/HOWTO-SplashScreen.html">HOWTO-SplashScreen</a></li><li class="toclevel"><a href="../Manual/HOWTO-LightCookie.html">HOWTO-LightCookie</a></li><li class="toclevel"><a href="../Manual/HOWTO-FixZAxisIsUp.html">HOWTO-FixZAxisIsUp</a></li><li class="toclevel"><a href="../Manual/HOWTO-Water.html">HOWTO-Water</a></li><li class="toclevel"><a href="../Manual/HOWTO-Lightmap.html">HOWTO-Lightmap</a></li></ul>
</p>



<p>Bump maps are greyscale images that use as a height map on your objects in order to give an appearance of depth. Assuming you have a model that looks like this:
</p>

<p><img class='figure' src='images/HOWTO-bumpmap-0.jpg' />
</p>

<p>we want to make the light parts of the object stand out.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Draw a grayscale height map of your texture in photoshop. White is high, black is low. Something like this:<br /><img class='figure' src='images/HOWTO-bumpmap-1.jpg' />
</li><li> Save the image next to your main texture.
</li><li> In Unity, select the image and choose <b>Asset-&gt;Import Settings...</b> from the main menu.
</li><li> The Texture inspector pops up; select the 24 bit RGB format and enable 'Generate Bump map':<br /> <img class='figure' src='images/HOWTO-bumpmap-2.jpg' />
</li><li> In the material inspector on the right, select 'Bumped' from the Shader drop-down:<br /><img class='figure' src='images/HOWTO-bumpmap-3.jpg' />
</li><li> Drag your texture from the project window to the 'Bumpmap' texture slot:<br /><img class='figure' src='images/HOWTO-bumpmap-4.jpg' />
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>Your object now has a bump map applied:
</p>

<p><img class='figure' src='images/HOWTO-bumpmap-5.jpg' />
</p>

<h2>Hints</h2>
<ul><li> To make the bumps more noticable, either use the Bumpyness slider in the texture import settings or blur the texture in photoshop. Play with both to get a feel for it.
</li></ul>






<p>A detail texture is small, fine pattern which is faded in as you approach a surface, for example wood grain, imperfections in stone, or earthly details on a terrain.
</p>

<p>Detail textures must tile in all directions. Color values from 0-127 makes the object it's applied to darker, 128 doesn't change anything, and lighter colors makes the object lighter. It's very important that the image is centered around 128 - otherwise the object it's applied to will get lighter or darker as you approach.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Draw or find a grayscale image of the detail texture. <br><img class='figure' src='images/HOWTO-UseDetailTexture-0.jpg' />
</li><li> Save the image next to your main texture.
</li><li> In Unity, select the image and choose <b>Asset->Import Settings...</b> from the main menu.
</li><li> The Texture importer pops up; Under mip maps, enable <b>Fades Out</b> and set the sliders to something like this:<br> <img class='figure' src='images/HOWTO-UseDetailTexture-1.jpg' /><br> The top slider determines how small the texture should before before beginning to fade out, and the bottom determines how far away it is completely gone
</li><li> In the material inspector on the right, select 'DiffuseDetail' from the Shader drop-down:<br><img class='figure' src='images/HOWTO-UseDetailTexture-2.jpg' />
</li><li> Drag your texture from the project window to the 'Detail' texture slot.
</li><li> Click the texture in the material inspector, and set the scale values to a high value below <br> <img class='figure' src='images/HOWTO-UseDetailTexture-3.jpg' />
</li></ol>

<p></div></div></td></tr></table>
</p>





<p>Cubemaps are used by the <i>Reflective</i> builtin shaders. To build one, you either create six 2D textures and create a new Cubemap asset, or built Cubemap from a single square texture.
</p>

<p>More details are in <a href="../Components/class-CubemapTexture.html">Cubemap Texture</a> documentation page.
</p>



<p>A skybox is a 6-sided cube that is drawn behind all graphics in the camera. To create one, do as follows:
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Make 6 textures that correspond to each of the 6 sides of the skybox and import by putting them into the Assets folder.
</li><li> For each texture you need to change the wrap mode from Repeat to Clamp. If you don't do this colors on the edges will not match up:<br /> <img class='figure' src='images/HOWTO-UseSkybox-0.jpg' />
</li><li> Create a new material by choosing <b>Assets-&gt;Create-&gt;Material</b> from the main menu.
</li><li> Select the shader drop-down in the top of the inspector, choose <b>RenderFX-&gt;Skybox</b> from the drop-down.
</li><li> Assign the 6 textures to each texture slot in the material. You can do this by dragging each texture from the project view onto each slot in the material.<br /> <img class='figure' src='images/HOWTO-UseSkybox-1.jpg' />
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>To Assign the skybox to the scene you're working on, do like this:
<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Choose <b>Edit-&gt;Render Settings</b> from the main menu.
</li><li> Drag the material you created above to the Skybox Material slot in the inspector.
</li></ol>

</div></div></td></tr></table>
</p>




<p>Mesh Particle Emitters are generally used when you need high control over where to emit particles.
For example when you want to do a flaming sword.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Drag a mesh into the scene.
</li><li> Remove the MeshRenderer by right-clicking on the MeshRenderer's inspector titlebar and choosing Remove Component.
</li><li> Choose MeshParticleEmitter from the Component-&gt;Particles menu
</li><li> Choose ParticleAnimator from the Component-&gt;Particles menu
</li><li> Choose ParticleRenderer from the Component-&gt;Particles menu
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>You should now see particles emitting from the mesh.
</p>

<p>Play around with the values in the <a href="../Components/class-MeshParticleEmitter.html">MeshParticleEmitter</a>.
</p>

<p>Especially enable Interpolate Triangles in the Mesh Particle Emitter Inspector and set Min Normal Velocity and Max Normal Velocity to 1.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Choose Material from the Assets -&gt; Create menu
</li><li> In the shader popup select the Particles/Additive shader
</li><li> Drag&amp;Drop a texture from the project view onto the texture slot in the material
</li><li> Drag the material from project view on the particle system in the scene view
</li></ol>

<p></div></div></td></tr></table>
</p>

<p>You should now see textured particles emitting from the mesh.
</p>

<h2>See Also</h2>
<ul><li> <a href="../Components/class-MeshParticleEmitter.html">MeshParticleEmitter</a>
</li></ul>



<p>Here's how to do a splash screen or any other type of full-screen image in Unity. This HOWTO takes care to work for multiple different resolutions and aspect ratios.
</p>

<ol><li> First you need a big texture. Ideally textures should be power of two in size. You might for example use 1024x512 as this fits most screens.
</li><li> Make a box using the &quot;GameObject-&gt;Create Other-&gt;Cube&quot; menu item.
</li><li> Scale it to be in 16:9 format by switching the Inspector to &quot;Full&quot; mode, then entering 16 and 9 as the first two value in the Scale:<img class='figure' src='images/HOWTO-SplashScreen-0.jpg' />
</li><li> Put the texture on a cube and make a camera to point at it. Place the camera at such a distance so that the cube is still visible on a widescreen.
</li><li> Apply the texture to the box by dragging it on.
</li></ol>



<p>Unity ships with a few Light Cookies. They can be found in Standard Assets/Light Cookies.
Sometimes you want to create your own though.
</p>

<p>A light cookie modulates the color of the light with the alpha channel, thus allows you to
</p>

<p>An interesting way to add a lot of visual detail to your scenes is to use cookies - greyscale textures you use to control the precise look of in-game lighting. This is fantastic for making moving clouds and giving an impression of dense foilage. The Light page has more info on all this, but the main thing is that for textures to be usable for cookies, the following properties need to be set:
</p>

<p><img class='figure' src='images/HOWTO-LightCookie-0.jpg' />
</p>

<p>To create a light cookie for a spot light:
</p>

<ol><li> Paint a cookie texture in photoshop. The image should be grayscale. White pixels means full lighting intensity, black pixels mean no lighting. The borders of the texture need to be completely black, otherwise the light will appear to leak outside of the spotlight.
</li><li> In the texture inspector change the &quot;Repeat&quot; Wrap mode to &quot;Clamp&quot;
</li><li> Select the Texture and bring up the Import Settings using the Assets -&gt; Import Settings... menu.
</li></ol>

<p>Use the following settings:
</p>
<ol><li> Enable Border Mipmaps
</li><li> Enable Build Alpha From Grayscale (This way you can make a grayscale cookie and unity converts it to a alpha map automatically)
</li><li> Set the Texture Format to Alpha 8 Bit
</li></ol>
<p><img class='figure' src='images/HOWTO-LightCookie-1.jpg' />
</p>

<p>To create a light cookie for a directional light:
</p>




<p>Some 3D art packages export their models so that the z-axis faces upwards. Most of the standard scripts in Unity assume that the y-axis is upwards. It is usually easier to fix the rotation in Unity than to modify the scripts to make things fit.
</p>

<p><img class='figure' src='images/HOWTO-FixZAxisIsUp-0.jpg' />
</p>

<p><i>Your model with z-axis point upwards</i>
</p>

<p>If at all possible it is recommended that you fix the model in your 3d modeller to have the y-axis face upwards before exporting.
</p>

<p>If this is not possible, you can fix it in Unity by adding an extra parent transform:
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Create an empty game object using the <b>GameObject -&gt; Create Empty</b> menu
</li><li> Place the new game object so that it is at the center of your mesh or which ever point you want your object to rotate around.
</li><li> Drag the mesh on the empty game object
</li></ol>

<p></div></div></td></tr></table>
</p>

<p><img class='figure' src='images/HOWTO-FixZAxisIsUp-1.jpg' />
</p>

<p><i>The model with an extra empty transform</i>
</p>




<p>Unity includes several water prefabs (including needed shaders, scripts and art assets) among it's <a href="../Manual/HOWTO-InstallStandardAssets.html">standard asset packages</a>. Indie version includes a basic water, while Unity Pro includes a reflective and reflective+refractive water prefabs.
</p>

<p><img class='figure' src='images/HOWTO-Water-0.jpg' />
</p>

<p><i>Reflective&amp;Refractive water on the left, Reflective water on the right</i>
</p>

<h2>Water setup</h2>

<p>In most cases you just drag a prefab into your scene (make sure to have the <a href="../Manual/HOWTO-InstallStandardAssets.html">standard assets installed</a>):
</p>
<ul><li> Unity Indie has <b>Daylight Water</b> and <b>Nighttime Water</b> in <i>Standard Assets/Water</i>.
</li><li> Unity Pro has <b>Daylight Reflective Water</b>, <b>Nighttime Reflective Water</b> and <b> Reflective-Refractive Water</b> in <i>Pro Standard Assets/Water</i> (but it needs some assets from <i>Standard Assets/Water</i> as well).
</li></ul>

<p>The prefab uses oval-shaped mesh for the water. If you need to use different <a href="../Components/class-Mesh.html">Mesh</a> the easiest way is just changing it in Mesh Filter of water object:
</p>

<p><img class='figure' src='images/HOWTO-Water-1.jpg' />
</p>


<h2>Creating water from scratch (Advanced)</h2>

<p>The simple water in Unity Indie does not require any special setup; the most you can do is tweak values of the material. The rest of this section will describe how to setup reflective and/or refractive water from scratch (without using prefabs described above).
</p>

<p>Water needs:
</p>
<ul><li> A geometry of the water. This should be flat mesh, oriented horizontally. UV coordinates are not required. The water game object should use Water layer.
</li><li> One of water materials to render with (''FX/WaterPlane ...&quot;).
</li><li> A camera and a RenderTexture for the reflections. Refractive water needs additional camera and render texture.
<ul><li> The camera(s) should be placed exactly on the water plane, and transform's y-axis should point upwards.
</li><li> Cameras should exclude Water layer from their culling mask. This makes water itself not visible in reflections/refractions.
</li><li> Target textures should be setup accordingly (e.g. reflections render texture for reflection camera).
</li><li> Attach <i>Pro Standard Assets/Water/Sources/ReflectionRenderTexture</i> script to the cameras. This script places the controlled camera into correct position (e.g. for reflection camera it reflects main camera along water plane), sets up the correct culling mode and sets up oblique projection matrix so that geometry gets properly clipped along water plane.
</li></ul></li><li> In water material, the render textures connected to corresponding properties.
</li></ul>

<h2>Properties in water materials</h2>
<p>These properties are used in Reflective&amp;Refractive water shader. Most of them are used in other water shaders as well.
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Wave scale</nobr></b></td><td> Scaling of waves bumpmap. The smaller the value, the larger water waves.
</td></tr><tr><td><b><nobr> Reflection/refraction distort</nobr></b></td><td> how much reflection/refraction is distorted by the waves bumpmap.
</td></tr><tr><td><b><nobr> Refraction color</nobr></b></td><td> additional tint for refraction.
</td></tr><tr><td><b><nobr> Environment reflection/refraction</nobr></b></td><td> render textures for real-time reflection and refraction.
</td></tr><tr><td><b><nobr> Bumpmap</nobr></b></td><td> Defines the shape of the waves. The final waves are produced by combining two these bumpmaps, each scrolling at different direction, scale and speed. The second bumpmap is twice smaller than the first one.
</td></tr><tr><td><b><nobr> Wave speed</nobr></b></td><td> Scrolling speed for first bumpmap (1st and 2nd numbers) and the second bumpmap (3rd and 4th numbers).
</td></tr><tr><td><b><nobr> Fresnel</nobr></b></td><td> A texture with alpha channel controlling the Fresnel efffect - how much reflection vs. refraction is visible, based on viewing angle.
</td></tr></tr></table>
</p>

<p>The rest of properties are not used by Reflective&amp;Refractive shader by itself, but need to be set up in case user's video card does not suppor it and must fallback to the simpler shader:
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
Color ramp/cube and fresnel</nobr></b></td><td> A texture that defines water color (RGB) and Fresnel effect (A) based on viewing angle.
</td></tr><tr><td><b><nobr> Horizon color</nobr></b></td><td> The color of the water at horizon. <i>(Used only in the simple water shader)</i>
</td></tr><tr><td><b><nobr> Fallback texture</nobr></b></td><td> Texture used to represent the water on really old video cards, if none of better looking shaders can't run on it.
<p></td></tr></tr></table>
</p>








<p>Unity supports importing from a lot of 3D applications. Choose the one you're working with below:
</p>
<ul><li> <a href="../Manual/HOWTO-ImportObjectMaya.html">Maya</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectCinema4D.html">Cinema 4D</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectMax.html">3D Studio MAX</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectCheetah3D.html">Cheetah3D</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectModo.html">Modo</a>
</li><li> <a href="../Manual/HOWTO-importObjectLightwave.html">Lightwave</a>
</li><li> <a href="../Manual/HOWTO-ImportObjectBlender.html">Blender</a>
</li></ul>

<h2> Other applications</h2>
<p>Unity can read <b>.FBX</b>, <b>.3DS</b>, <b>.dxf</b> and <b>.obj</b> files, so if your program can export to this format you're home free. FBX exporters for popular 3D packages can be found <a class="wiki"  href="http://autodesk.com/fbx">here</a>.
</p>

<h2>Hints</h2>
<ul><li> Store textures in a folder called <b>Textures</b> next to the exported mesh. This will guarantee that Unity can always find the Texture and automatically connect the Texture to the Material. For more information, see the <a href="../Components/class-Texture2D.html">Textures</a> reference.
</li></ul>

<h2>See Also</h2>
<ul><li> <a href="../Manual/HOWTO-bumpmap.html">How do I use bump maps?</a>
</li><li> <a href="../Components/class-Mesh.html">Mesh Import Settings</a>
</li><li> <a href="../Manual/HOWTO-FixZAxisIsUp.html">Fixing a mesh that has the z-axis facing upwards</a>
</li></ul>



<p>If you make your 3D objects in 3dsMax, you can export them into Unity using the <b>Autodesk .FBX</b> format.
</p>

<ol><li> Download the latest fbx exporter from <a class="wiki"  href="http://autodesk.com/fbx">here</a> and install it.
</li><li> Export your scene (<b>File-&gt;Export</b> or <b>File-&gt;Export Selected</b>) in <b>.fbx</b> format on your PC. Using default export options should be ok.
</li><li> Move the exported fbx file into your Unity project folder on the Mac.
</li><li> When you switch back into Unity, the <b>.fbx</b> file is imported automatically.
</li><li> Drag the file from the project window into the scene view.
</li></ol>

<h2> Unity currently imports from 3ds Max</h2>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> Meshes with vertex colors, normals and UVs
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li><li> Animations FK &amp; IK
</li><li> Bone based animations
</li></ol>

<h2> Exporter options</h2>

<p>Using default FBX exporter options (that basically export everything) should be ok in all cases.
</p>

<p><img class='figure' src='images/HOWTO-ImportObjectMax-0.jpg' />
</p>

<p><i>Default FBX exporter options (for fbx plugin version 2006.08)</i>
</p>



<p>Unity natively imports Blender files. To get started, simply place your <b>.blend</b> file in your project's assets folder.
When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<p>If you modify your .blend file, Unity will automatically update whenever you save.
</p>

<h2> Unity currently imports</h2>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> All objects with position, rotation and scale.
</li><li> Meshes with vertices, polygons, triangles, UV's and Normals.
</li></ol>

<h4>Requirements</h4>
<ol><li> You need to have at least Blender version 2.4 installed.
</li></ol>

<p>Textures and diffuse color are not assigned automatically but you can easily do this by dragging the texture onto the mesh in the scene view in Unity.
</p>

<p>Animation is currently not imported from Blender; this is a limitation of Blender's Collada exporter. As soon as Blender's Collada exporter supports this Unity will be updated to import animations from Blender.
</p>



<p>Unity natively imports Cinema 4D files. To get started, simply place your <b>.C4D</b> file in your project's assets folder.
When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<p>If you modify your .c4d file, Unity will automatically update whenever you save.
</p>

<h3>Unity currently imports</h3>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> Meshes with UV's, Normals
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li><li> Animations FK (IK needs to be manually baked)
</li><li> Bone based animations
</li></ol>

<p>Unity does not import Point Level Animations (PLA) at the moment. Use Bone based animations instead.
</p>

<h4>Animated Characters using IK</h4>

<p>If you are using IK to animate your characters in Cinema 4D, you have to bake the IK before exporting using the Plugins -&gt; Mocca -&gt; Cappucino menu. If you don't bake your IK prior to importing into Unity, you will most likely only get animated locators but no animated bones.
</p>

<h4>Requirements</h4>
<ol><li> You need to have at least Cinema 4D version 8.5 installed to import the .C4D file
</li></ol>

<p>If you don't have Cinema 4D installed on your machine but want to import a Cinema 4D file from another machine, you can export to the fbx format, which Unity imports natively.
</p>
<ol><li> Open the Cinema 4D file
</li><li> In Cinema 4D choose <b>File -&gt; Export-&gt; FBX 6.0</b>
</li><li> Place the exported fbx file in the Unity project folder. Unity will now automatically import the fbx file.
</li></ol>

<h4>Hints</h4>
<ol><li>To maximize import speed when importing Cinema 4D files. Go to the Cinema 4D preferences <b>Edit -&gt; Preferences</b> and select the FBX 6.0 preferences. Now uncheck <b>Embed Textures</b>.
</li></ol>


<h4> Behind the import process (Advanced)</h4>
<p>When Unity imports a Cinema 4D file it will automatically install a Cinema 4D plugin and launch Cinema 4D in the background. Unity then communicates with Cinema 4D to convert the .C4D file into a format Unity can read. The first time you import a .c4d time and Cinema 4D is not open yet it will take a short while to launch it but afterwards import .c4d files will be very quick.
</p>



<p>You can import meshes and animations from Lightwave using the FBX plugin for Lightwave.
</p>

<h2>Unity currently imports</h2>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> Meshes with UV's and Normals
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li><li> Animations
</li><li> Bone based animations
</li></ol>

<h3> Installation</h3>
<p>Download the latest Lightwave FBX exporter from:
</p>
<h3> By downloading these plugins you automatically agree to <a class="wiki"  href="http://www.otee.dk/lightwave_plugins/License.txt">this</a> license.</h3>
<p><a class="wiki"  href="http://www.otee.dk/lightwave_plugins/mbr_FBX200508_LW80_MACOS.pkg.sit"> os x lighwave 8.0 plugin</a> <br />
<a class="wiki"  href="http://www.otee.dk/lightwave_plugins/mbr_FBX200508_LW82_MACOS.pkg.sit"> os x lighwave 8.2 plugin</a> <br />
<a class="wiki"  href="http://www.otee.dk/lightwave_plugins/mbr_FBX200508_LW80_WIN.zip"> windows lighwave 8.0 plugin</a> <br />
<a class="wiki"  href="http://www.otee.dk/lightwave_plugins/mbr_FBX200508_LW82_WIN.zip"> windows lighwave 8.2 plugin</a> <br />
</p>


<p>There are three versions of the plugin, one for LightWave 7.5, one for LightWave 8.0 and one for LightWave 8.2. Make sure you have the correct version: the LW7 plugin doesn't work properly with LW8.
</p>

<p>The plugin comes in a OS X package. If  you double click the package to install it, the installer will try put it in the correct folder. If it can't find your LightWave plugin folder, it will create its own LightWave folder in your Application folder and dump it there. If the latter occurs you should move it to your LightWave plugin folder (or any sub-folder). Once there you have to add the plugin to LightWave via the &quot;Edit Plugins&quot; panel (option-F11) -  see the LightWave manual for more details on how to add plugins.
</p>

<p><img class='figure' src='images/HOWTO-importObjectLightwave-0.jpg' />
</p>

<p>Once added to LightWave the plugin is acessible via the Generics menu (on the Utiliies) tab.  If the Generic menu is not present you will have to add it using the Config Menus panel. In the latter panel it can be found in the Plug-ins category and is calld &quot;Generic Plugins&quot;. Add it to any convenient menu (see the LightWave manual for more details on how to do this).
</p>

<p>More information about installation can also be found in the release notes that can downloaded with the installer.
</p>

<h2> Exporting</h2>
<p>All objects and animations have to be exported from Layout (there is no Modeler FBX exporter).
</p>

<h3>1. Select Export to FBX from the Generics menu</h3>

<p><img class='figure' src='images/HOWTO-importObjectLightwave-1.jpg' /> <img class='figure' src='images/HOWTO-importObjectLightwave-2.jpg' />
</p>

<h3>2. Select the appropriate settings in the fbx export dialog</h3>
<ul><li> Select the fbx file name. Make sure to save the exported fbx file in the Assets folder of your current Unity project.
</li><li> In the FBX dialogue panel you MUST select &quot;Embed Textures&quot; else the exported object will have no UVs. This is a bug in the lightwave fbx exporter and will be fixed in a future version according to Alias.
</li><li> If you want to export animations into unity you must have &quot;Animations&quot; checked. You also need to have &quot;Lights&quot; or &quot;Cameras&quot; checked.
</li><li> To change the name of the exported animation clip in unity, change the name from &quot;LW Take 001&quot; to your liking.
</li></ul>

<p><img class='figure' src='images/HOWTO-importObjectLightwave-3.jpg' />
</p>

<h3>3. Switch to unity.</h3>
<ul><li> Unity will automatically import the fbx file and automatically generate materials for the textures.
</li><li> Drag the imported fbx file from the project view into the scene view.
</li></ul>

<p><img class='figure' src='images/HOWTO-importObjectLightwave-4.jpg' />
</p>


<h2>Important notes</h2>
<ul><li>  You must select &quot;Embed Textures&quot; in the FBX panel when exporting or no UVs are exported
</li><li>  If you want to export animations you must enable &quot;Animations&quot; and either &quot;Camera&quot; or &quot;Lights&quot;.
</li><li>  It is strongly recommended to always place your textures in a folder called &quot;Textures&quot; next to the fbx file. This will guarantee that Unity can always find the Texture and automatically connect the texture to the material.
</li></ul>



<p>Unity natively imports Maya files. To get started, simply place your <b>.mb</b> or <b>.ma</b> file in your project's assets folder.
When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<h2> Unity currently imports from Maya</h2>
<ol><li> All objects with pivot points, position, rotation and scale
</li><li> Meshes with vertex colors, normals and up to 2 UV sets
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li><li> Animations FK &amp; IK
</li><li> Bone based animations
</li></ol>

<p>Unity does not import blend shapes. Use Bone based animations instead. Unity automatically triangulates polygonal meshes when importing. Thus there is no need to do this manually in Maya.
</p>

<p>If you are using IK to animate characters you have to select the imported .mb file in project view and choose <b>Assets -&gt; Import Settings...</b>. In the import settings dialog, you have to choose <b>Bake IK &amp; Simulation</b>.
</p>


<h2>Requirements</h2>
<p>In order to import Maya <b>.mb</b> and <b>.ma</b> files, you need to have Maya installed on the machine you are using Unity to import the .mb/.ma file. Maya 5.0 and up is supported.
</p>

<p>If you don't have Maya installed on your machine but want to import a Maya file from another machine, you can export to the fbx format, which Unity imports natively.
</p>
<ol><li> Open the Maya file
</li><li> If you don't have the fbx plugin already installed. Download and install it from <a class="wiki"  href="http://www.alias.com/eng/products-services/fbx/download.shtml">here</a>.
</li><li> Place the exported fbx file in the Unity project folder. Unity will now automatically import the fbx file.
</li></ol>

<h3> Behind the import process (Advanced)</h3>
<p>When Unity imports a Maya file it will launch Maya in the background. Unity then communicates with Maya to convert the .mb file into a format Unity can read. The first time you import a Maya file in Unity, Maya has to launch in a command line process, this can take around 20 seconds, but the second time importing will be very quick.
</p>



<p>Unity imports from Modo through their pipelining features using fbx. In Modo 201, simply save your modo scene as an <b>.fbx</b> file to the project folder. When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<p>If you modify the .fbx file, Unity will automatically update whenever you save.
</p>

<h2> Unity currently imports</h2>
<ol><li> All objects with position, rotation and scale.
</li><li> Meshes with vertices, normals and UV's
</li><li> Materials with Texture and diffuse color. Multiple materials per mesh.
</li></ol>



<p>Unity natively imports Cheetah3D files. To get started, simply place your <b>.jas</b> file in your project's assets folder.
When you switch back into Unity, the scene is imported automatically and will show up in the project view.
</p>

<p>To see your model in Unity, simply drag it from the project view into the scene view.
</p>

<p>If you modify your .jas file, Unity will automatically update whenever you save.
</p>

<h2> Unity currently imports from Cheetah3D</h2>
<ol><li> All objects with position, rotation and scale.
</li><li> Meshes with vertices, polygons, triangles, UV's and Normals.
</li><li> Animations
</li><li> Materials with diffuse color and textures
</li></ol>

<h4>Requirements</h4>
<ol><li> You need to have at least Cheetah3D 2.6 installed.
</li></ol>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-exportpackage.html">HOWTO-exportpackage</a></li><li class="toclevel"><a href="../Manual/HOWTO-InstallStandardAssets.html">HOWTO-InstallStandardAssets</a></li></ul>
</p>



<p>Unity stores a lot of metadata about your assets - import settings, links to other assets, etc... Here's how to move them between projects, while preserving all this info.
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'>
<ol><li> Select all the asset files you want to export from the project window.
</li><li> Choose <b>Assets-&gt;Export Package...</b> from the main menu.
</li><li> Save the package somewhere
</li><li> Open the project you want to import the assets to.
</li><li> Choose <b>Assets-&gt;Import Package...</b> from the main menu.
</li><li> Select the package file you created in step 3
</li></ol>

<p></div></div></td></tr></table>
</p>

<h2>Hints</h2>
<ul><li> If you place the assets file in the Standard Packages folder next to your Unity application, they will appear in the Create New Project dialog.
</li></ul>



<p>Unity ships with Standard Assets and Pro Standard Assets.
</p>

<p>Standard Assets contain useful things like a first person controller, some skyboxes, flares, a water plane prefab and common camera scripts.
</p>

<p>Pro Standard Assets contain all kinds of Image Effects, like <a href="../Components/script-GlowEffect.html">Glow</a>, <a href="../Components/script-MotionBlur.html">Motion Blur</a>, <a href="../Components/script-ColorCorrectionEffect.html">Color Correction</a>, <a href="../Components/script-NoiseEffect.html">Noise</a> and others; as well as several advanced <a href="../Manual/HOWTO-Water.html"> Water prefabs</a>.
</p>

<h3> Installing</h3>
<p>When creating a new project Unity automatically installs the Standard Assets and Pro Standard Assets for Pro users.
</p>

<h3> Upgrading</h3>

<p>Sometimes you might want to upgrade your Standard Assets, for example because a new version of Unity ships with new Standard Assets:
</p>

<ol><li> Open your project.
</li><li> Choose <b>Assets -&gt; Import Package</b> from the menu.
</li><li> Select <i>Standard Assets.unitypackage</i> or <i>Pro Standard Assets.unitypackage</i>.
</li><li> A list of new or replaced assets will be presented, click <i>Apply Now</i>.
</li></ol>



<p><ul class="toc"><li class="toclevel"><a href="../Manual/HOWTO-First Person Walkthrough.html">HOWTO-First Person Walkthrough</a></li></ul>
</p>



<p>Here's how you can make a simple first person walk-through with your own artwork:
</p>

<ol><li> Import your level. See <a href="../Manual/HOWTO-importObject.html">here</a> on how to import geometry from your art package into Unity.
</li><li> Select the imported model file and choose <b>Assets -&gt; Import Settings ...</b>. Enable <b>Meshes have colliders</b>.
</li><li> Locate the &quot;Standard Assets/Prefabs/First Person Controller&quot; in the project view and drag it into the scene view.
</li><li> Make sure that the size of your level is correct. The First Person Controller is exactly 2 meters high, so if your level doesn't fit the size of the controller, you should adjust the scale of the level size. Getting scale right is critical for physical simulation otherwise objects feel like they are floating or too heavy. You can either scale the model in the scene view using the scale handle or use the <b>Assets -&gt; Import Settings ...</b> on the model file.
</li><li> Move the First Person Controller to be at the start location using the transform handles. It is critical that the first person controller does not intersect any level geometry, when starting the game. (Otherwise it will be stuck in the geometry)
</li><li> Remove the default camera &quot;Main Camera&quot; in the hierarchy view. The First person controller already has it's own camera.
</li><li> Hit Play to walk around in your own level.
</li></ol>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/Optimizing Graphics Performance.html">Optimizing Graphics Performance</a></li><li class="toclevel"><a href="../Manual/Shaders.html">Shaders</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/ShaderTut1.html">ShaderTut1</a></li><li class="toclevel"><a href="../Manual/ShaderTut2.html">ShaderTut2</a></li><li class="toclevel"><a href="../Manual/SL-Shader.html">SL-Shader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Properties.html">SL-Properties</a></li><li class="toclevel"><a href="../Manual/SL-SubShader.html">SL-SubShader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Pass.html">SL-Pass</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Material.html">SL-Material</a></li><li class="toclevel"><a href="../Manual/SL-CullAndDepth.html">SL-CullAndDepth</a></li><li class="toclevel"><a href="../Manual/SL-SetTexture.html">SL-SetTexture</a></li><li class="toclevel"><a href="../Manual/SL-Fog.html">SL-Fog</a></li><li class="toclevel"><a href="../Manual/SL-AlphaTest.html">SL-AlphaTest</a></li><li class="toclevel"><a href="../Manual/SL-Blend.html">SL-Blend</a></li><li class="toclevel"><a href="../Manual/SL-NameAndTags.html">SL-NameAndTags</a></li><li class="toclevel"><a href="../Manual/SL-BindChannels.html">SL-BindChannels</a></li></ul><li class="toclevel"><a href="../Manual/SL-UsePass.html">SL-UsePass</a></li><li class="toclevel"><a href="../Manual/SL-GrabPass.html">SL-GrabPass</a></li></ul><li class="toclevel"><a href="../Manual/SL-Fallback.html">SL-Fallback</a></li></ul><li class="toclevel"><a href="../Manual/SL-RenderPipeline.html">SL-RenderPipeline</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Attenuation.html">SL-Attenuation</a></li></ul><li class="toclevel"><a href="../Manual/SL-BuiltinValues.html">SL-BuiltinValues</a></li><li class="toclevel"><a href="../Manual/Reference - Structure.html">Reference - Structure</a></li><li class="toclevel"><a href="../Manual/Reference - Values.html">Reference - Values</a></li><li class="toclevel"><a href="../Manual/ShaderLab Cheat Sheet.html">ShaderLab Cheat Sheet</a></li></ul><li class="toclevel"><a href="../Manual/Reducing File size.html">Reducing File size</a></li><li class="toclevel"><a href="../Manual/Web Player Deployment.html">Web Player Deployment</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/Web-LoaderImages.html">Web-LoaderImages</a></li><li class="toclevel"><a href="../Manual/Web-GeneratedHtml.html">Web-GeneratedHtml</a></li><li class="toclevel"><a href="../Manual/Web-BrowserCommunication.html">Web-BrowserCommunication</a></li></ul><li class="toclevel"><a href="../Manual/Plugins.html">Plugins</a></li><li class="toclevel"><a href="../Manual/Build Player Pipeline.html">Build Player Pipeline</a></li></ul>
</p>



<p>Making your game run smoothly is of prime importance to its success. Thankfully Unity is there with you. We have spent a lot of time and energy making it run fast on a wide variety of hardware. Below are some simple guidelines to maximizing the speed of your game.
</p>

<h2> In summary - combine, combine, combine</h2>

<ul><li> If you care about performance, combine meshes.
</li><li> If you care about performance make sure all your combined meshes also share the same material and texture.
</li></ul>

<h2> In detail:</h2>

<p>Todays graphics cards are really good at pushing a lot of polygons but they have quite some overhead for every batch that you submit to the graphics card. So if you have a 100 triangle object it is going to be just as expensive to render as a 1500 poly object. The sweet spot for optimal rendering performance is somewhere around 1500-4000 triangles per mesh.
</p>

<p>You only pay rendering cost for objects that have a mesh renderer attached. And you only pay for those that are within the view frustum. There is no attached rendering cost to having a lot of empty game objects in your scene.
</p>

<ul><li> The best way to improve rendering performance, is to combine objects together so each mesh has around 1500 or more triangles and uses only one material for the entire mesh.
</li></ul>

<p>It is important to understand that just combining two objects which don't share a material does not give you any performance increase at all. if you want to combine effectively you need to make sure your mesh uses only one material after you have combined it.
</p>

<p>There is one thing to be aware of when combining objects though.
If you use a lot of small lights in your scene, it might make sense to combine only objects that are close to each other.
</p>

<p>The rendering cost for a mesh that has multiple materials is the same as having multiple renderers for each material. The most common reason why you have multiple materials is because two meshes don't share the same textures. So if you want to optimize rendering performance you need to make sure that the objects you combine share textures.
</p>


<ul><li> Unity is very good at pushing lots of polygons. Unity uploads all geometry to the graphics card for good cache utilization and optimal data alignment.
</li><li> You simply have to make sure that the graphics card doesn't have to handle a huge amount of batches.
</li><li> The number of pixel lights affecting an object heavily affects performance.
</li></ul>

<p>If you want to have the best performance and don't care about bumpmapping or per pixel lighting just go to Edit -&gt; Render Settings ... and set pixel light count to zero. This will simply use vertex lighting for all objects.
This means all geometry will be rendered only once every frame. This is an extremely useful LOD setting, so your game can run fine on older graphics cards.
</p>

<h3> Pixel lights</h3>

<p>If you use pixel lighting, then we have to render every object as many times as we have pixel lights that affect the object.
If you combine two objects that are very far apart, it might increase the size of the object and now you have a lot of lights affecting this big object. If your objects were seperate however, the light wouldn't have to be applied on the part of the mesh which is far away. This can result in rendering the combined mesh as many times as the uncombined mesh thus you didn't save anything.
</p>

<p>When rendering a mesh unity finds all lights surrounding the mesh. It then figures out what lights affect the mesh the most. The Edit -&gt; Render Settings are used to modify how many of the lights end up as pixel lights and how many as vertex lights.
</p>

<p>Every light calculates it's importance based on how far away it is from the mesh and how intense it is.
</p>

<p>Some lights are more important than others depending on the game context. For this every light has a Render Mode setting which can be set to &quot;Force Pixel&quot; or &quot;Force Vertex&quot;.
</p>

<p>Imagine the player's car with head lights driving through the night. The head light is the most important light in the game. Thus set the head lights Render Mode to &quot;Force Pixel&quot;.
</p>

<p>If you have a light that isn't very important and also visually doesn't gain much from being a pixel light, set the lights Render Mode to &quot;Force Vertex&quot;. This way you don't waste rendering performance without gaining any visual quality.
</p>



<p>All rendering in Unity is done with <i>Shaders</i> - small scripts that let you configure the how the OpenGL hardware is set up for rendering. Unity ships with 30+ shaders but you can extend this by making more yourself.
</p>

<p>Read on for how!
</p>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/ShaderTut1.html">ShaderTut1</a></li><li class="toclevel"><a href="../Manual/ShaderTut2.html">ShaderTut2</a></li><li class="toclevel"><a href="../Manual/SL-Shader.html">SL-Shader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Properties.html">SL-Properties</a></li><li class="toclevel"><a href="../Manual/SL-SubShader.html">SL-SubShader</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Pass.html">SL-Pass</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Material.html">SL-Material</a></li><li class="toclevel"><a href="../Manual/SL-CullAndDepth.html">SL-CullAndDepth</a></li><li class="toclevel"><a href="../Manual/SL-SetTexture.html">SL-SetTexture</a></li><li class="toclevel"><a href="../Manual/SL-Fog.html">SL-Fog</a></li><li class="toclevel"><a href="../Manual/SL-AlphaTest.html">SL-AlphaTest</a></li><li class="toclevel"><a href="../Manual/SL-Blend.html">SL-Blend</a></li><li class="toclevel"><a href="../Manual/SL-NameAndTags.html">SL-NameAndTags</a></li><li class="toclevel"><a href="../Manual/SL-BindChannels.html">SL-BindChannels</a></li></ul><li class="toclevel"><a href="../Manual/SL-UsePass.html">SL-UsePass</a></li><li class="toclevel"><a href="../Manual/SL-GrabPass.html">SL-GrabPass</a></li></ul><li class="toclevel"><a href="../Manual/SL-Fallback.html">SL-Fallback</a></li></ul><li class="toclevel"><a href="../Manual/SL-RenderPipeline.html">SL-RenderPipeline</a></li><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Attenuation.html">SL-Attenuation</a></li></ul><li class="toclevel"><a href="../Manual/SL-BuiltinValues.html">SL-BuiltinValues</a></li><li class="toclevel"><a href="../Manual/Reference - Structure.html">Reference - Structure</a></li><li class="toclevel"><a href="../Manual/Reference - Values.html">Reference - Values</a></li><li class="toclevel"><a href="../Manual/ShaderLab Cheat Sheet.html">ShaderLab Cheat Sheet</a></li></ul>
</p>



<p><i>This tutorial will teach you how you can create your own shaders and make you game look a lot better!</i>
</p>

<p>Unity is equipped with a powerful shading and material language called <b>ShaderLab</b>. In style it is similar to CgFX and Direct3D Effects languages - it describes everything needed to display a material, not just plain vertex/pixel shaders.
</p>

<p>Shaders describe properties that are exposed in Unity's <a href="../Components/class-Material.html">material inspector</a> and multiple shader implementations <i>(SubShaders)</i> targeted at different graphics hardware capabilities, each describing complete OpenGL rendering state, fixed function pipeline setup or vertex/fragment programs to use. Vertex and fragment programs are written in high-level Cg programming language or low-level shader assembly.
</p>

<p>In this tutorial we describe how to write shaders in ShaderLab using both fixed function and programmable pipelines. We assume that the reader has a basic understanding of <a class="wiki"  href="http://opengl.org/documentation/red_book">OpenGL</a> render states, fixed function and programmable pipelines and has some knowledge of <a class="wiki"  href="http://developer.nvidia.com/page/cg_main.html">Cg programming language</a>. Some shader tutorials can be found on <a class="wiki"  href="http://shadertech.com/articles">shadertech website</a>.
</p>

<hr />

<h2> Getting started</h2>

<p>To create a new shader, either choose <b>Assets-&gt;Create-&gt;Shader</b> from the main menu, or duplicate an existing shader, and work from that. The new shader can be edited by double-clicking it in the project view.
</p>

<p>We'll start with a very basic shader:
</p>

<p><pre class='codelisting'>Shader &quot;Tutorial/Basic&quot; {
    Properties {
        _Color (&quot;Main Color&quot;, Color) = (1,0.5,0.5,1)
    }
    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
            }
            Lighting On
        }
    }
}
</pre>
</p>

<p>This simple shader demonstrates one of the most basic shaders possible. It defines a color property called <i>&quot;Main Color&quot;</i> and assigns it a default value of rose-like color (red=100% green=50% blue=50% alpha=100%). It then renders the object by invoking a Pass and in that pass setting the diffuse material component to the property <i>_Color</i> and turning on the vertex lighting.
</p>

<p>To test this shader, create a new material, select the shader from the drop-down menu <i>(Tutorial-&gt;Basic)</i> and assign the material to some object. Tweak the color in the material inspector and watch the changes. Time to move onto more complex things!
</p>

<hr />

<h2> Basic Vertex Lighting</h2>

<p>If you open an existing complex shader, it can be a bit hard to get a good overview. To get you started, we will dissect the built-in <i>VertexLit</i> shader that ships with Unity. This shader uses OpenGL's fixed function pipeline to do per-vertex lighting.
</p>

<p><pre class='codelisting'>Shader &quot; VertexLit&quot; {
    Properties {
        _Color (&quot;Main Color&quot;, Color) = (1,1,1,0.5)
        _SpecColor (&quot;Spec Color&quot;, Color) = (1,1,1,1)
        _Emission (&quot;Emmisive Color&quot;, Color) = (0,0,0,0)
        _Shininess (&quot;Shininess&quot;, Range (0.01, 1)) = 0.7
        _MainTex (&quot;Base (RGB)&quot;, 2D) = &quot;white&quot; { }
    }
    
    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
                Ambient [_Color]    
                Shininess [_Shininess]
                Specular [_SpecColor]
                Emission [_Emission]    
            } 
            Lighting On
            SeperateSpecular On
            SetTexture [_MainTex] {
                constantColor [_Color]
                Combine texture * primary DOUBLE, texture * constant 
            } 
        }
    } 
}
</pre>
</p>

<p>All shaders start with the keyword <b><a href="../Manual/SL-Shader.html">Shader</a></b> followed by a string that represents the name of the shader. This is the name that is shown in the inspector. All code for this shader must be put within the curly braces after it: <b>{ }</b> (called a block).
</p>

<ul><li> The name should be short and descriptive. It does not have to match the <i>.shader</i> file name.
</li><li> To put shaders in submenus in Unity, use slashes - e.g. <i>&quot;MyShaders/Test&quot;</i> would be shown as <i>&quot;Test&quot;</i> in a submenu called <i>&quot;MyShaders&quot;</i>.
</li></ul>

<p>The shader is composed of a <b>Properties</b> block followed by <b>SubShader</b> blocks. Each of these is described in sections below.
</p>

<h3>Properties</h3>

<p>At the beginning of the shader block you can define any properties that artists can edit in the <a href="../Components/class-Material.html">material inspector</a>. In the <i>VertexLit</i> example the properties look like this:
</p>

<p><img class='figure' src='images/ShaderTut1-0.jpg' />
</p>

<p>The properties are listed on separate lines within the <b><a href="../Manual/SL-Properties.html">Properties</a></b> block. Each property starts with the internal name (<b>_Color</b>, <b>_MainTex</b>). After this in parentheses comes the name shown in the inspector and the type of the property. After that, the default value for this property is listed:
</p>

<p><img class='figure' src='images/ShaderTut1-1.jpg' />
</p>

<p>The list of possible types are in the <a href="../Manual/SL-Properties.html">properties reference</a>. The default value depends on the property type. In the example of a color, the default value should be a four component vector.
</p>

<p>We now have our properties defined, and are ready to start writing the actual shader.
</p>

<h3>The Shader Body</h3>

<p><i>Before we move on, let's define the basic structure of a shader file.</i>
</p>

<p>Different graphic hardware has different capabilities. For example, some graphics cards support fragment programs and others don't; some can lay down four textures per pass while the others can do only two or one; etc. To allow you to make full use of whatever hardware your user has, a shader can contain multiple <i>SubShaders</i>. When Unity renders a shader, it will go over all subshaders and use the first one that the hardware supports.
</p>

<p><pre class='codelisting'>
Shader &quot;Structure Example&quot; {
    Properties { /* ...shader properties... }
    SubShader {
    	// ...subshader that uses vertex/fragment programs...
    }
    SubShader {
    	// ...subshader that uses four textures per pass...
    }
    SubShader {
    	// ...subshader that uses two textures per pass...
    }
    SubShader {
    	// ...subshader that might look ugly but runs on anything :)
    }
}
</pre>
</p>

<p>This system allows Unity to support all existing hardware and maximize the quality on each one. It does, however, result in some long shaders.
</p>

<p>Inside each SubShader block you set the rendering state shared by all passes; and define rendering passes themselves. A complete list of available commands can be found in the <a href="../Manual/SL-SubShader.html">subshader reference</a>.
</p>

<h3>Passes</h3>
<p>Each subshader is a collection of passes. For each pass, the object geometry is rendered, so there must be at least one pass. Our <i>VertexLit</i> shader has just one pass:
<pre class='codelisting'>
// ...snip...
Pass {
    Material {
        Diffuse [_Color]
        Ambient [_Color]
        Shininess [_Shininess]
        Specular [_SpecColor]
        Emission [_Emission]    
    } 
    Lighting On
    SeperateSpecular On
    SetTexture [_MainTex] {
        constantColor [_Color]
        Combine texture * primary DOUBLE, texture * constant 
    }
}
// ...snip...
</pre>
</p>

<p>Any commands defined in a pass configures the graphics hardware to render the geometry in a specific way.
</p>

<p>In the example above we have a <b><a href="../Manual/SL-Material.html">Material</a></b> block that binds our property values to the OpenGL's material settings. The command <b>Lighting On</b> turns on the standard vertex lighting, and <b>SeperateSpecular On</b> enables the use of a separate color for the specular highlight.
</p>

<p>All of these command so far map very directly to the fixed function OpenGL hardware model. Consult <a class="wiki"  href="http://opengl.org/documentation/red_book">OpenGL red book</a> for more information on this.
</p>

<p>The next command, <b><a href="../Manual/SL-SetTexture.html">SetTexture</a></b>, is very important. These commands define the textures we want to use and how to mix, combine and apply them in our rendering. <b>SetTexture</b> command is followed by the property name of the texture we would like to use (<i>_MainTex</i> here) This is followed by a <b>combiner block</b> that defines how the texture is applied. The commands in the combiner block are executed for each pixel that is rendered on screen.
</p>

<p>Within this block we set a constant color value, namely the color of the material, <i>_Color</i>. We'll use this constant color below.
</p>

<p>In the next command we specify how to mix the texture with the color values. We do this with the <b>Combine</b> command that specifies how to blend the texture with another one or with a color. Generally it looks like this:
</p>
<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;<b>Combine</b> <i>ColorPart</i><b>,</b> <i>AlphaPart</i></tt>
</p>

<p>Here <i>ColorPart</i> and <i>AlphaPart</i> define blending of color (RGB) and alpha (A) components respectively. If <i>AlphaPart</i> is omitted, then it uses the same blending as <i>ColorPart</i>.
</p>

<p>In our <i>VertexLit</i> example:
</p>
<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;<b>Combine</b> texture * primary DOUBLE<b>,</b> texture * constant</tt>
</p>

<p>Here <b>texture</b> is the color coming from the current texture (here <i>_MainTex</i>). It is multiplied (<b>*</b>) with the <b>primary</b> vertex color. Primary color is the vertex lighting color, calculated from the <i>Material</i> values above. Finally, the result is multiplied by two to increase lighting intensity (<b>double</b>). The alpha value (after the comma) is <b>texture</b> multiplied by <b>constant</b> value (set with <b>constantColor</b> above). Another often used combiner mode is called <b>previous</b> (not used in this shader). This is the result of any previous <i>SetTexture</i> step, and can be used to combine several textures and/or colors with each other.
</p>

<h3>Summary</h3>

<p>Our <i>VertexLit</i> shader configures standard vertex lighting and sets up the texture combiners so that the rendered lighting intensity is doubled.
</p>

<p>We could put more passes into the shader, they would get rendered one after the other. For now, though, that is not nessesary  as we have the desired effect. We only need one SubShader as we make no use of any advanced features - this particular shader will work on any graphics card that Unity supports.
</p>

<p>The <i>VertexLit</i> shader is one of the most basic shaders that we can think of. We did not use any hardware specific operations, nor did we utilize any of the more special and cool commands that ShaderLab and Cg has to offer.
</p>

<p>In the <a href="../Manual/ShaderTut2.html">next chapter</a> we'll proceed by explaining how to write custom vertex &amp; fragment programs using Cg language.
</p>



<p><i>This tutorial will teach you how to write custom vertex and fragment programs in Unity shaders. For a basic introduction to ShaderLab see the <a href="../Manual/ShaderTut1.html">Getting Started tutorial</a>.</i>
</p>

<p>Lets start with a small recap of the general structure of a shader:
</p>

<p><pre class='codelisting'>Shader &quot;MyShaderName&quot; {
    Properties {
        // ... properties here ...
    }
    SubShader {
        // ... subshader for graphics hardware A ...
        Pass {
            // ... pass commands ...
        }
        // ... more passes if needed ...
    }
    SubShader {
        // ... subshader for graphics hardware B ...
    }
    // ... Optional fallback ...
    FallBack &quot; VertexLit&quot;, 1
}
</pre>
Here at the end we introduce a new command:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;<b>FallBack</b> &quot; VertexLit&quot;, 1</tt>
</p>

<p>The <b><a href="../Manual/SL-Fallback.html">Fallback</a></b> command can be used at the end of the shader; it tells which shader should be used if no SubShaders from the current shader can run on user's graphics hardware. The effect is the same as including all SubShaders from the fallback shader at the end. For example, if you were to write a bump-mapped shader, then instead of writing a very basic non-bump-mapped subshader for old graphics cards you can just fallback to builtin <i>VertexLit</i> shader.
</p>

<p>The basic building blocks of the shader are introduced in the <a href="../Manual/ShaderTut1.html">first shader tutorial</a> while the full documentation of <a href="../Manual/SL-Properties.html">Properties</a>, <a href="../Manual/SL-SubShader.html">SubShaders</a> and <a href="../Manual/SL-Pass.html">Passes</a> is in the reference.
</p>

<p>A quick way of building subshaders is to use passes defined in other shaders. The command <b><a href="../Manual/SL-UsePass.html">UsePass</a></b> does just that, so you can reuse shader code in a neat fashion. As an example the following command uses the pass with the name <i>&quot;BASE&quot;</i> from the builtin <i>Glossy</i> shader:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;<b>UsePass</b> &quot; Glossy/BASE&quot;</tt>
</p>

<p>In order for UsePass to work, a name must be given to the pass one wishes to use. The <b><a href="../Manual/SL-NameAndTags.html">Name</a></b> command inside the pass gives it a name:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;<b>Name</b> &quot;<i>MyPassName</i>&quot;</tt>
</p>

<h2> Vertex and fragment programs</h2>

<p>We described a pass that used just a single texture combine instruction in the <a href="../Manual/ShaderTut1.html">first tutorial</a>. Now it is time to demonstrate how we can use vertex and fragment programs in our pass.
</p>

<p>When you use vertex and fragment programs (the so called &quot;programmable pipeline&quot;), most of the hardcoded functionality (&quot;fixed function pipeline&quot;) in the graphics hardware is switched off. For example, using a vertex program turns off standard OpenGL transformations, lighting and texture coordinate generation completely. Similarly, using a fragment program replaces any texture combine modes defined in SetTexture commands; so you can as well just write empty SetTexture commands just to set the used textures:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;SetTexture [_MainTex] {}</tt>
</p>

<p>Writing vertex/fragment programs requires a thorough knowledge of 3D transformations, lighting and coordinate spaces - because you have to rewrite the fixed functionality that is built into OpenGL yourself. On the other hand, you can do much more than what's built in!
</p>

<h2> Using Cg in ShaderLab</h2>

<p>Shaders in ShaderLab are usually written in <a class="wiki"  href="http://developer.nvidia.com/page/cg_main.html">Cg programming language</a> by embedding &quot;Cg snippets&quot; in the shader text. Cg snippets are compiled into low-level shader assembly by the Unity editor, and the final shader that is included in your game's data files only contains this low-level assembly. When you select a shader in the Project View, the Inspector shows shader text after Cg compilation, which might help as a debugging aid. Note that because Cg code is compiled by the editor, you can't create Cg shaders from scripts at runtime.
</p>

<p>In general, Cg snippets are placed inside Pass blocks. They look like this:
<pre class='codelisting'>
Pass {
&nbsp;&nbsp;&nbsp;&nbsp;<i>// ... the usual pass state setup ...</i>
&nbsp;&nbsp;&nbsp;&nbsp;
<b>CGPROGRAM</b>
<i>// compilation directives for this snippet, e.g.:</i>
<b>// profiles</b> arbfp1
<b>// vertex</b> vert
<b>// fragment</b> frag
<br />
<i>// the Cg code itself</i>
<br />
<b>ENDCG</b>
&nbsp;&nbsp;&nbsp;&nbsp;<i>// ... the rest of pass setup ...</i>
}
</pre>
</p>

<p>The following example demonstrates a complete shader with Cg programs that renders object normals as colors:
<pre class='codelisting'>
Shader &quot;Tutorial/Display Normals&quot; {
SubShader {
    Pass {
    
CGPROGRAM
// profiles arbfp1
// vertex vert
// fragment frag
// fragmentoption ARB_fog_exp2
#include &quot;UnityCG.cginc&quot;

struct v2f {
    V2F_POS_FOG;
    float3  color : COLOR0;
};

v2f vert (appdata_base v)
{
    v2f o;
    PositionFog( v.vertex, o.pos, o.fog );
    o.color = v.normal * 0.5 + 0.5;
    return o;
}

half4 frag (v2f i) : COLOR
{
    return half4( i.color, 1 );
}
ENDCG

    }
}
Fallback &quot; VertexLit&quot;, 1
}
</pre>
</p>

<p>When applied on an object it will result in an image like this (if your graphics card supports vertex&amp; fragment programs of course):
</p>

<p><img class='figure' src='images/ShaderTut2-0.jpg' />
</p>

<p>Our &quot;Display Normals&quot; shader does not have any properties, contains a single SubShader with a single Pass that is empty except for the Cg code. Finally, a fallback to the builtin <i>VertexLit</i> shader is defined. Let's dissect the Cg code part by part:
</p>

<p><pre class='codelisting'>
<b>CGPROGRAM</b>
<b>// profiles</b> arbfp1
<b>// vertex</b> vert
<b>// fragment</b> frag
<b>// fragmentoption</b> ARB_fog_exp2
<br />
<i>// ... snip ...</i>
<b>ENDCG</b>
</pre>
</p>

<p>The whole Cg snippet is written between <b>CGPROGRAM</b> and <b>ENDCG</b> keywords. At the start compilation directives are given as a special form of comments:
</p>
<ul><li> <b>// profiles</b> <i>name</i> indicates which hardware profile to compile to, <i>arbfp1</i> being the OpenGL ARB vertex and fragment programs.
</li><li> <b>// vertex</b> <i>name</i> tells that the code contains a vertex program in the given function (<i>vert</i> here).
</li><li> <b>// fragment</b> <i>name</i> tells that the code contains a fragment program in the given function (<i>frag</i> here).
</li><li> <b>// fragmentoption</b> <i>name</i> adds an option to the compiled fragment program. Here we add support for exponential squared fog.
</li></ul>

<p>Following the compilation directives is just plain Cg code. We start by including a builtin Cg file:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;#include &quot;UnityCg.cginc&quot;</tt>
</p>

<p>The <i>UnityCg.cginc</i> file contains commonly used declarations and functions so that the shaders can be kept smaller. The file itself is found inside Unity application: <i>Unity.app/Contents/CGIncludes/UnityCG.cginc</i>. Here we'll use <i>appdata_base</i> structure, <i>V2F_POS_FOG</i> macro and <i>PositionFog</i> helper function from that file. We could just define them directly in the shader and not include the file of course.
</p>

<p>Next we define a &quot;vertex to fragment&quot; structure (here named <i>v2f</i>) - what information is passed from the vertex to the fragment program. We pass the standard position and fog parameters and a <i>float3 color</i> parameter. The color will be computed in the vertex program and just output in the fragment program.
</p>

<p>We proceed by defining the vertex program - <i>vert</i> function. Here we compute position and fog in the standard way (using helper function from <i>UnityCG.cginc</i>) and output input normal as a color:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;o.color = v.normal * 0.5 + 0.5;</tt>
</p>

<p>Normal components are in -1..1 range, while colors are in 0..1 range, so we scale and bias the normal in the code above. Next we define a fragment program - <i>frag</i> function that just outputs the calculated color and 1 as the alpha component:
<pre class='codelisting'>
half4 frag (v2f i) : COLOR
{
    return half4( i.color, 1 );
}
</pre>
</p>

<p>That's it, our shader is finished! Even this simple shader is very useful to visualize mesh normals.
</p>

<p>Of course, this shader does not respond to lights at all, and that's where things get a bit more complicated; read on <a href="../Manual/SL-RenderPipeline.html">Render Pipeline</a> and <a href="../Manual/SL-Attenuation.html">Light Attenuation</a> pages in the reference for details.
</p>


<h2> Using shader properties in Cg code</h2>

<p>When you define properties in the shader, you give them a name like <i>_Color</i> or <i>_MainTex</i>. To use them in Cg you just have to define a variable of a matching name and type. Unity will automatically set Cg variables that have names matching with shader properties.
</p>

<p>Here is a complete shader that displays a texture modulated by a color. Of course, you could easily do the same in a texture combiner call, but the point here is just to show how to use properties in Cg:
</p>

<p><pre class='codelisting'>
Shader &quot;Tutorial/Textured Colored&quot; {
Properties {
    _Color (&quot;Main Color&quot;, Color) = (1,1,1,0.5)
    _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; { }
}
SubShader {
    Pass {
    
CGPROGRAM
// profiles arbfp1
// vertex vert
// fragment frag
// fragmentoption ARB_fog_exp2

#include &quot;UnityCG.cginc&quot;

float4 _Color;
sampler2D _MainTex : register(s0);

struct v2f {
    V2F_POS_FOG;
    float2  uv : TEXCOORD0;
};

v2f vert (appdata_base v)
{
    v2f o;
    PositionFog( v.vertex, o.pos, o.fog );
    o.uv = TRANSFORM_UV(0);
    return o;
}

half4 frag (v2f i) : COLOR
{
    half4 texcol = tex2D( _MainTex, i.uv );
    return texcol * _Color;
}
ENDCG

        SetTexture [_MainTex] {}
    }
}
Fallback &quot; VertexLit&quot;, 1
}
</pre>
</p>

<p>The structure of this shader is the same as in the previous example. Here we define two properties, namely <i>_Color</i> and <i>_MainTex</i>. Inside Cg code we define corresponding variables:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;float4 <i>_Color</i>;</tt>
</p>
<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;sampler2D <i>_MainTex</i> : register(s0);</tt>
</p>

<p>Property types in ShaderLab map to Cg variable types this way:
</p>
<ul><li> Color and Vector properties map to <i>float4</i> variables
</li><li> Range and Float properties map to <i>float</i> variables
</li><li> Texture properties map to <i>sampler2D</i> variables for regular (2D) textures. CUBE and RECT textures map to <i>samplerCUBE</i> and <i>samplerRECT</i> variables respectively.
</li></ul>

<p>Note that in the case of a texture property we explicitly bind it to the first sampler register: <i>register(s0)</i>. This is to ensure that Cg will use the correct texture; sampler registers should match the order of <i>SetTexture</i> commands later.
</p>

<p>The vertex and fragment programs here don't do anything fancy; vertex program uses the <i>TRANSFORM_UV</i> macro from <i>UnityCG.cginc</i> to make sure texture scale&amp;offset is applied correctly, and fragment program just samples the texture and multiplies by the color property.
</p>

<p>After the Cg snippet we write an empty SetTexture command:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;SetTexture [<i>_MainTex</i>] {}</tt>
</p>

<p>This actually sets the texture <i>_MainTex</i> from the properties. If you'd have more textures, you'd need to write similar SetTexture commands in the order that matches sampler register declarations (see paragraph about <i>register(s0)</i> above).
</p>


<h2> Summary</h2>

<p>We have shown how custom shader programs can be generated in a few easy steps. While the examples shown here are very simple, there's nothing preventing you to write arbitrarily complex shader programs! This can help you to take the full advantage of Unity and achieve optimal rendering results.
</p>

<p>We have a forum for shaders at <a class="wiki"  href="http://forum.unity3d.com">forum.unity3d.com</a> so go there to get help with your shaders! There you can also find the source of all Unity builtin shaders - to examine and learn from. The complete ShaderLab reference manual is <a href="../Manual/Shaders.html">here</a>. Happy programming, and enjoy the power of Unity and Shaderlab.
</p>


<p>The Shader is the root object of a shader file. Each file must define one (and only one) shader. It specifies how any objects whose material uses this shader is rendered.
</p>

<h2> Syntax</h2>
<p><dl><dt><code><b>Shader</b> &quot;<i>name</i>&quot; <b>{</b> [Properties] Subshaders [Fallback] <b>}</b></code></dt><dd> Defines a shader. It will appear in the material inspector listed under <b>name</b>. Shaders optionally can define a list of <b>properties</b> that show up as material settings. After this comes a list of SubShaders, and optionally a fallback.</dd></dl>
</p>

<h2> Details</h2>

<h3> Properties</h3>

<p>Shaders can have a list of <a href="../Manual/SL-Properties.html">properties</a>. Any properties declared in a shader are shown in the material inspector inside Unity. Typical properties are the object color, textures, or just arbitrary values to be used by the shader.
</p>

<h3> SubShaders &amp; Fallback</h3>

<p>Each shader is comprised of a list of <a href="../Manual/SL-SubShader.html">sub-shaders</a>. You must have at least one. When loading a shader, Unity will go through the list of subshaders, and pick the first one that is supported by the end user's machine. If no subshaders are supported, Unity will try to use <a href="../Manual/SL-Fallback.html">fallback shader</a>.
</p>

<p>Different graphic cards have different capabilities. This raises an eternal issue for game developers; you want your game to look great on the latest hardware, but don't want it to be available only to those 3% of the population. This is where subshaders come in. Create one subshader that has all the fancy graphic effects you can dream of, then add more subshaders for older cards. These subshaders may implement the effect you want in a slower way, or they may choose not to implement some details.
</p>

<h2> Examples</h2>

<p>Here is one of the simplest shaders possible:
<pre class='codelisting'>
// colored vertex lithing
Shader &quot;simple&quot; {
    // a single color property
    Properties {
        _Color (&quot;Main Color&quot;, Color) = (1,.5,.5,1)
    }
    // define one subshader
    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
            }
            Lighting On
        }
    }
}
</pre>
This shader defines a color property <i>_Color</i> (that shows up in material inspector as <i>Main Color</i>) with a default value of <code>(1, 0.5, 0.5, 1)</code>. Then a single subshader is defined. The subshader consists of one <a href="../Manual/SL-Pass.html">Pass</a> that turns on vertex lighting and sets up basic material for it.
</p>



<p>Shaders can define a list of parameters to be set by artists in Unity's material inspector. The Properties block in the shader file defines them.
</p>

<h2>Syntax</h2>
<p><dl><dt><b>Properties</b> { <i>Property</i> [<i>Property ...</i>] }</dt><dd> Defines the property block. Inside braces multiple properties are defined as follows.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Range</b> (<i>min</i>, <i>max</i>)) = <i>number</i></dt><dd> Defines a float property, represented as a slider from <i>min</i> to <i>max</i> in the inspector.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Color</b>) = (<i>number</i>,<i>number</i>,<i>number</i>,<i>number</i>)</dt><dd> Defines a color property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>2D</b>) = &quot;<i>name</i>&quot; { <i>options</i> }</dt><dd> Defines a 2D texture property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Rect</b>) = &quot;<i>name</i>&quot; { <i>options</i> }</dt><dd> Defines a rectangle (non power of 2) texture property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Cube</b>) = &quot;<i>name</i>&quot; { <i>options</i> }</dt><dd> Defines a cubemap texture property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Float</b>) = <i>number</i></dt><dd> Defines a float property.</dd><dt><i>name</i> (&quot;<i>display name</i>&quot;, <b>Vector</b>) = (<i>number</i>,<i>number</i>,<i>number</i>,<i>number</i>)</dt><dd> Defines a four component vector property.</dd></dl>
</p>

<h2>Details</h2>

<p>Each property inside the shader is referenced by <b>name</b> (in Unity, it's common to start shader property names with underscore). The property will show up in material inspector as <b>display name</b>. For each property a default value is given after equals sign:
</p>
<ul><li> For <i>Range</i> and <i>Float</i> properties it's just a single number.
</li><li> For <i>Color</i> and <i>Vector</i> properties it's four numbers in parentheses.
</li><li> For texture (<i>2D</i>, <i>Rect</i>, <i>Cube</i>) the default value is either an empty string, or one of builtin default textures: &quot;<i>white</i>&quot;, &quot;<i>black</i>&quot;, &quot;<i>gray</i>&quot; or &quot;<i>bump</i>&quot;.
</li></ul>

<p>Later on in the shader, property values are accessed using property name in square brackets: <b>[name]</b>.
</p>

<h2>Example</h2>
<p><pre class='codelisting'>
Properties {
    // properties for water shader
    _WaveScale (&quot;Wave scale&quot;, Range (0.02,0.15)) = 0.07 // sliders
    _ReflDistort (&quot;Reflection distort&quot;, Range (0,1.5)) = 0.5
    _RefrDistort (&quot;Refraction distort&quot;, Range (0,1.5)) = 0.4
    _RefrColor (&quot;Refraction color&quot;, Color)  = (.34, .85, .92, 1) // color
    _ReflectionTex (&quot;Environment Reflection&quot;, 2D) = &quot;&quot; {} // textures
    _RefractionTex (&quot;Environment Refraction&quot;, 2D) = &quot;&quot; {}
    _Fresnel (&quot;Fresnel (A) &quot;, 2D) = &quot;&quot; {}
    _BumpMap (&quot;Bumpmap (RGB) &quot;, 2D) = &quot;&quot; {}
}
</pre>
</p>

<h3>Texture property options</h3>

<p>The <i>options</i> inside curly braces of the texture property are optional. The available options are:
</p>

<p><dl><dt><b>TexGen</b> <i>texgenmode</i></dt><dd> Automatic texture coordinate generation mode for this texture. Can be one of <i>ObjectLinear</i>, <i>EyeLinear</i>, <i>SphereMap</i>, <i>CubeReflect</i>, <i>CubeNormal</i>; these correspond directly to OpenGL texgen modes. Note that TexGen is ignored if custom vertex programs are used.</dd></dl>
</p>

<h3>Example</h3>
<p><pre class='codelisting'>
// EyeLinear texgen mode example
Shader &quot;Texgen/Eye Linear&quot; {
	Properties {
		_MainTex (&quot;Base&quot;, 2D) = &quot;white&quot; { TexGen EyeLinear }
	}
	SubShader {
		Pass {
			SetTexture [_MainTex] { combine texture alpha }
		}
	} 
}
</pre>
</p>



<p>Each shader in Unity consists of a list of subshaders. When Unity has to display a mesh, it will find the shader to use, and pick the first subshader that runs on the user's graphics card.
</p>

<h2>Syntax</h2>

<p><dl><dt><b>Subshader</b> <b>{</b> [<i>CommonState</i>] <i>Passdef</i> [<i>Passdef ...</i>] <b>}</b></dt><dd> Defines the subshader as optional common state and a list of pass definitions.</dd></dl>
</p>

<h2>Details</h2>

<p>A subshader defines a list of <a href="../Manual/SL-Pass.html"> rendering passes</a> and optionally setup any state that is common to all passes.
</p>

<p>When Unity chooses which subshared to render with, it renders an object once for each Pass defined (and possibly more due to light interactions). As each render of the object is an expensive operation, you want to define the shader in minimum amount of passes possible. Of course, sometimes on some graphics hardware the needed effect can't be done in a single pass; then you have no choice but to use multiple passes.
</p>

<p>Each pass definition can be a <a href="../Manual/SL-Pass.html"> regular Pass</a>, a <a href="../Manual/SL-UsePass.html"> Use Pass</a> or a  <a href="../Manual/SL-GrabPass.html"> Grab Pass</a>.
</p>

<p>Any statements that are allowed in a Pass definition can also appear in Subshader block. This will make all passes use this &quot;shared&quot; state. Additionally, some <a href="../Manual/SL-NameAndTags.html">Tags</a> (<i>RenderQueue</i>) are regognized in the SubShader block.
</p>

<h2>Example</h2>

<p><pre class='codelisting'>
SubShader {
    Pass {
        Lighting Off
        SetTexture [_MainTex] {}
    }
}
</pre>
This subshader defines a single Pass that turns off any lighting and just displays a mesh with texture named <i>_MainTex</i>.
</p>


<p>The Pass block causes the geometry of an object to be rendered once.
</p>

<h2>Syntax</h2>
<p><dl><dt><b>Pass</b> <b>{</b> <i>[Name and Tags]</i> <i>[RenderSetup]</i> <i>[TextureSetup]</i> <b>}</b> </dt><dd> The basic pass command contains an optional list of render setup commands, optionally followed by a list of textures to use.</dd></dl>
</p>

<h3> Name and tags</h3>

<p>A Pass can define it's name and arbitrary number of Tags - name/value strings that communicate Pass' intent to the rendering engine. More details <a href="../Manual/SL-NameAndTags.html"> here</a>.
</p>

<h3> Render Setup</h3>
<p><dl><dt><b>Material</b> <b>{</b> <i>Material Block</i> <b>}</b></dt><dd> Defines a material to use in a vertex lighting pipeline.</dd><dt><b>Lighting</b> On | Off</dt><dd> Turn vertex lighting on or off.</dd><dt><b>Cull</b> Back | Front | Off</dt><dd> Set polygon culling mode.</dd><dt><b>ZTest</b> (Less | Greater | LEqual | GEqual | Equal | NotEqual | Always)</dt><dd> Set depth testing mode.</dd><dt><b>ZWrite</b> On | Off</dt><dd> Set depth writing mode.</dd><dt><b>Fog</b> <b>{</b> <i>Fog Block</i> <b>}</b></dt><dd> Set fog parameters.</dd><dt><b>AlphaTest</b> (Less | Greater | LEqual | GEqual | Equal | NotEqual | Always) <i>CutoffValue</i></dt><dd> Turns on alpha testing.</dd><dt><b>Blend</b> <i>SourceBlendMode</i> <i>DestBlendMode</i></dt><dd></dd><dt><b>Color</b> <i>Color value</i></dt><dd> Sets color to use if vertex lighting is turned off.</dd><dt><b>ColorMask</b> RGB | A | or any combination of R, G, B, A</dt><dd> Set color writing mask.</dd><dt><b>Offset</b> <i>OffsetFactor</i> <b>,</b> <i>OffsetUnits</i></dt><dd> Set depth offset.</dd><dt><b>SeparateSpecular</b> On | Off</dt><dd> Turns separate specular color for vertex lighting on or off.</dd></dl>
</p>

<h3> Texture Setup</h3>
<p>After the render setup, you can specify a number of textures and their combining modes to apply.
<dl><dt><b>SetTexture</b> <i>texture property</i> { <i>[Combine options]</i> }</dt><dd></dd></dl>
</p>


<h2>Details</h2>

<h3> Lighting</h3>

<p>The per-pixel lighting pipeline works by rendering objects in multiple passes. Unity renders the object once to get ambient and any vertex lights in. Then it renders each pixel light affecting the object in a separate additive pass. See <a href="../Manual/SL-RenderPipeline.html">Render Pipeline</a> for details.
</p>

<h2> See Also</h2>

<p>There are a selection of special passes available for reusing common functionality or implementing various high-end effects:
<dl><dt><a href="../Manual/SL-UsePass.html">UsePass</a></dt><dd> Includes named passes from another shader.</dd><dt><a href="../Manual/SL-GrabPass.html">GrabPass</a></dt><dd> Grabs the contents of the screen into a texture, for use in a later pass.</dd></dl>
</p>

<h2> Subsections</h2>

<p><ul class="toc"><li class="toclevel"><a href="../Manual/SL-Material.html">SL-Material</a></li><li class="toclevel"><a href="../Manual/SL-CullAndDepth.html">SL-CullAndDepth</a></li><li class="toclevel"><a href="../Manual/SL-SetTexture.html">SL-SetTexture</a></li><li class="toclevel"><a href="../Manual/SL-Fog.html">SL-Fog</a></li><li class="toclevel"><a href="../Manual/SL-AlphaTest.html">SL-AlphaTest</a></li><li class="toclevel"><a href="../Manual/SL-Blend.html">SL-Blend</a></li><li class="toclevel"><a href="../Manual/SL-NameAndTags.html">SL-NameAndTags</a></li><li class="toclevel"><a href="../Manual/SL-BindChannels.html">SL-BindChannels</a></li></ul>
</p>



<p>The material and lighting parameters are used to control the built-in vertex lighting.
</p>

<p>Pixel lights are usually implemented with custom vertex/fragment programs and don't use vertex lighting. For these you don't use any of the commands described here, instead you define your own <a > vertex and fragment programs</a> where you do all lighting, textuting and anything else yourself.
</p>

<p><map name="GraffleExportLight">
	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling">
	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest">
	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend">
	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog">
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-SetTexture">
</map>
<img class='figure' src='images/SL-Material-0.jpg' />
</p>

<p>Vertex Coloring &amp; Lighting is the first effect to gets calculated for any rendered geometry. It operates on the vertex level, and calculates the base color that is used before textures are applied.
</p>

<h2>Syntax</h2>
<p>The toplevel commands control whether to use OpenGL lighting or not, and some configuration options. The main setup is in the <b>Material Block</b>, detailed further below.
<dl><dt><b>Color</b> <i>Color</i></dt><dd> Sets the object to a solid color. A color is either four RGBA values in parenthesis, or a color property name in square brackets.</dd><dt><b>Material</b> <b>{</b> <i>Material Block</i> <b>}</b></dt><dd>The Material block is used to define the material properties of the object.</dd><dt><b>Lighting</b> On | Off</dt><dd> For the settings defined in the Material block to have any effect, you must enable Lighting with the <i>Lighting On</i> command. If lighting is off instead, the color is taken straight from the <i>Color</i> command.</dd><dt><b>SeperateSpecular</b> On | Off</dt><dd> This command makes specular lighting be added to the end of the shader pass, so specular lighting is unaffected by texturing. Only has effect when <i>Lighting On</i> is used.</dd></dl>
</p>

<h3>Material Block</h3>

<p>This contains settings for how the material reacts to the light. Any of these properties can be left out, in which case they default to black (i.e. have no effect).
</p>

<p><dl><dt><b>Diffuse</b> <i>Color</i></dt><dd> The diffuse color component. This is an object's base color.</dd><dt><b>Ambient</b> <i>Color</i></dt><dd> The ambient color component. This is the color the object has when it's hit by the ambient light set in the <a href="../Components/class-RenderSettings.html">RenderSettings</a>.</dd><dt><b>Specular</b> <i>Color</i></dt><dd> The color of the object's specular highlight.</dd><dt><b>Shininess</b> <i>Number</i></dt><dd> The sharpness of the highlight, between 0 and 1. At 0 you get a huge highlight that looks a lot like diffuse lighting, at 1 you get a tiny speck.</dd><dt><b>Emission</b> <i>Color</i></dt><dd> The color of the object when it is not hit by any light.</dd></dl>
</p>

<p>The full color of lights hitting the object is:
</p>

<table><tr><td><div class='cbox'><div class='cbox-data'><p><b>Ambient</b> * <a href="../Components/class-RenderSettings.html"> RenderSettings ambient setting</a> + <br>(Light color * <b>Diffuse</b> + Light Color * <b>Specular</b>) + <br><b>Emission</b>
</p>
<p></div></div></td></tr></table>
</p>

<p>The light parts of the equation (within parenthesis) is repeated for all lights that hit the object.
</p>

<p>Typically you want to keep the Diffuse and Ambient colors the same (all builtin Unity shaders do this).
</p>

<h2>Examples</h2>

<p>Always render object in pure red:
<pre class='codelisting'>
Shader "Solid Red" {
    SubShader {
        Pass {
            Color (1,0,0)
        }
    }
}
</pre>
</p>


<p>Basic Shader that colors the object white and applies vertex lighting:
<pre class='codelisting'>
Shader "VertexLit White" {
    SubShader {
        Pass {
            Material {
                Diffuse (1,1,1,1)
                Ambient (1,1,1,1)
            }
            Lighting On
        }
    }
}
</pre>
</p>


<p>An extended version that adds material color as a property visible in Material Inspector:
<pre class='codelisting'>
Shader "VertexLit Simple" {
    Properties {
        _Color ("Main Color", COLOR) = (1,1,1,1)
    }
    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
                Ambient [_Color]
            }
            Lighting On
        }
    }
}
</pre>
</p>


<p>And finally, a full fledges vertex-lit shader (see also <a href="../Manual/SL-SetTexture.html">SetTexture</a> reference page):
<pre class='codelisting'>
Shader "VertexLit" {
    Properties {
        _Color ("Main Color", Color) = (1,1,1,0)
        _SpecColor ("Spec Color", Color) = (1,1,1,1)
        _Emission ("Emmisive Color", Color) = (0,0,0,0)
        _Shininess ("Shininess", Range (0.01, 1)) = 0.7
        _MainTex ("Base (RGB)", 2D) = "white" {}
    }

    SubShader {
        Pass {
            Material {
                Diffuse [_Color]
                Ambient [_Color]        
                Shininess [_Shininess]
                Specular [_SpecColor]
                Emission [_Emission]    
            } 
            Lighting On
            SeperateSpecular On
            SetTexture [_MainTex] {
                Combine texture * primary DOUBLE, texture * primary
            } 
        } 
    }
}
</pre>
</p>




<p><map name="GraffleExportCull">
<!--	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling"> -->
	<area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material">
	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest">
	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend">
	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog">
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-Texture">
</map>
<img class='figure' src='images/SL-CullAndDepth-0.jpg' />
</p>

<p>Culling is an optimization that does not render polygons facing away from the viewer. All polygons have a front and a back side. Culling makes use of the fact that most objects are closed; if you have a cube, you will never see the sides facing away from you (there is always a side facing you in front of it) so we don't need to draw the sides facing away. Hence the term: Backface culling.
</p>

<p>The other feature that makes rendering looks correct is Depth testing. Depth testing makes sure that only the foremost objects are drawn in a scene.
</p>

<h2> Syntax</h2>
<p><dl><dt><b>Cull</b> Back | Front | Off</dt><dd> Controls which sidedness of polygons should be culled (not drawn)</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Back</b> Don't render polygons facing away from the viewer <i>(default)</i>.</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Front</b> Don't render polygons facing towards the viewer. Used for turning objects inside-out.</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Off</b> Disables culling - all faces are drawn. Used for special effects.</dd></dl>
<dl><dt><b>ZWrite</b> On | Off</dt><dd> Controls whether pixels from this object are written to the depth buffer (default is <i>On</i>). If you're drawng solid objects, leave this on. If you're drawing semitransparent effects, switch to <i>ZWrite Off</i>. For more details read below.</dd><dt><b>ZTest</b> Less | Greater | LEqual | GEqual | Equal | NotEqual | Always</dt><dd> How should depth testing be performed. Default is <i>LEqual</i> (draw objects in from or at the distance as existing objects; hide objects behind them).</dd><dt><b>Offset</b> <i>Factor</i> <b>,</b> <i>Units</i></dt><dd> Offsets the values drawn into the depth buffer. This allows you to force one polygon to be drawn on top of another although they are actually in the same position. For example <i>Offset -1, -1</i> pulls the polygon a bit closer to the camera.</dd></dl>
</p>

<h2> Details</h2>
<p>Depth Testing explained.
</p>

<p>Drawing transparent objects Back To Front.
</p>

<h2> Examples</h2>

<p>This object will render only the backfaces of an object:
<pre class='codelisting'>
Shader "Show Insides" {
	SubShader {
		Pass {
			Material {
				Diffuse (1,1,1,1)
			}
			Lighting On
			Cull Front
		}
	}
}
</pre>
Try to apply it to a cube, and notice how the geometry feels all wrong when you orbit around it. This is because you're only seeing the inside parts of the cube.
</p>

<h3> Debugging Normals</h3>
<p>The next one is more interesting; first we render the object with normal vertex lighting, then we render the backfaces in bright pink. This has the effects of highlighting anywhere your normals need to be flipped. If you see physically-controlled objects getting 'sucked in' by any meshes, try to assign this shader to them. If any pink parts are visible, these parts will pull in anything unfortunate enough to touch it.
</p>

<p>Here we go:
<pre class='codelisting'>
Shader "Reveal Backfaces" {
	Properties {
		_MainTex ("Base (RGB)", 2D) = "white" { }
	}
	SubShader {
		// Render the front-facing parts of the object. 
		// We use a simple white material, and apply the main texture.
		Pass {
			Material {
				Diffuse (1,1,1,1)
			}
			Lighting On
			SetTexture [_MainTex] { 
				Combine Primary * Texture
			}
		}

		// Now we render the back-facing triangles in the most 
		// irritating color in the world: BRIGHT PINK!
		Pass {
			Color (1,0,1,1)
			Cull Front
		}
	}
}
</pre>
</p>

<h3> Glass Culling</h3>
<p>Controlling Culling is useful for more than debugging backfaces. If you have transparent objects, you quite often want to show the backfacing side of an object. If you render without any culling (<b>Cull Off</b>), you'll most likely have some rear faces overlapping some of the front faces.
</p>

<p>Here is a simple shader that will work for convex objects (spheres, cubes, car windscreens).
<pre class='codelisting'>
Shader "Simple Glass" {
	Properties {
		_Color ("Main Color", Color) = (1,1,1,0)
		_SpecColor ("Spec Color", Color) = (1,1,1,1)
		_Emission ("Emmisive Color", Color) = (0,0,0,0)
		_Shininess ("Shininess", Range (0.01, 1)) = 0.7
		_MainTex ("Base (RGB)", 2D) = "white" { }
	}

	SubShader {
		// We use the material in many passes by defining them in the subshader.
		// Anything defined here becomes default values for all contained passes.
		Material {
			Diffuse [_Color]
			Ambient [_Color]        
			Shininess [_Shininess]
			Specular [_SpecColor]
			Emission [_Emission]    
		} 
		Lighting On	
		SeperateSpecular On

		// Set up alpha blending
		Blend SrcAlpha OneMinusSrcAlpha

		// Render the back facing parts of the object. 
		// If the object is convex, these will always be further away
		// than the front-faces.
		Pass {
			Cull Front
			SetTexture [_MainTex] { 
				Combine Primary * Texture
			}
		}
		// Render the parts of the object facing us.
		// If the object is convex, these will be closer than the 
		// back-faces.
		Pass {
			Cull Back
			SetTexture [_MainTex] { 
				Combine Primary * Texture
			}
		}
	}
}
</pre>
</p>



<p>After the basic vertex lighting has been calculated, textures are applied. In ShaderLab this is done using <b>SetTexture</b> command.
</p>

<p>Note that if you use <a > fragment programs</a>, all texture combiner modes are ignored. You only need to write empty <i>SetTexture</i> command.
</p>

<p><map name="GraffleExportTexture">
</p>
<p><tt> <area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling"></tt>
</p>
<p><tt> <area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material"></tt>
</p>
<p><tt> <area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest"></tt>
</p>
<p><tt> <area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend"></tt>
</p>
<p><tt> <area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog"></tt>
</map>
<img class='figure' src='images/SL-SetTexture-0.jpg' />
</p>

<p>Texturing is the place to do old-style combiner effects. You can have multiple SetTexture commands inside a pass - all textures are applied in sequence, like layers in a painting program. SetTexture commands must be placed at the end of a <a href="../Manual/SL-Pass.html">Pass</a>.
</p>

<h2>Syntax</h2>
<p><dl><dt><b>SetTexture</b> <i>[TexturePropertyName]</i> <b>{</b> <i>Texture Block</i> <b>}</b></dt><dd> Assigns a texture. <i>TextureName</i> must be defined as a texture property. How to apply the texture is defined inside the <i>TextureBlock</i>.</dd></dl>
</p>

<h3> Texture Block</h3>
<p>The texture block controls how the texture is applied.
</p>

<p><dl><dt>combine <i>src1</i> * <i>src2</i></dt><dd> Multiplies src1 and src2 together. The result will be darker than either input.</dd><dt>combine <i>src1</i> + <i>src2</i></dt><dd> Adds  src1 and src2 together. The result will be lighter than either input.</dd><dt>combine <i>src1</i> - <i>src2</i></dt><dd>  Subtracts src2 from src1.</dd><dt>combine <i>src1</i> +- <i>src2</i></dt><dd> Adds src1 to src2, then subtracts 0.5 (a signed add).</dd><dt>combine <i>src1</i> lerp (<i>src2</i>) <i>src3</i></dt><dd> Alphablends between src1 and src3, using the alpha of src2.</dd><dt>combine <i>src1</i> * <i>src2</i> + <i>src3</i></dt><dd> Multiplies src1 with the alpha component of src2, then adds src3.</dd><dt>combine <i>src1</i> * <i>src2</i> +- <i>src3</i></dt><dd> Multiplies src1 with the alpha component of src2, then does a signed add with src3.</dd><dt>combine <i>src1</i> * <i>src2</i> - <i>src3</i></dt><dd>  Multiplies src1 with the alpha component of src2, then subtracts src3.</dd></dl>
</p>

<p><dl><dt></dt><dd>All the <b>src</b> properties can be either one of <i>previous</i>, <i>constant</i>, <i>primary</i> or <i>texture</i>. </dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Previous</b> is the the result of the previous SetTexture.</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Primary</b> is the color from the <a href="../Manual/SL-Material.html">lighting calculation</a> or the vertex color if it is <a href="../Manual/SL-BindChannels.html">bound</a>.</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Texture</b> is the color of the texture specified by <i>[_TextureName]</i> in the SetTexture (see above).</dd><dt></dt><dd>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Constant</b> is the color specified in <b>ConstantColor</b>, described below.</dd></dl>
<dl><dt></dt><dd> The formula specified above can optionally be followed by the keywords <b>Double</b> or <b>Quad</b> to make the resulting color 2x or 4x as bright.</dd></dl>
<dl><dt>ConstantColor <i>color</i></dt><dd> Defines a constant color that can be used in the values above.</dd></dl>
</p>

<h2> Details</h2>

<p>Older graphics cards use a layered approach to textures. The textures are applied one after each other, modifying the color that will be written to the screen. For each texture, the texture is typically combined with the result of the previous operation.
</p>

<p><img class='figure' src='images/SL-SetTexture-1.jpg' />
</p>

<h3> Separate Alpha &amp; Color blending</h3>
<p>By default, the combiner formula is used for calculating both the RGB and alpha component of the color settexture. Optionally, you can specify a separate formula for the alpha calculation. This looks like this:
</p>

<p><pre class='codelisting'>
SetTexture [_MainTex] { combine previous * texture, previous + texture }
</pre>
</p>

<p>Here, we multiply the RGB colors and add the alpha.
</p>

<h3> Specular highlights</h3>
<p>By default the <b>primary</b> color is the sum of the diffuse, ambient and specular colors (as defined in the <a href="../Manual/SL-Material.html">Lighting calculation</a>). If you specify <b>SeperateSpecular On</b> in the pass options, the specular color will be added in <i>after</i> the combiner calculation, rather than before. This is the default behavior of the built-in VertexLit shader.
</p>

<h3> Graphic cards</h3>
<p>The combiner options are supported by the following graphic cards: NVidia TNT, NVidia GeForce (all versions), ATI Rage, ATI Radeon (all versions). The number of <b>SetTexture</b> blocks you can have is also dependant on the card:
</p>

<p><dl><dt>ATI Rage</dt><dd>2 SetTexture commands only. Does not support the following combiner modes - combine&nbsp;src1&nbsp;*&nbsp;src2&nbsp;+&nbsp;src3, combine&nbsp;src1&nbsp;*&nbsp;src2&nbsp;+-&nbsp;src3 or combine&nbsp;src1&nbsp;*&nbsp;src2&nbsp;-&nbsp;src3.</dd><dt>ATI Radeon 7500</dt><dd> 3 SetTexture commands. Supports all combiner modes</dd><dt>ATI Radeon 8500, 9000, 9200</dt><dd> 6 SetTexture commands. Supports all combiner modes</dd><dt>ATI Radeon 9500 and above</dt><dd> 8 SetTexture commands.</dd><dt>NVidia TNT, GeForce 1, GeForce 2, GeForce 4MX</dt><dd> 2 SetTexture commands. Supports all the combiner modes.</dd><dt>All later NVidia graphic cards</dt><dd> 4 SetTexture. Supports all the combiner modes.</dd></dl>
</p>

<h2> Examples</h2>

<h3> Alpha Blending Two Textures</h3>
<p>This small examples takes two textures. First it sets the first combiner to just take the <b>_MainTex</b>, then is uses the alpha channel of <b>_BlendTex</b> to fade in the RGB colors of <b>_BlendTex</b>
<pre class='codelisting'>
Shader "Examples/2 Alpha Blended Textures" {
	Properties {
		_MainTex ("Base (RGB)", 2D) = "white" {}
		_BlendTex ("Alpha Blended (RGBA) ", 2D) = "white" {}
	}
	SubShader {
		Pass {
			// Apply base texture
			SetTexture [_MainTex] { 
				combine texture
			}
			// Blend in the alpha texture using the lerp operator
			SetTexture [_BlendTex] { 
				combine texture lerp (texture) previous
			}
		}
	} 
}
</pre>
</p>

<h3> Alpha Controlled Self-illumination</h3>
<p>This shader uses the alpha component of the <b>_MainTex</b> to decide where to apply lighting. It does this by applying the texture to two stages; In the first stage, the alpha value of the texture is used to blend between the vertex color and solid white. In the second stage, the RGB values of the texture are multiplied in.
</p>

<p><pre class='codelisting'>
Shader "Examples/Self-Illumination" {
	Properties {
		_MainTex ("Base (RGB) Self-Illumination (A)", 2D) = "white" {}
	}
	SubShader {
		Pass {
			// Set up basic white vertex lighting
			Material {
				Diffuse (1,1,1,1)
				Ambient (1,1,1,1)
			}
			Lighting On
			
			// Use texture alpha to blend up to white (= full illumination)
			SetTexture [_MainTex] {
				constantColor (1,1,1,1)
				combine constant lerp(texture) previous
			}
			// Multiply in texture
			SetTexture [_MainTex] {
				combine previous * texture
			}
		}
	} 
}
</pre>
</p>

<p>We can do something else for free here, though; instead of blending to solid white, we can add a self-illumination color and blend to that. Note the use of <b>ConstantColor</b> to get a _SolidColor from the properties into the texture blending.
</p>

<p><pre class='codelisting'>
Shader "Examples/Self-Illumination 2" {
	Properties {
		_IlluminCol ("Self-Illumination color (RGB)", Color) = (1,1,1,1)
		_MainTex ("Base (RGB) Self-Illumination (A)", 2D) = "white" {}
	}
	SubShader {
		Pass {
			// Set up basic white vertex lighting
			Material {
				Diffuse (1,1,1,1)
				Ambient (1,1,1,1)
			}
			Lighting On
			
			// Use texture alpha to blend up to white (= full illumination)
			SetTexture [_MainTex] {
				// Pull the color property into this blender
				constantColor [_IlluminCol] 
				// And use the texture's alpha to blend between it and 
				// vertex color
				combine constant lerp(texture) previous
			}
			// Multiply in texture
			SetTexture [_MainTex] {
				combine previous * texture
			}
		}
	} 
}
</pre>
</p>

<p>And finally, we take all the lighting properties of the vertexlit shader and pull that in:
<pre class='codelisting'>
Shader "Examples/Self-Illumination 3" {
	Properties {
		_IlluminCol ("Self-Illumination color (RGB)", Color) = (1,1,1,1)
		_Color ("Main Color", Color) = (1,1,1,0)
		_SpecColor ("Spec Color", Color) = (1,1,1,1)
		_Emission ("Emmisive Color", Color) = (0,0,0,0)
		_Shininess ("Shininess", Range (0.01, 1)) = 0.7
		_MainTex ("Base (RGB)", 2D) = "white" {}
	}

	SubShader {
		Pass {
			// Set up basic vertex lighting
			Material {
				Diffuse [_Color]
				Ambient [_Color]        
				Shininess [_Shininess]
				Specular [_SpecColor]
				Emission [_Emission]    
			}
			Lighting On
			
			// Use texture alpha to blend up to white (= full illumination)
			SetTexture [_MainTex] {
				constantColor [_IlluminCol] 
				combine constant lerp(texture) previous
			}
			// Multiply in texture
			SetTexture [_MainTex] {
				combine previous * texture
			}
		}
	} 
}
</pre>
</p>




<p>Fogging blends the color of the generated pixels down towards a constant color based on distance from camera.
</p>

<p><map name="GraffleExportTextureFog">
	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling">
	<area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material">
	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest">
	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend">
<!--	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog"> -->
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-Texture">
</map>
<img class='figure' src='images/SL-Fog-0.jpg' />
</p>

<p>Fogging does not modify a blended pixel's alpha value, only it's RGB components.
</p>

<h2> Syntax</h2>
<p>Fog {
</p>
<p><tt>  Mode</tt>
}
</p>



<p>The alpha test is a last chance to reject a pixel from being written to the screen.
</p>

<p><map name="alphatest">
	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling">
	<area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material">
<!--	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest"> -->
	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend">
	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog">
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-Texture">
</map>
<img class='figure' src='images/SL-AlphaTest-0.jpg' />
</p>

<p>After the final output color has been calculated, the color can optionally have its alpha value compared to a fixed value. If the test fails, the pixel is not written to the display
</p>


<h2> Syntax</h2>
<p><dl><dt>AlphaTest Off</dt><dd> Render all pixels (default).</dd><dt>AlphaTest <i>comparison</i> <i>AlphaValue</i></dt><dd> Set up the alpha test to only render pixels whose alpha value is within a certain range.</dd></dl>
</p>

<h3>Comparison</h3>
<p>Comparison is one of the following words:
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>greater</nobr></b></td><td> Only render pixels whose alpha is greater than <i>AlphaValue</i>. Can be abbreviated as >
</td></tr><tr><td><b><nobr>gequal</nobr></b></td><td> Only render pixels whose alpha is greater than or equal to <i>AlphaValue</i>. Can be abbreviated as >=
</td></tr><tr><td><b><nobr>less</nobr></b></td><td>  Only render pixels whose alpha value is less than <i>AlphaValue</i>. Can be abbreviated as <
</td></tr><tr><td><b><nobr>lequal</nobr></b></td><td> Only render pixels whose alpha value is less than or equal to from <i>AlphaValue</i>. Can be abbreviated as <=
</td></tr><tr><td><b><nobr>equal</nobr></b></td><td>  Only render pixels whose alpha value equals <i>AlphaValue</i>. Can be abbreviated as =
</td></tr><tr><td><b><nobr>notequal</nobr></b></td><td> Only render pixels whose alpha value differ from <i>AlphaValue</i>. Can be abbreviated as !=
>=
</td></tr><tr><td><b><nobr>allways</nobr></b></td><td> Render all pixels. This is functionally equivalent to <i>AlphaTest Off</i>.
Never</td></tr></tr></table>
</p>

<h3> AlphaValue</h3>
<p>A floating-point number between 0 and 1. This can also be a variable reference to a float or a range, in which case it should be written using the standard square bracket notation (<i>[VariableName]</i>)
</p>

<h2> Details</h2>
<p>The alpha test is important when rendering concave objects with transparent parts. The graphics card maintains a record of the depth of every pixel written to the screen. If a new pixel is further away than one already rendered, the new pixel is not written to the display. This means that even with <a href="../Manual/SL-Blend.html">blending</a>, objects will not show through.
</p>

<p><img class='figure' src='images/SL-AlphaTest-1.jpg' />
</p>

<p>In this figure, the tree on the left is rendered using <b>AlphaTest</b>. Note how the pixels in it are either completely transparent or Opaque. The center tree is rendered using only <b>alpha blending</b> - notice how transparent parts of nearby branches cover the distant leaves because of the depth buffer. The tree on the right is rendered using the last example shader - which implements a combination of blending and alpha testing to hide any artifacts.
</p>



<h2> Examples</h2>
<p>The simplest possible example, assign a texture with an alpha channel to it. The object will only be visible where alpha is greater than .5
</p>

<p><pre class='codelisting'>
Shader "Simple Alpha" {
	Properties {
		_MainTex ("Base (RGB) Transparency (A)", 2D) = "" {}
	}
	SubShader {
		Pass {
			// Only render pixels with an alpha larger than .5
			AlphaTest Greater .5
			SetTexture [_MainTex]
		}
	}
}
</pre>
</p>

<p>This is not much good by itself. Let us add some lighting and make the cutoff value tweakable
<pre class='codelisting'>
Shader "Cutoff Alpha" {
	Properties {
		_MainTex ("Base (RGB) Transparency (A)", 2D) = "" {}
		_Cutoff ("Alpha cutoff", Range (0,1)) = .5
	}
	SubShader {
		Pass {
			// Use the Cutoff parameter defined above to determine
			// what to render.
			AlphaTest Greater [_Cutoff]
			Material {
				Diffuse (1,1,1,1)
				Ambient (1,1,1,1)
			}
			Lighting On
			SetTexture [_MainTex] {
				combine texture * primary
			}
		}
	}
}
</pre>
</p>

<p>When rendering plants and trees, many games have the hard edges typical of alpha testing. A way around that is to render the object twice. In the first pass, we use alpha testing to only render pixels that are more than 50% opaque. In the second pass, we alpha-blend the graphic in the parts that were cut away, without recording the depth of the pixel. We might get a bit of confusion as further away branches overwrite the nearby ones, but in practice, that is hard to see  as leaves have a lot of visual detail in them.
</p>

<p><pre class='codelisting'>
Shader "Vegetation" {
	Properties {
		_Color ("Main Color", Color) = (.5, .5, .5, .5)
		_MainTex ("Base (RGB) Alpha (A)", 2D) = "white" {}
		_Cutoff ("Base Alpha cutoff", Range (0,.9)) = .5
	}
	SubShader {
		// Set up basic lighting
		Material {
			Diffuse [_Color]
			Ambient [_Color]
		}	
		Lighting On

		// Render both front and back facing polygons.
		Cull Off

		// first pass:
		//   render any pixels that are more than [_Cutoff] opaque
		Pass {	
			AlphaTest Greater [_Cutoff]
			SetTexture [_MainTex] {
				combine texture * primary, texture
			}
		}

		// Second pass:
		//   render in the semitransparent details.
		Pass {
			// Dont write to the depth buffer
			ZWrite off
			// Don't write pixels we have already written.
			ZTest Less
			// Only render pixels less or equal to the value
			AlphaTest LEqual [_Cutoff]
			
			// Set up alpha blending
			Blend SrcAlpha OneMinusSrcAlpha

			SetTexture [_MainTex] {
				combine texture * primary, texture
			}
		}
	}
}
</pre>
Note that we have some setup inside the SubShader, rather than in the individual passes. Any state set in the SubShader is inherited as defaults in passes inside it.
</p>



<p>Blend is used to make transparent objects.
</p>

<p><map name="GraffleExport">
	<area shape=rect coords="110,15,182,42" href="tiki-index.php?page=SL-Culling">
	<area shape=rect coords="20,15,92,42" href="tiki-index.php?page=SL-Material">
	<area shape=rect coords="380,15,452,42" href="tiki-index.php?page=SL-AlphaTest">
<!--	<area shape=rect coords="470,15,542,42" href="tiki-index.php?page=SL-Blend"> -->
	<area shape=rect coords="290,15,362,42" href="tiki-index.php?page=SL-Fog">
	<area shape=rect coords="200,15,272,42" href="tiki-index.php?page=SL-Texture">
</map>
<img class='figure' src='images/SL-Blend-0.jpg' />
</p>

<p>When graphics are rendered, after all shaders have executed and all textures have been applied, thye are written to the screen. How they are combined with what is already there is controlled by the Blend command.
</p>

<h2> Syntax</h2>
<p><dl><dt>Blend Off </dt><dd> Turn off blending</dd><dt>Blend <i>SrcFactor</i> <i>DstFactor</i></dt><dd> Configure &amp; enable color blending. The generated color is multiplied by the <b>SrcFactor</b>. The color already on screen is multiplied by <b>DstFactor</b> and the two are added together.</dd></dl>
</p>

<h2> Properties</h2>
<p>All following properties are valid for both SrcFactor &amp; DstFactor. <b>Source</b> refers to the calculated color, <b>destination</b> is the color already on the screen.
</p>

<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>One</nobr></b></td><td> The value 1 - use this to let either the source or the destination color come through fully.
</td></tr><tr><td><b><nobr>Zero</nobr></b></td><td> The value 0 - use this to remove either the source or the destination values.
</td></tr><tr><td><b><nobr>SrcColor</nobr></b></td><td>  The value of this stage is multiplied by the source color value.
</td></tr><tr><td><b><nobr>SrcAlpha</nobr></b></td><td> The value of this stage is multiplied by the source alpha value.
</td></tr><tr><td><b><nobr>DstColor</nobr></b></td><td>  The value of this stage is multiplied by frame buffer source color value.
</td></tr><tr><td><b><nobr>DstAlpha</nobr></b></td><td> The value of this stage is multiplied by frame buffer source alpha value.
</td></tr><tr><td><b><nobr>OneMinusSrcColor</nobr></b></td><td> The value of this stage is multiplied by 1 - source color.
</td></tr><tr><td><b><nobr>OneMinusSrcAlpha</nobr></b></td><td> The value of this stage is multiplied by 1 - source alpha.
</td></tr><tr><td><b><nobr>OneMinusDstColor</nobr></b></td><td> The value of this stage is multiplied by 1 - destination.
</td></tr><tr><td><b><nobr>OneMinusDstAlpha</nobr></b></td><td> The value of this stage is multiplied by 1 - destination.
<p></td></tr></tr></table>
</p>

<h2> Details</h2>
<p>Below are the most common blend types.
<pre class='codelisting'>
Pass {
    Blend Off                           // No Blending (default)
    Blend SrcAlpha OneMinusSrcAlpha     // Alpha
    Blend One One                       // Additive 
    Blend One OneMinusDstColor          // Soft Additive
    Blend DstColor Zero                 // Multiplicative
    Blend DstColor SrcColor             // 2x Multiplicative
}
</pre>
</p>

<h2> Example</h2>
<p>Here is a small example shader that adds a texture to whatever is on the screen already:
<pre class='codelisting'>
Shader "Simple Additive" {
    Properties {
        _MainTex ("Texture to blend", 2D) = "black"  {}
    }
    SubShader {
        Blend One One
        SetTexture [_MainTex]	
    }
}
</pre>
</p>

<p>And a more complex one, Glass. This is a 2-pass shader:
</p>
<ol><li> The first pass renders a lighted, alpha-blended texture on to the screen. The alpha channel decides the transparency
</li><li> The second pass renders a reflection cubemap on top of the alpha-blended window, using additive transparency
</li></ol>


<p><pre class='codelisting'>
Shader "Glass" {
    Properties {
        _Color ("Main Color", Color) = (1,1,1,1)
        _MainTex ("Base (RGB) Transparency (A)", 2D) = "white"
        _Reflections ("Base (RGB) Gloss (A)", Cube) = "skybox" { TexGen CubeReflect }
    }
    SubShader {
        Pass {
            Tags {"Queue" = "Transparent" }
            Blend SrcAlpha OneMinusSrcAlpha
            Material {
                Diffuse [_Color]
            }
            Lighting On
            SetTexture [_MainTex] {
                combine texture * primary double, texture * primary
            }
        }
        Pass {
            Blend One One
            Material {
                Diffuse [_Color]
            }
            Lighting On
            SetTexture [_Reflections] {
                combine texture
                Matrix [_Reflection]
            }
        }
    } 
}
</pre>
</p>


<p>Passes and subshaders use tags to tell how and when they expect to be rendered to the rendering engine. The tags recognized by Unity are different for Passes and SubShaders. Passes can also be given a name to be referenced by a <a href="../Manual/SL-UsePass.html">UsePass</a> command.
</p>
<h2> Syntax</h2>
<p><dl><dt><b>Tags {</b> &quot;<i>TagName1</i>&quot; = &quot;<i>Value1</i>&quot; &quot;<i>TagName2</i>&quot; = &quot;<i>Value2</i>&quot; <b>}</b></dt><dd> Specifies <b>TagName1</b> to have <b>Value1</b>, <b>TagName2</b> to have <b>Value2</b>. You can have as many tags as you like.</dd><dt><b>Name</b> &quot;<i>PassName</i>&quot;</dt><dd> Gives the <i>PassName</i> name to the current pass.</dd></dl>
</p>
<h2> Details</h2>
<p>Tags are basic key-value pairs. Inside a <a href="../Manual/SL-SubShader.html">SubShader</a> tags are used to determine rendering order. Inside a <a href="../Manual/SL-Pass.html">Pass</a> tags are used to control which role this pass has in the lighting pipeline (ambient, vertex lit, pixel lit etc.).
</p>

<p>A pass can be given a name so that a <a href="../Manual/SL-UsePass.html">UsePass</a> command can reference it.
</p>

<hr />

<h2> SubShader Tags</h2>

<h3> Rendering Order - Queue tag</h3>
<p>You can determine in which order your objects are drawn using the <i>Queue</i> tag. Unity renders all objects in 4 render queues in order to make effects like transparency work properly. A Shader decides which render queue any objects using it belongs to.
</p>

<p><i>Transparent</i> and <i>Overlay</i> queues are rendered back to front, all other queues have arbitrary order that optimizes for performance.
</p>

<p>The 4 queues are:
<table class="wikitable"><tr><td class="wikicell" >Background</td><td class="wikicell" >This render queue is rendered before any others. It is used for skyboxes and the like.</td></tr><tr><td class="wikicell" >Geometry <i>(default)</i></td><td class="wikicell" >This is used for most objects. Usually opaque geometry uses this queue.</td></tr><tr><td class="wikicell" >Transparent</td><td class="wikicell" >This render queue is rendered after <i>Geometry</i>, in back-to-front order. Anything alpha-blended (i.e. shaders that don't write to depth buffer) should go here (glass, particle effects)</td></tr><tr><td class="wikicell" >Overlay</td><td class="wikicell" >This render queue is meant for overlay effects. Anything rendered last should go here (e.g. lens flares)</td></tr></table>
</p>

<hr />

<h2> Pass Tags</h2>

<h3> LightMode tag</h3>

<p><b>LightMode</b> tag defines Pass' role in the lighting pipeline. See <a href="../Manual/SL-RenderPipeline.html">render pipeline</a> for details.
</p>

<p>Possible values for LightMode tag are:
<dl><dt>Vertex</dt><dd> Rendered if any lights hit the object.</dd><dt>VertexOrNone</dt><dd> <i>(default)</i> Rendered if only vertex lights or no lights at all hit the object.</dd><dt>VertexOnly</dt><dd> Rendered if only vertex lights hit the object.</dd><dt>PixelOnly</dt><dd> Rendered once for each pixel light, provided that no vertex lights hit the object.</dd><dt>Pixel</dt><dd> Rendered once for each pixel light.</dd><dt>VertexOrPixel</dt><dd> Rendered once if any light hits the object.</dd><dt>VertexAndPixel</dt><dd> Rendered once if both vertex and pixel lights hit the object.</dd><dt>PixelOrNone</dt><dd> Rendered if only pixel lights or no lights at all hit the object. Often used as an ambient pass.</dd><dt>None</dt><dd> Rendered only if no lights affect the object.</dd><dt>Always</dt><dd> Always rendered. All lights are setup for vertex lighting.</dd></dl>
</p>

<p>If the active subshader does not have a pass with LightMode of PixelOnly or Pixel, then Unity treats the shader as not supporting pixel lights. In that case, all lights affecting the object are treated as vertex lights.
</p>

<p>The most common cases of LightMode usage are:
</p>
<ul><li> Leave it at default value of VertexOrNone (i.e. not use the tag at all). All lights will be setup as vertex lighting + ambient; or if no lights are affecting the object only ambient portion will be set up.
</li><li> To implement good pixel lit shaders, most often you write a <i>PixelOrNone</i> pass that renders ambient only, a <i>Vertex</i> pass that renders vertex lighting + ambient, and a <i>Pixel</i> pass that adds illumination one light at a time. Majority of builtin shaders in Unity follow this configuration.
</li></ul>

<h3>LightCount tag</h3>

<p>For pixel lit (LightType is Pixel or PixelOnly) passes, a <b>LightCount</b> tag indicates how many lights this pass computes at once. The default value is 1, meaning that a pixel lit pass computes lighting from a single light. All builtin Unity shaders compute lighting from one pixel light at a time.
</p>

<p>For passes that use a larger LightCount (currently up to and including 2), Unity will render as many pixel lights simultaneously. If there are less lights than this number, their colors will be set to black. The light parameters (positions, colors etc.) are provided in the <a href="../Manual/SL-BuiltinValues.html">builtin value arrays</a>.
</p>

<h3>LightTexCount tag</h3>

<p>For a pixel lit pass, the <b>LightTexCount</b> indicates what combination of light attenuation types does the pass support. The tag's value is a string consisting of '0', '1' and '2' characters; meaning a pass supports zero, one or two light attenuation textures. The default value is &quot;012&quot; - i.e. the pass supports all attenuation combinations. When implementing pixel lit shaders for older hardware, often you implement separate passes for these combinations because of hardware restrictions. See <a href="../Manual/SL-Attenuation.html">Attenuation and Pixel Lights</a> for details.
</p>

<hr />

<h2> Examples</h2>
<p><pre class='codelisting'>
Shader &quot;Transparent Queue Example&quot; {
     SubShader {
        Tags {&quot;Queue&quot; = &quot;Transparent&quot; }
        Pass {
        }
    } 
}
</pre>
<i>An example illustrating how to render something in the transparent queue</i>
</p>



<p><b>BindChannels</b> command allows you to map vertex data from mesh data to the rendered triangles.
</p>

<p>By default, Unity figures out the bindings for you, but in some cases you want custom bindings to be used.
</p>

<p>For example you could map the primary UV set to be used in the first texture stage and the secondary UV set to be used in the second texture stage.
</p>

<h2> Syntax</h2>
<p><dl><dt><b>BindChannels</b> <b>{</b> <b>Bind</b> &quot;<i>source</i>&quot;, <i>target</i> <b>}</b> </dt><dd> Specifies <i>source</i> to be mapped to <i>target</i></dd></dl>
<b>Source</b> can be one of:
<dl><dt>Vertex</dt><dd> vertex position</dd><dt>Normal</dt><dd> vertex normal</dd><dt>Tangent</dt><dd> vertex tangent</dd><dt>Texcoord</dt><dd> primary UV coordinate</dd><dt>Texcoord1</dt><dd> secondary UV coordinate</dd><dt>Color</dt><dd> per-vertex color</dd></dl>
<b>Target</b> can be one of:
<dl><dt>Vertex</dt><dd> position input</dd><dt>Normal</dt><dd> normal input</dd><dt>Tangent</dt><dd> tangent input</dd><dt>Texcoord0, Texcoord1, ...</dt><dd> texture coordinates for corresponding texture stage</dd><dt>Texcoord</dt><dd> texture coordinates for all texture stages</dd><dt>Color</dt><dd> per-vertex color input</dd></dl>
</p>

<h2> Examples</h2>

<p><pre class='codelisting'>
// Maps the first UV set to the first texture stage
// and the second UV set to the second texture stage
BindChannels {
   Bind &quot;Vertex&quot;, vertex
   Bind &quot;texcoord&quot;, texcoord0
   Bind &quot;texcoord1&quot;, texcoord1
} 
</pre>
</p>

<p><pre class='codelisting'>
// Maps the first uv set to all texture stages
BindChannels {
   Bind &quot;Vertex&quot;, vertex
   Bind &quot;texcoord&quot;, texcoord
} 
</pre>
</p>

<p><pre class='codelisting'>
// Maps the first uv set to all texture stages
// and vertex colors to the per-vertex color
BindChannels {
   Bind &quot;Vertex&quot;, vertex
   Bind &quot;texcoord&quot;, texcoord
   Bind &quot;Color&quot;, color
} 
</pre>
</p>



<p>The UsePass command uses named passes from another shader.
</p>

<h2>Syntax</h2>
<p><dl><dt><b>UsePass</b> &quot;<i>Shader/Name</i>&quot; </dt><dd> Inserts all passes with a given name from a given shader. <i>Shader/Name</i> contains the name of the shader and the name of the pass, separated by a slash character.</dd></dl>
</p>

<h2>Details</h2>

<p>Some of the shaders could reuse existing passes from other shaders, reducing code duplication. For example, in most pixel lit shaders the ambient or vertex lighting passes are the same as in the corresponding VertexLit shaders. The UsePass command does just that - it includes a given pass from another shader. As an example the following command uses the pass with the name <i>&quot;BASE&quot;</i> from the builtin <i>Glossy</i> shader:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;<b>UsePass</b> &quot; Glossy/BASE&quot;</tt>
</p>

<p>In order for UsePass to work, a name must be given to the pass one wishes to use. The <a href="../Manual/SL-NameAndTags.html">Name</a> command inside the pass gives it a name:
</p>

<p><tt>    &nbsp;&nbsp;&nbsp;&nbsp;<b>Name</b> &quot;<i>MyPassName</i>&quot;</tt>
</p>



<p>GrabPass is a special passtype - it grabs the contents of the screen where the object is about to be drawn into a texture. This texture can be used in subsequent passes to do advanced image based effects.
</p>

<h2>Syntax</h2>
<p>The GrabPass belongs inside a <a href="../Manual/SL-SubShader.html">subshader</a>. All properties are optional.
</p>

<p><pre class='codelisting'>
GrabPass {
    TextureScale 0.5
    TextureSize 256
    BorderScale 0.3
    // following are regular pass commands
    Tags { &quot;LightMode&quot; = &quot;VertexLit&quot; }
    Name &quot;BASE&quot;
}
</pre>
</p>

<h2> Properties</h2>
<table class="reftable"><tr><th>Property:</th><th>Function:</th></tr><tr><td><b><nobr>
TextureSize</nobr></b></td><td> Specifies that you want the grabbed texture to have a certain pixel dimension.
</td></tr><tr><td><b><nobr>TextureScale</nobr></b></td><td> Specifies that you want the texture to be a certain scale of the object's screen size. This is the default behaviour.
</td></tr><tr><td><b><nobr>BorderScale</nobr></b></td><td> Specifies that you want to grab an extra region around the object. The value is relative to the object's bounding box.
<p></td></tr></tr></table>
</p>

<h2> Details</h2>

<p>You can grab the screen behind the object being rendered in order to use it in a later pass. This is done with the GrabPass command. In a subsequent pass, you can access the grabbed screen as a texture, distorting what is behind the object. This is typically used to create stained glass and other refraction-like effects.
</p>

<ul><li> The region grabbed from the screen is available to subsequent passes as <i>_GrabTexture</i> texture property.
</li><li> After grabbing, BorderScale gets converted into screenspace coordinates as <i>_GrabBorderPixels</i> property. This is the maximum amount you can displace within subsequent passes.
</li></ul>

<p>Unity will reuse the screen texture between different objects doing GrabPass. This means that one refractive object will not refract another.
</p>

<h2> Example</h2>

<h4> So Much For So Little</h4>
<p>Here is the most complex way ever of rendering nothing.
<pre class='codelisting'>
Shader &quot;ComplexInvisible&quot; {
    SubShader {
        // Grab the screen behind the object into _GrabTexture, using default values
        GrabPass { }
        
        // Render the object with the texture generated above.
        Pass {
            SetTexture [_GrabTexture] 
        }
    }
}
</pre>
</p>

<p>This shader has two passes: First pass grabs whatever is behind the object at the time of rendering, then applies that in the second pass. Note that the <i>_GrabTexture</i> is configured to display at the exact position of the object - hence it becomes transparent.
</p>

<h2> See Also</h2>
<ul><li> <a href="../Manual/SL-Pass.html">Regular Pass command</a>
</li></ul>




<p>After all Subshaders a Fallback can be defined. It basically says &quot;if none of subshaders can run on this hardware, try using the ones from another shader&quot;.
</p>

<h2> Syntax</h2>
<p><dl><dt><b>Fallback</b> &quot;name&quot;</dt><dd> Fallback to shader with a given <i>name</i>.</dd><dt><b>Fallback off</b></dt><dd> Explicitly state that there is no fallback and no warning should be printed, even if no subshaders can run on this hardware.</dd></dl>
</p>

<h2> Details</h2>

<p>A fallback statement has the same effect as if all subshaders from the other shader would be inserted into it's place.
</p>

<h2> Example</h2>

<p><pre class='codelisting'>
Shader &quot;example&quot; {
    // properties and subshaders here...
    Fallback &quot;otherexample&quot;
}
</pre>
</p>



<p>Shaders define both how an object looks by itself (it's material properties) and how it reacts to the light. Because lighting calculations must be built into the shader, and there are many possible light types, writing quality shaders that &quot;just work&quot; is an involved task. This document describes the pecularities of Unity's lighting&amp;rendering pipeline and how the shaders need to be written to support all the different lights.
</p>

<h2> Light types and modes</h2>

<p>In Unity, a <a href="../Components/class-Light.html">Light</a> can be Directional, Point or Spot light. Additionally, Ambient light level can be specified in <a href="../Components/class-RenderSettings.html">Render Settings</a>.
</p>

<p>When any object is rendered, the lights that illuminate it are determined; and each light is chosen to render in <i>Vertex</i> or <i>Pixel</i> lighting mode. Per-pixel lighting usually looks a lot better, but is more expensive to render as well. So for each object, only some amount (specified in <a href="../Components/class-QualitySettings.html">Quality Settings</a>) of brightest lights are rendered in Pixel mode, while the remaining are rendered using Vertex lighting. When no lights are shining on an object, it is rendered in <i>None</i> mode.
</p>

<p>Each object is then rendered in the following way:
</p>
<ul><li> If there are any Vertex lights shining on it, they are all rendered at once. This renders all &quot;vertex&quot; passes in the shader, and the shader is expected to take both vertex lighting and ambient light into account here.
</li><li> If there are no Vertex lights shining on it, a shader is executed once, to take ambient light into account. This renders all &quot;none&quot; passes in the shader.
</li><li> After that, the pixel lighting is added on top. Usually all &quot;pixel&quot; passes in the shader are rendered for each pixel light. This is the main reason why pixel lights are more expensive - because they have to render object for each light separately, instead of for all lights at once.
<ul><li> A pixel-lit shader pass can be written in a way that supports more than one light at a time. Unity renders as much pixel lights at once as the shader can handle, but due to hardware limits and authoring complexity most often pixel lit shader passes operate on one light at a time.
</li></ul></li></ul>

<p>Each pass in a shader communicates it's lighting type (pixel, vertex etc.) via <a href="../Manual/SL-NameAndTags.html">Tags</a>.
</p>

<h2> Vertex Lights</h2>

<p>Vertex lights are rendered using &quot;vertex&quot; passes (see <a href="../Manual/SL-NameAndTags.html">pass tags</a>). All lights are rendered at once, using a fixed function OpenGL lighting model (<a class="wiki"  href="http://en.wikipedia.org/wiki/Blinn-Phong_shading">Blinn-Phong</a>). It is not possible to use vertex programs with vertex lights because vertex programs and fixed function lighting can be used at the same time. Note that it is still possible to use fragment programs, reading the interpolated diffuse and specular lighting colors.
</p>

<p>In summary, vertex lighting is calculated automatically. All you do in a shader is use the calculated diffuse/specular colors, either in a fragment program or in the texture combiner setup. Vertex lights do not support light cookies.
</p>

<h2> Pixel Lights</h2>

<p>Implementing a pixel lighting shader part is much more involved, mostly because there are different light types (directional, point, spot) and a shader must be able to process all of them. For pixel lights you also want to write a custom vertex program (using fixed function OpenGL lighting does not make sense - you could just use vertex lights and get much better performance) where you must calculate the lighting yourself.
</p>

<p>If you implement pixel lighting passes in the shader, most often you want to implement passes for the case when no lights are shining (ambient pass) as well. See <a href="../Manual/SL-NameAndTags.html">Pass Tags</a> for details.
</p>

<p>The details of implementing light types in custom shaders are described in <a href="../Manual/SL-Attenuation.html">Attenuation and Cookies for Pixel Lights</a>.
</p>



<p>The different light types in Unity's pixel lighting pipeline are implemented using texture lookups to do the attenuation:
</p>
<ul><li> Directional lights can't attenuate, so they don't need any extra processing.
<ul><li> If a cookie is set up, a directional light does one texture lookup into the cookie.
</li></ul></li><li> Point lights don't need extra processing if attenuation is turned off. If attenuation is used, a texture lookup needs to be done. This is done by doing a single volume (3D) texture lookup; or by doing two (one 2D and one 1D) lookups if the graphics card does not support volume textures.
<ul><li> If a cookie is set up, attenuation is always turned off and the light does one texture lookup into the cookie cubemap.
</li></ul></li><li> Spot lights use two texture lookups: one to get the spotlight shape and another to do distance attenuation.
<ul><li> If a cookie is set up, it is used to get spotlight shape. The light still uses two texture lookups.
</li></ul></li></ul>

<p>So each light can do zero, one or two texture lookups to take attenuation and light cookie into account. Taking various lookup texture types into account there are five combinations in total:
</p>
<ul><li> No texture lookups
</li><li> A single lookup into a texture
</li><li> A single lookup into a volume texture
</li><li> A single lookup into a cubemap texture
</li><li> Two texture lookups
</li></ul>

<h2> Attenuation in fragment programs</h2>

<p>When using fragment programs, Unity helps setting these combinations up by providing some macros and definitions in <b>AutoLight.cginc</b> and <b>UnityCG.cginc</b> Cg include files. Then what you do is:
</p>
<ul><li> Use <i>// autolight 7</i> option at start of your CGPROGRAM block
</li><li> Include the helper files: <i>#include &quot;AutoLight.cginc&quot;</i> and <i>#include &quot;UnityCG.cginc&quot;</i>
</li><li> Declare two structures for passing information from a vertex to fragment program. The first is output by a vertex program; and the second is taken as an input in fragment program. The two structures should be identical otherwise, but the first one must contain a <i>float4 _LightCoord[2]</i> texcoord. Most convenient way is using a <i>V2F_LIGHT_COORDS(TEXCOORD<b>index</b>);</i> macro.
</li><li> Output the first structure from a vertex program, using a <i>PASS_LIGHT_COORDS(<b>lighttexindex</b>);</i> macro to compute the attenuation lookup texture coordinates.
</li><li> Input the first structure in a fragment program, and a <i>LIGHTDECL(TEXUNIT<b>lighttexindex</b>)</i> macro.
</li><li> Finally, in a fragment program use <i>LIGHTATT</i> macro that returns a single float value for the light attenuation.
</li><li> In <i>SetTexture</i> block after the Cg code, setup attenuation textures along your regular textures:
<ul><li> <i>SetTexture [_LightTexture0] {} SetTexture [_LightTextureB0] {}</i>
</li></ul></li></ul>

<p>This is pretty complex, so a full shader example is in order. This shader fully shows how to use light attenuation textures in a fragment program. The rest of the shader is kept minimal - it exposes just a color and computes a simple diffuse lighting per-vertex.
<pre class='codelisting'>
Shader &quot;Light Attenuation&quot; {
Properties {
    _Color (&quot;Main Color&quot;, Color) = (1,1,1,0.5)
}

Category {
    Blend AppSrcAdd AppDstAdd
    Fog { Color [_AddFog] }
    
    // Fragment program cards
    SubShader {
        // Ambient pass
        Pass {
            Tags {&quot;LightMode&quot; = &quot;PixelOrNone&quot;}
            Color [_PPLAmbient]
            SetTexture [_Dummy] {constantColor [_Color] Combine primary DOUBLE, constant}
        }
        // Vertex lights
        Pass { 
            Tags {&quot;LightMode&quot; = &quot;Vertex&quot;}
            Lighting On
            Material {
                Diffuse [_Color]
                Emission [_PPLAmbient]
            }
            SetTexture [_Dummy] {constantColor [_Color] Combine primary DOUBLE, constant}
        }
        // Pixel lights
        Pass {
            Tags {
                &quot;LightMode&quot; = &quot;Pixel&quot;
                &quot;LightTexCount&quot; = &quot;012&quot; // this is the default as well
            }
CGPROGRAM
// profiles arbfp1
// vertex vert
// fragment frag
// autolight 7
#include &quot;UnityCG.cginc&quot;
#include &quot;AutoLight.cginc&quot;
// fragmentoption ARB_fog_exp2
// fragmentoption ARB_precision_hint_fastest

// Define the two structures
struct v2f {
    V2F_POS_FOG;
    float4 color : COLOR0;
    // Pass light coords in two slots starting from TEXCOORD0.
    // If we'd use some texcoords for ourselves, the index would
    // be different.
    V2F_LIGHT_COORDS(TEXCOORD0);
};
struct v2f2 { 
    V2F_POS_FOG;
    float4 color : COLOR0;
};

// Vertex program
v2f vert (appdata_base v)
{
    v2f o;
    PositionFog( v.vertex, o.pos, o.fog );
    
    // compute a simple diffuse per-vertex
    float3 ldir = normalize( ObjSpaceLightDir( v.vertex ) );
    float diffuse = dot( v.normal, ldir );
    o.color = diffuse * _ModelLightColor[0] * 2;
    
    // compute&amp;pass texture coords for attenuation
    PASS_LIGHT_COORDS(0); // 0 is the texture index, see SetTexture part below
    return o;
}

// Fragment program
// TEXUNIT0 is the texture index, see SetTexture part below
float4 frag (v2f2 i, LIGHTDECL(TEXUNIT0))  : COLOR
{
    // Just multiply interpolated color with attenuation
    return i.color * LIGHTATT;
}
ENDCG
            // We don't use any textures ourselves,
            // so attenuation textures start from 0
            SetTexture [_LightTexture0] {}
            SetTexture [_LightTextureB0] {}
        }
    }
}

Fallback &quot; VertexLit&quot;, 1
}
</pre>
</p>

<h2> Attenuation for older hardware</h2>

<p>Writing pixel lit shaders for older hardware (that does not support fragment programs) is even more involved due to resource constraints and the fact that these shaders have to be written in an assembly-like language. In this
case most often you write separate passes and shaders that support 0, 1 or 2 attenuation textures.
</p>

<p>For example, the above shader written for <a class="wiki"  href="http://oss.sgi.com/projects/ogl-sample/registry/ATI/text_fragment_shader.txt">ATI Fragment Shader</a> cards (Radeon 8500 and up) would be like the example below. Ambient and Vertex passes are still the same in this case, but there are separate Pixel passes for 0, 1 and 2 attenuation textures, with different shaders accordingly. In a real shader you'd implement both SubShaders in a single shader, and possibly a couple more for even older video cards <i>(gotta love all the different cards out there, right?)</i>.
<pre class='codelisting'>
Shader &quot;Light Attenuation&quot; {
Properties {
    _Color (&quot;Main Color&quot;, Color) = (1,1,1,0.5)
}

CGINCLUDE
// This block will be pasted into all later cg program blocks
#include &quot;UnityCG.cginc&quot;
float4 Lighting( appdata_base v )
{
    // compute a simple diffuse per-vertex
    float3 ldir = normalize( ObjSpaceLightDir( v.vertex ) );
    float diffuse = dot( v.normal, ldir );
    return diffuse * _ModelLightColor[0] * 2;
}
ENDCG

Category {
    Blend AppSrcAdd AppDstAdd
    Fog { Color [_AddFog] }
    
    // ATI Fragment shader cards
    SubShader {
        // Ambient pass
        Pass {
            Name &quot;BASE&quot;
            Tags {&quot;LightMode&quot; = &quot;PixelOrNone&quot;}
            Color [_PPLAmbient]
            SetTexture [_Dummy] {constantColor [_Color] Combine primary DOUBLE, constant}
        }
        // Vertex lights
        Pass { 
            Tags {&quot;LightMode&quot; = &quot;Vertex&quot;}
            Lighting On
            Material {
                Diffuse [_Color]
                Emission [_PPLAmbient]
            }
            SetTexture [_Dummy] {constantColor [_Color] Combine primary DOUBLE, constant}
        }
        
        // Lights with 0 light textures
        Pass {
            Tags {
                &quot;LightMode&quot; = &quot;Pixel&quot;
                &quot;LightTexCount&quot; = &quot;0&quot;
            }
CGPROGRAM
// vertex vert
struct v2f {
    V2F_POS_FOG;
    float4 color : COLOR0;
};
v2f vert (appdata_base v)
{
    v2f o;
    PositionFog( v.vertex, o.pos, o.fog );
    o.color = Lighting( v );
    return o;
}
ENDCG
            Program &quot;&quot; {
                SubProgram {
                    &quot;!!ATIfs1.0
                    StartOutputPass;
                        MOV r0, color0; # just output color
                    EndPass;
                    &quot;
                }
            }
        }
        
        // Lights with 1 light texture
        Pass {
            Tags {
                &quot;LightMode&quot; = &quot;Pixel&quot;
                &quot;LightTexCount&quot; = &quot;1&quot;
            }

CGPROGRAM
// vertex vert
struct v2f {
    V2F_POS_FOG;
    float4 color : COLOR0;
    float4 LightCoord0 : TEXCOORD0; // one light texcoord
};
v2f vert (appdata_base v)
{
    v2f o;
    PositionFog( v.vertex, o.pos, o.fog );
    o.color = Lighting( v );
    o.LightCoord0 = LIGHT_COORD( 0 ); // light texcoord
    return o;
}
ENDCG
            Program &quot;&quot; {
                SubProgram {
                    &quot;!!ATIfs1.0
                    StartOutputPass;
                        SampleMap r0, t0.str; # attenuation
                        MUL r0, color0, r0.a; # multiply with color
                    EndPass; 
                    &quot;
                }
            }
            SetTexture[_LightTexture0] {}
        }
        
        // Lights with 2 light textures
        Pass {
            Tags {
                &quot;LightMode&quot; = &quot;Pixel&quot;
                &quot;LightTexCount&quot; = &quot;2&quot;
            }
CGPROGRAM
// vertex vert
struct v2f {
    V2F_POS_FOG;
    float4 color : COLOR0;
    float4 LightCoord0 : TEXCOORD0; // two light texcoords
    float4 LightCoordB0 : TEXCOORD1;
};
v2f vert (appdata_base v)
{
    v2f o;
    PositionFog( v.vertex, o.pos, o.fog );
    o.color = Lighting( v );
    o.LightCoord0 = LIGHT_COORD( 0 );
    o.LightCoordB0 = LIGHT_COORD( 1 );
    return o;
}
ENDCG
            Program &quot;&quot; {
                SubProgram {
                    &quot;!!ATIfs1.0
                    StartOutputPass;
                        SampleMap r0, t0.stq_dq; # attenuation1
                        SampleMap r1, t1.stq_dq; # attenuation2
                        MUL r0, color0, r0.a;
                        MUL r0, r0, r1.a;
                    EndPass; 
                    &quot;
                }
            }
            SetTexture[_LightTexture0] {}
            SetTexture[_LightTextureB0] {}
        }
    }
}

Fallback &quot; VertexLit&quot;, 1
}
</pre>
</p>



<p>Unity provides a handful of builtin values for your shaders: things like current object's transformation matrices, light's color, time etc.
</p>

<p>You just use them in ShaderLab like you'd use any other property, the only difference is that
you don't have to declare it somewhere - they are &quot;built in&quot;.
</p>

<p>Using them in Cg shaders requires including <b>UnityCG.cginc</b> file.
</p>

<h3>Transformations</h3>

<p><table class="wikitable"><tr><td class="wikicell" ><b>Name</b> </td><td class="wikicell" > <b>Type</b> </td><td class="wikicell" > <b>Value</b> </td><td class="wikicell" > <b>Usage</b></td></tr><tr><td class="wikicell" >_Object2World </td><td class="wikicell" > float4x4 </td><td class="wikicell" > Object to World space matrix </td><td class="wikicell" > Finding world space positions</td></tr><tr><td class="wikicell" >_World2Object </td><td class="wikicell" > float4x4 </td><td class="wikicell" > World to Object space matrix </td><td class="wikicell" > Finding local space positions from world space</td></tr><tr><td class="wikicell" >_ObjectSpaceCameraPos </td><td class="wikicell" > float3 </td><td class="wikicell" > Camera's position in object space </td><td class="wikicell" ></td></tr></table>
</p>

<h3>Lighting</h3>

<p>All these properties are actually arrays of size 2: i.e. _ModelLightColor[2]. Number 2 is the maximum amount of pixel lights that Unity can render in one pass. Most pixel lit shaders are written to process only one light/pass though. See <a href="../Manual/SL-NameAndTags.html">LightCount tag documentation</a> for details.
</p>

<p>In plain ShaderLab, you access them by just appending an index: e.g. the first light's model*light color is <i>_ModelLightColor0</i>. In Cg shaders, they are exposed as real arrays, so the same in Cg is <i>_ModelLightColor[0]</i>.
</p>

<p><table class="wikitable"><tr><td class="wikicell" ><b>Name</b> </td><td class="wikicell" > <b>Type</b> </td><td class="wikicell"  colspan="2"> <b>Value</b></td></tr><tr><td class="wikicell" >_ModelLightColor </td><td class="wikicell" > float4 </td><td class="wikicell"  colspan="2"> Material's Main * Light color</td></tr><tr><td class="wikicell" >_SpecularLightColor </td><td class="wikicell" > float4 </td><td class="wikicell"  colspan="2"> Material's Specular * Light color</td></tr><tr><td class="wikicell" >_ObjectSpaceLightPos </td><td class="wikicell" > float4 </td><td class="wikicell"  colspan="2"> Light's position in object space. <i>w</i> component is 0 for directional lights, 1 for other lights</td></tr><tr><td class="wikicell" >_Light2World </td><td class="wikicell" > float4x4 </td><td class="wikicell"  colspan="2"> Light to World space matrix</td></tr><tr><td class="wikicell" >_World2Light </td><td class="wikicell" > float4x4 </td><td class="wikicell"  colspan="2"> World to Light space matrix</td></tr><tr><td class="wikicell" >_Object2Light </td><td class="wikicell" > float4x4 </td><td class="wikicell"  colspan="2"> Object to Light space matrix</td></tr></table>
</p>

<h3>Misc</h3>

<p><table class="wikitable"><tr><td class="wikicell" ><b>Name</b> </td><td class="wikicell" > <b>Type</b> </td><td class="wikicell" > <b>Value</b> </td><td class="wikicell" > <b>Usage</b></td></tr><tr><td class="wikicell" >_Time </td><td class="wikicell" > float4 </td><td class="wikicell" > Time (t/20, t, t*2, t*3) </td><td class="wikicell" > Animating things inside the shaders</td></tr><tr><td class="wikicell" >_SinTime </td><td class="wikicell" > float4 </td><td class="wikicell" > Sine of time: (t/8, t/4, t/2, t) </td><td class="wikicell" > Animating things inside the shaders</td></tr><tr><td class="wikicell" >_CosTime </td><td class="wikicell" > float4 </td><td class="wikicell" > Cosine of time: (t/8, t/4, t/2, t) </td><td class="wikicell" > Animating things inside the shaders</td></tr><tr><td class="wikicell" >_CubeNormalize </td><td class="wikicell" > samplerCUBE </td><td class="wikicell" > Normalization cube map </td><td class="wikicell" > Used for pixel lighting on older hardware</td></tr><tr><td class="wikicell" >_SpecFalloff </td><td class="wikicell" > sampler2D </td><td class="wikicell" > Specular lookup map </td><td class="wikicell" > Used for pixel lighting on older hardware</td></tr></table>
</p>


<p><img class='figure' src='images/Reference - Structure-0.jpg' />
</p>

<h2>Quick reference for values accepted by shaderlab</h2>

<p><a href="../Manual/SL-NameAndTags.html">Tag values</a> - passes and subshaders use tags to tell how and when they expect to be rendered to the rendering engine.
</p>

<p><a href="../Manual/SL-BuiltinValues.html">Builtin variables</a> - a set of builtin variables for the shaders: transformation matrices, light parameters etc.
</p>

<hr />

<h3>Fog setup</h3>

<p>By default, the shaders are set up correctly regarding fog. When using multipass, you often want to change the fog value for each pass to avoid applying it multiple times.
</p>

<p><table class="wikitable"><tr><td class="wikicell" ><b>Property name</b></td><td class="wikicell" ><b>Value</b></td></tr><tr><td class="wikicell" >_FogColor</td><td class="wikicell" >The fog color</td></tr><tr><td class="wikicell" >_AddFog </td><td class="wikicell" > Fog color used for Additive passes.</td></tr><tr><td class="wikicell" >_MultiplyFog </td><td class="wikicell" > Fog color used for multiply passes.</td></tr><tr><td class="wikicell" >_FogStart</td><td class="wikicell" >The fog starting distance</td></tr><tr><td class="wikicell" >_FogEnd</td><td class="wikicell" >The fog end distance</td></tr><tr><td class="wikicell" >_FogDensity</td><td class="wikicell" >The fog density</td></tr></table>
</p>

<h3>Material setup</h3>

<p>You can change the OpenGL material settings from within a shader using the following properties:
</p>

<p><table class="wikitable"><tr><td class="wikicell" ><b>Property name</b></td><td class="wikicell" ><b>Value</b></td></tr><tr><td class="wikicell" >Ambient</td><td class="wikicell" >The Ambient color</td></tr><tr><td class="wikicell" >Diffuse </td><td class="wikicell" > Diffuse material color</td></tr><tr><td class="wikicell" >Specular </td><td class="wikicell" > Specular material color</td></tr><tr><td class="wikicell" >Emissive</td><td class="wikicell" > Emissive material color</td></tr><tr><td class="wikicell" >Shininess</td><td class="wikicell" >Shininess factor</td></tr></table>
</p>

<h3>Simple state commands</h3>
<p><table class="wikitable"><tr><td class="wikicell" >Name string </td><td class="wikicell" > Sets the name of this pass to string</td></tr><tr><td class="wikicell" >Color color </td><td class="wikicell" > Sets the current color to color</td></tr><tr><td class="wikicell" >Blendcolor color </td><td class="wikicell" > uses color  as the blending color</td></tr><tr><td class="wikicell" >Lighting bool </td><td class="wikicell" > Turns OpenGL lighting on/off</td></tr><tr><td class="wikicell" >Colormask rgbflags  </td><td class="wikicell" >  Disables rendering to the color channels that are set. f.eks will no rendering to the alpha channel occur when writing Colormask Alpha</td></tr><tr><td class="wikicell" >Cull cullorient  </td><td class="wikicell" >  cullorient can be Front, Back or FrontAndBack and sets culling of those faces. It is also possible to write Cull false for no culling.</td></tr><tr><td class="wikicell" >Shademodel model  </td><td class="wikicell" >  Sets the shading model in OpenGL. Can be Smooth or Flat.</td></tr><tr><td class="wikicell" >Seperatespecular bool  </td><td class="wikicell" >  Turn Seperate specular on/off.</td></tr></table>
</p>

<p>Print this and stick on the wall!
</p>

<p><table class="wikitable"><tr><td class="wikicell"  colspan="4"><div align="center"><b>State modifiers</b></div></td></tr><tr><td class="wikicell" ><b>Culling &amp; Depth</b></td><td class="wikicell" ><b>Blending</b></td><td class="wikicell" ><b>Material &amp; Lighting</b></td><td class="wikicell" ><b>Esoteric stuff</b></td></tr><tr><td class="wikicell" >ZTest<br>ZWrite<br>Cull</td><td class="wikicell" >Blend<br>AlphaTest</td><td class="wikicell" >Material<br>Lighting<br>Fog<br>SeparateSpecular<br>Color</td><td class="wikicell" >ColorMask<br>ShadeModel<br>Offset</td></tr><tr><td class="wikicell" ><b>Texturing</b></td><td class="wikicell" ><b>Channels</b></td><td class="wikicell" ><b>Programs</b></td><td class="wikicell" ><b>Tags</b></td></tr><tr><td class="wikicell" >SetTexture<br>Texgen<br>ConstantColor<br>Combine<br>Matrix</td><td class="wikicell" >BindChannels<br>Bind</td><td class="wikicell" >Bind<br>Properties<br>Local</td><td class="wikicell" >Tags</td></tr></table>
</p>

<hr />

<p><table class="wikitable"><tr><td class="wikicell" ><b>Material</b></td><td class="wikicell"  colspan="3">Diffuse Specular Ambient Emission Shininess</td></tr><tr><td class="wikicell" ><b>Blend Modes</b></td><td class="wikicell"  colspan="3">One Zero SrcAlpha DstAlpha SrcColor DstColor OneMinus*** AppSrcAdd AppDstAdd</td></tr><tr><td class="wikicell" ><b>Alpha and Depth Test Modes</b></td><td class="wikicell"  colspan="3">Less Greater LEqual GEqual Equal NotEqual Always</td></tr><tr><td class="wikicell" ><b>Fog</b></td><td class="wikicell"  colspan="3">Mode Color Start End</td></tr><tr><td class="wikicell" ><b>Combiners</b></td><td class="wikicell"  colspan="3">Combine Texture Primary Previous Lerp Alpha</td></tr></table>
</p>

<hr />

<p><table class="wikitable"><tr><td class="wikicell"  colspan="4"><div align="center"><b>Tags</b></div></td></tr><tr><td class="wikicell" >RenderQueue</td><td class="wikicell"  colspan="3">Background Geometry<i>(def)</i> Transparent Overlay</td></tr><tr><td class="wikicell" >LightMode</td><td class="wikicell"  colspan="3"> VertexOrNone <i>(def)</i> Vertex Pixel PixelOrNone</td></tr><tr><td class="wikicell"  colspan="4"><div align="center"><b>Channels</b></div></td></tr><tr><td class="wikicell"  colspan="4">Vertex Normal Tangent TexCoord Color</td></tr></table>
</p>




<p><i>Premature optimization is the root of all evil</i>
</p>

<p><i>&ndash; Donald Knuth.</i>
</p>

<h3> Unity post-processes all imported assets</h3>
<p>Unity always post-processes imported files, thus storing a file as a multi layered psd file instead of a jpg will make absolutely zero difference in the size of the player you will deploy. Save your files in the format you are working with (eg. .mb files, psd files, tiff files) to make your life easier.
</p>

<h3> Unity strips out unused assets</h3>
<p>The amount of assets in your project folder does <b>not</b> influence the size of your built player. Unity is very smart about detecting which assets are used in your game and not. Unity follows all references to assets before building a game and builds a list of assets that need to be included in the game. Thus you can safely keep unused assets in your project folder.
</p>

<h3> Unity prints an overview of the used file size</h3>

<p>After Unity has completed building a player, it prints an overview of what type of asset took up most file size, and it prints which assets were included in the build:
</p>

<p>To see it just open <b>/Applications/Utilities/Console.app</b>
</p>

<p><img class='figure' src='images/Reducing File size-0.jpg' />
</p>

<p><i>An overview of what took up space</i>
</p>

<h3> Optimizing texture size</h3>

<p>Often textures take up most space in the build. The first thing to do is to turn on texture compression when building the player.
</p>

<p>If that doesnt get the size down, it is about reducing the size of the textures. The trick here is that you don't need to modfiy the actual source content. Simply select the texture in the project view and choose <b>Assets -&gt; Import Settings...</b>.
</p>

<p>Here you can specify the maximum texture size which will be used when importing the texture. It is a good idea to zoom in on an object that uses the texture, then adjust the maximum texture size until it starts looking worse in the scene view.
</p>

<p><img class='figure' src='images/Reducing File size-1.jpg' />
</p>

<p><i>Tuning texture size</i>
</p>

<h3> How much memory does my texture take up</h3>

<p><table class="wikitable"><tr><td class="wikicell" ><div align="center"><b>Compression</b></td><td class="wikicell" ><b>Memory consumption</b></div></td></tr><tr><td class="wikicell" >DXTC1 RGB</td><td class="wikicell" >0.5 Bpp (bytes/pixel)</td></tr><tr><td class="wikicell" >DXTC3 RGBA</td><td class="wikicell" >1 Bpp</td></tr><tr><td class="wikicell" >DXTC5 RGBA</td><td class="wikicell" >1 Bpp</td></tr><tr><td class="wikicell" >RGB 16bit</td><td class="wikicell" >2 Bpp </td></tr><tr><td class="wikicell" >RGB 24bit</td><td class="wikicell" >3 Bpp</td></tr><tr><td class="wikicell" >Alpha 8bit</td><td class="wikicell" >1 Bpp</td></tr><tr><td class="wikicell" >RGBA 16bit</td><td class="wikicell" >2 Bpp</td></tr><tr><td class="wikicell" >RGBA 32bit</td><td class="wikicell" >4 Bpp</td></tr></table>
</p>

<p>To figure out total texture size: width * height * bpp.
Add 33% if you have Mipmaps.
</p>

<p>When building a game there is a button <b>Compress textures</b>.
</p>

<p>By default Unity does not compress textures when importing, even if you choose DXTC compression. This is because compressing textures takes a long time and it is better to have fast iteration time when importing textures into your game. (You can  change this behaviour in the preferences though)
</p>

<p>The compress textures button in the build settings will make sure that all textures that have DXTC texturing enabled will actually be compressed, before building the player.
</p>



<p>When building a Web Player, Unity automatically generates a <i>html</i> file next to the player data file. It contains the default html code to load the web player data file using both the Netscape plugin and ActiveX plugin.
</p>

<p>It is possible to further tweak and customize the generated html file to make it fit better with the containing site's design, to add more html content etc. The following articles discuss the related subjects in depth:
</p>
<ul><li> <a href="../Manual/Web-LoaderImages.html">Customizing Web Player loading screen</a>
</li><li> <a href="../Manual/Web-GeneratedHtml.html">HTML code to load Unity content explained</a>
</li><li> <a href="../Manual/Web-BrowserCommunication.html">Web browser &lt;-&gt; Unity communication</a>
</li></ul>




<p>By default Unity Web Player displays a small Unity logo and a progress bar while loading a web player. It is possible to customize the appearance of this loading screen. Here is a <a class="wiki"  href="http://www.otee.dk/webplayers/CustomProgress/index.html">sample html</a> file of a customized loader screen.
</p>

<p>Please note that modifying the loader images is only allowed with <b>Unity Pro</b>.
</p>

<p>The Unity Web Player takes five customizable parameters which are used to display custom loader screens. All images used need to be RGB 8 bit/channel <b>.png</b> files. The parameters to images can be absolute or relative links.
</p>

<p>Example:
<pre class='codelisting'>
logoimage=&quot;mylogo.png&quot; progressbarimage=&quot;myprogress.png&quot; progressframeimage=&quot;myprogressframe.png&quot; backgroundcolor=020F16
</pre>
This example is an excerpt of the HTML file inside the &lt;<i>embed</i>&gt; tag (for Firefox/Safari/Netscape/Opera browsers). Similar HTML code needs to be added for Internet Explorer as separate &lt;<i>param</i>&gt; tags inside the &lt;<i>object</i>&gt; tag (see the <a class="wiki"  href="http://www.otee.dk/webplayers/CustomProgress/index.html">sample html</a> file).
</p>

<p>The parameters are:
</p>
<ul><li> <b>logoimage</b>: the logo image. This is drawn centered on the screen.
</li><li> <b>progressframeimage</b>: drawn below the logo for the empty parts of the progress bar.
</li><li> <b>progressbarimage</b>: the &quot;filled&quot; part of the progress bar. This is drawn on top of the progress frame image. It is recommended to keep this image the same width as the <i>progressframeimage</i>. The progress image is always cropped to the percentage of how far the download has progressed relative to the width of the image.
<ul><li> The progress bar and progress frame images usually have the same width and height.
</li></ul></li><li> <b>backgroundcolor</b>: the window of the plugin is cleared with this solid color. Colors always need to be 6 hexadecimal characters eg. 020F16 (default is white).
</li><li> <b>bordercolor</b>: a one pixel border is drawn around the plugin window in this color. Colors always need to be 6 hexadecimal characters eg. 020F16 (default is white).
</li></ul>



<p>Web players are loaded by Unity browser plugin. The HTML code required to put a web player on the page is different for Internet Explorer and all other browsers. IE uses ActiveX plugin and an <i>object</i> tag must be used while all other supported browsers use Netscape plugin and an <i>embed</i> tag must be used.
</p>

<p>The default HTML template is generated by Unity when <a href="../Manual/Web Player Deployment.html">building a web player</a> and is all you need to display Unity content in a web page. This page describes the HTML code to load Unity in detail in case you want to customize the generated file or generate the code on your own (e.g. from a server side script).
</p>

<p>The smallest HTML snippet to load web players on all supported browsers is such (place inside <i>body</i> tag):
<pre class='codelisting'>
&lt;object id="Unity" classid="CLSID:36D04559-44B7-45E0-BA81-E1508FAB359F"
    codebase="http://unity3d.com/download_webplayer/UnityWebPlayer.cab"
    width="400" height="300">
    &lt;param name="src" value="MyDataFile.unityweb" />
    &lt;embed src="MyDataFile.unityweb" width="400" height="300"
        name="UnityEmbed" type="application/x-unity" pluginspage="http://unity3d.com/getunityplayer.html" />
&lt;/object>
</pre>
Here both <i>object</i> and <i>embed</i> tags are used in such a way that IE ignores the <i>embed</i> tag while the other browsers ignore the <i>object</i> tag.
</p>
<ul><li> Size of plugin window is controlled with <i>width</i> and <i>height</i> parameters (400x300 here).
</li><li> Path to the <i>unityweb</i> data file is given with <i>src</i> tag inside <i>object</i> tag and with same-named parameter inside <i>embed</i> tag.
</li><li> The rest of the parameters should not be modified: <i>codebase</i> and <i>pluginspage</i> point to the location from which Unity plugin can be installed; <i>classid</i> is the unique identifier of Unity ActiveX plugin; and <i>type</i> is the content type for the Netscape plugin.
</li></ul>

<p>The HTML generated when building a web player is slightly more complex - it uses browser detection to generate only the needed tags (<i>object</i> or <i>embed</i>) and it inserts some content in the case Unity Web Player can't be loaded or installed.
</p>



<p>The HTML page that contains a web player can communicate with it and vice versa. Basically there are two communication directions:
</p>
<ul><li> Web page calls functions in Unity game.
</li><li> Unity game calls functions in the web page.
</li></ul>


<h2>Calling game functions from the web page</h2>

<p>The Unity web plugin has a function <i>SendMessage</i> that can be called from a web page. This is a very similar to the <a class="wiki"  href="../ScriptReference/GameObject.SendMessage.html">GameObject.SendMessage</a> function in Unity scripting API. From a web page you pass object name, function name and a single argument; and <i>SendMessage</i> will call the given function in the given game object.
</p>

<p>When building a web player, the generated HTML template contains a helper function <i>GetUnity()</i> that returns the Unity object. Use it to call <i>SendMessage</i>; for example this would execute function <i>MyFunction</i> on the game object named <i>MyObject</i>, passing a string argument.
<pre class='codelisting'>
&lt;script language="javascript" type="text/javascript">
&lt;!--
function SaySomethingToUnity()
{
    GetUnity().SendMessage( "MyObject", "MyFunction", "Hello from a web page!" );
}
-->
&lt;/script>
</pre>
</p>

<p>Inside of Unity, you need to have a script attached to the game object named <i>MyObject</i>. This script needs to implement a function named MyFunction:
<pre class='codelisting'>
function MyFunction(param : String)
{
    Debug.Log(param);
}
</pre>
</p>

<p>A single string, int or float argument must be passed using SendMessage. Note that this parameter is required on the calling side. If you don't need it, just pass a zero and ignore it on the Unity side.
</p>

<p>Also note that the game object specified by the name can be given like a path name eg. <i>/MyObject/SomeChild</i>. <i>SomeChild</i> must be a child of <i>MyObject</i> and <i>MyObject</i> must be at the root level due to the <i>/</i> in front of it's name.
</p>

<h2>Calling web page functions from the game</h2>

<p>For this <a class="wiki"  href="../ScriptReference/Application.ExternalCall.html">Application.ExternalCall</a> function is used. Basically you can call any JavaScript function defined in the web page, passing any number of parameters to it. For example, this call in a game script:
<pre class='codelisting'>
Application.ExternalCall( "SayHello", "The game says hello!" );
</pre>
will execute function <i>SayHello</i> in the web page, passing a single string to it. The web page would define the function like this:
<pre class='codelisting'>
&lt;script language="javascript" type="text/javascript">
&lt;!--
function SayHello( arg )
{
    // show the message
    alert( arg );
}
-->
&lt;/script>
</pre>
</p>

<p>Of course, the function in the web page can be arbitrarily complex; for example navigate to some other web page, change some HTML content or even perform some AJAX magic.
</p>

<p>Arbitrary number of string, int and float arguments can be passed using <i>ExternalCall</i>.
</p>

<h2>Executing arbitrary browser code from the game</h2>

<p>You don't even have to define functions in the embedding web page, as with the  <a class="wiki"  href="../ScriptReference/Application.ExternalEval.html">Application.ExternalEval</a> function, you can execute arbitrary browser code from the game.
</p>

<p>The following example checks that the page embedding the game is fetched from a certain host (unity3d.com). If not, it will redirect to another URL.
This can be used to prevent deep linking to your game.
<pre class='codelisting'>
Application.ExternalEval( "if(document.location.host != 'unity3d.com') { document.location='http://unity3d.com'; }" );
</pre>
</p>




<p>Unity has extensive support for C, C++ or Objective-C based plugins.
In order to use a plugin you need to do two things:
</p>
<ul><li> Write a plugin in a C based language and compile it.
</li><li> Create a C# script which calls functions in the plugin to do something.
</li></ul>

<p>So the plugin provides a simple c interface. The Script then invokes the functions exposed by the plugin.
Here is a very simple example:
</p>

<h2>The C file of a minimal plugin:</h2>
<p><pre class='codelisting'>
float FooPluginFunction () { return 5.0F; }
</pre>
</p>

<h2>A C# script that uses the plugin:</h2>
<p><pre class='codelisting'>
using UnityEngine; 
using System.Runtime.InteropServices; 

class SomeScript : MonoBehaviour 
{
   // This tells unity to look up the function FooPluginFunction inside the plugin named &quot;PluginName&quot;
   [DllImport (&quot;PluginName&quot;)]
   private static extern float FooPluginFunction ();

   void Awake () 
   {
      // Calls the FooPluginFunction inside the PluginName plugin
      // And prints 5 to the console 
      print (FooPluginFunction ());
   }
}
</pre>
</p>

<h2>Building a plugin for Mac OS X</h2>

<p>If you are building a plugin for Mac OS X, you have to create a bundle. The easiest way to do this is using XCode. Use <i>File-&gt;NewProject...</i> and select the Bundle - Carbon Bundle preset.
</p>

<p>If you are using C++ or Objective-C to implement the plugin you have to make sure the functions are declared with C linkage to avoid name mangling issues.
<pre class='codelisting'>
extern &quot;C&quot;
{
  float FooPluginFunction ();
}
</pre>
</p>

<h2>Building a plugin for Windows</h2>

<p>Plugins on Windows are DLL files with exported functions. Practically any language or development environment that can create DLL files can be used to create plugins. Again, if you use C++, declare functions with C linkage to avoid name mangling issues.
</p>

<h2>Using your plugin from C#</h2>

<p>Once you have built your bundle you have to copy it to <i>Assets/Plugins</i> folder.
Unity will then find it by its name when you define a function like this:
<pre class='codelisting'>
[DllImport (&quot;PluginName&quot;)]
private static extern float FooPluginFunction ();
</pre>
</p>

<p>Please note that <i>PluginName</i> should not include the extension of the filename.
</p>

<h2>Deployment</h2>
<p>For cross platform plugins you have to include both .bundle (for Mac) and .dll (for Windows) files in Plugins folder. Once you have placed your plugins in the Plugins folder there is no more work required on your side. Unity automatically picks the right plugin for the right deployment platform and includes it with the player.
</p>

<h2>Examples</h2>

<h3> Midi Plugin</h3>
<p>A complete example of the Plugin interface can be found <a class="wiki"  href="http://www.otee.dk/tutorials/midiplugin.zip">here</a>.
</p>

<p>This is a complete MidiPlugin for OS X which uses Apple's CoreMidi API.
It provides a simple C API and a C# class using the C API.
The C# class contains a high level API, with easy access to NoteOn and NoteOff events and their velocity.
</p>

<h3> Texture Plugin</h3>
<p>An example how to assign image data to a texture from C++ directly to OpenGL. This can be used to implement decompressed movies. This example includes both XCode (for Mac) and Visual Studio (for Windows) project files. The plugin with accompanying Unity project can be found <a class="wiki"  href="http://www.otee.dk/examples/TexturePlugin.zip">here</a>.
</p>

<h2>More information</h2>
<p><a class="wiki"  href="http://www.mono-project.com/Interop_with_Native_Libraries">Mono Interop with native libraries</a>.
</p>

<p><a class="wiki"  href="http://msdn.microsoft.com/library/default.asp?url=/library/en-us/cpguide/html/cpconmarshalingdatawithplatforminvoke.asp">Microsoft p-invoke</a>.
</p>



<p>When building a player, you sometimes want to modify the built player in some way. For example you might want to add a custom icon, copy some documentation next to the player or build an Installer. Doing this manually can become tedious and if you know how to write sh or perl scripts you can automate this task.
</p>

<p>After Building a player unity automatically invokes the script placed in your project folders &quot;Assets/Editor/PostprocessBuildPlayer&quot; path.
</p>

<p>In this script you can post process the player in any way you like. For example build an installer out of the player.
</p>

<p>You can use perl, sh or any other commandline compatible language.
</p>

<p>Unity passes some useful command line arguments to the script, so you know what kind of player it is and where it is stored.
</p>

<p><pre class='codelisting'>
#!/usr/bin/perl

my $installPath = $ARGV[0];

# The type of player built:
# &quot;dashboard&quot;, &quot;standaloneWin32&quot;, &quot;standaloneOSXIntel&quot;, &quot;standaloneOSXPPC&quot;, &quot;standaloneOSXUniversal&quot;, &quot;webplayer&quot;
my $target = $ARGV[1];

# What optimizations are applied. At the moment either &quot;&quot; or &quot;strip&quot; when Strip debug symbols is selected.
my $optimization = $ARGV[2];

# The name of the set in the project settings
my $companyName = $ARGV[3];

# The name of the product set in the project settings
my $productName = $ARGV[3];

print (&quot;\n*** Building at '$installPath' with target: $target \n&quot;);
</pre>
</p>

